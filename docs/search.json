[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modeling Choice and RT",
    "section": "",
    "text": "Preface\nThis is a collection of notes and examples that serve as an introduction to cognitive models of choice and response time. To follow along in R, make sure you have the following packages installed.\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(ucminf)\nlibrary(WienR)\nlibrary(fddm)\nlibrary(rtdists)\n\n\nPlus, if you would like to use the Shiny app included in later Chapters, be sure you are working in RStudio with Shiny installed.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 In this workshop\nUnderstanding the mind is ultimately about understanding a dynamic system comprised of a large set of elements that interact in complex ways. If we had designed the mind, things would be easier: Like a car, a computer, or some other piece of modern machinery, we would have built different parts for different functions and stuck them together in a way that would make it easy for us to repair and reconfigure the system. In reality, things are not so simple. Because the mind is not human-engineered (or really “engineered” at all!), for us mere humans to understand it requires us to reverse-engineer the mind. In other words, we have to see what the mind does in some particular situation, build a particular type of machine—a model—that we hypothesize operates like the mind does, and then put the machine in that same scenario and see whether it acts like a human mind. To the extent that our model acts like a human in that scenario, that gives us reason to believe that the model is operating in some sense “like” a human mind does in that scenario.\nIn the early days of scientific psychology, our tools for building models of complex dynamical systems were quite limited. We could build physical models, but these are constrained by the physical properties of the materials we use (nonetheless, it is worth noting that mechanical model of attention by Broadbent (1957) is designed in such a way that the physical properties of the model capture important psychological constraints). Purely mathematical models may not have been so strongly constrained by physicality, but when considering situations with many interacting elements or when stochastic noise is involved, mathematical models quickly become intractable (consider the insoluble “three body problem”—even with a complete model of such a system, we cannot derive its future behavior analytically). As a result, early psychology was dominated by behaviorism, which eschewed the development of theories of the mind and contented itself merely with observing and cataloging behavior.\nIt was not until the middle of the twentieth century, when modern computers began to become of use, that the possibility of “reverse-engineering the mind” became a reality. This was the time of the “cognitive revolution” (Neisser, 1967). The revolution came about for both technical and conceptual reasons.\nFrom a conceptual perspective, computers offered a productive metaphor for helping us understand how the mind works. A computer uses the same physical substrate to perform different functions, similar to how the same brain lets us both speak and play piano. A computer’s adaptivity comes from the fact that the computer can run different “programs” on its hardware. A program is a set of procedures that take a set of “inputs” and transform them into “outputs”. This is analogous to how a living organism decides to act in a certain way (its “outputs”) depending on its goals and on the environment it happens to be in (its “inputs”). Meanwhile, the procedures that transform a computer’s inputs into outputs often involve intermediate steps that do not themselves produce observable behavior but which are nonetheless represented by changes in the internal state of the computer. These internal states are analogous to thoughts or beliefs in that they may not be externally observable, but they are critical steps on the path toward taking an action. The computer metaphor thus enables us to understand cognition in terms of how internal states of mind represent aspects of an organism’s environment, goals, and thoughts in such a way that these representations can be processed to yield behavior that is appropriate to the situation the organism is in.\nFrom a technical perspective, computers offer a way to derive predictions from complex models that would not have been tractable otherwise. As we shall see, this is particularly valuable for two applications: First, we can use the computer to simulate what a model would do and thereby understand the distribution of possible actions it can take. This obviates the need to derive predictions through mathematical analysis or logic, which though powerful, can only be applied to simple models. Second, we can use the computer to fit a model to data. Almost all models have parameters which can be thought of as “knobs” or “settings” that adjust the kind of behavior the model produces. To “fit” a model means to find the parameters for that model that get it to generate behavior that is as close as possible to the behavior recorded in a dataset. Except for very simple models, it is impossible (or at least very impractical) to try to fit them to data without a computer. But as we shall see, fitting a model is useful because we can infer from the best-fitting parameters something about the person who produced the data to which the model was fit.\nIn summary, computers made it feasible for cognitive psychologists to “reverse-engineer” the mind because they (a) provided a valuable conceptual metaphor that allowed theories of cognition to be posed in the form of computational models comprised of internal representations and processes applied to those representations; (b) enabled predictions to be derived for models that were complex and/or had stochastic elements; and (c) enabled those same kinds of models to be “fit” to data so that model parameters can give insight into how a person performed the task for which data was recorded.\nThere is an important difference between “reverse-engineering” a natural system, like the mind, from reverse-engineering a human-designed system like a car. Because a natural system was not “engineered”, the models we devise are not guaranteed to work the same way as a natural system, even if the model accurately mimicks the behavior of the natural system in the cases we study. The purpose in “reverse-engineering” the mind is not to build a duplicate mind, it is instead to “translate” a complex system into a form that enables us to understand it better. The model is a deliberate simplification which we expect to deviate from reality in many ways. What we hope is that we arrive at a model that helps us understand the key features of a natural system well enough for us to understand why it acts the way it does in specific situations (for further discussion of the purposes of models in psychology, see Cox & Shiffrin, In press; Singmann et al., 2022).\nWith that high-minded philosophical stuff out of the way, the purpose of this workshop is to see how to use computational cognitive models of a particular ilk. These are models that are designed to account for two aspects of behavior: choice and response time (RT). These models are applied in situations where a person (or other organism!) has to decide between a small number of possible alternatives, often just two. Such situations abound in experimental psychology, including lexical decision, recognition memory, detection tasks, search tasks, categorization tasks, etc. The models are designed to help us understand two things:\nFor the purposes of this workshop, we will focus on models of choice and RT called diffusion models.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#in-this-workshop",
    "href": "intro.html#in-this-workshop",
    "title": "1  Introduction",
    "section": "",
    "text": "Why did a participant make the choices they made?\nWhy did it take the participant a certain amount of time to make the choices they made?\n\n\n\n1.1.1 Key theoretical constructs\nThe vast majority of models of choice and RT, including diffusion models, address the two questions above by invoking four basic theoretical constructs:\nEvidence accumulation: Choosing from among a set of options is assumed to require accumulating “evidence” that weights either in favor of or against each option. This evidence may come from perception (e.g., deciding which of two stimuli is brighter), from memory (e.g., deciding whether an item was or was not on a previously-studied list), or from deliberation (e.g., deciding which of two products to buy). As such, the idea that decisions are made by accumulating evidence helps explain not only which choice was made (it was the option that was most favored by the accumulated evidence) and how long it took to made the choice (the time needed to accumulate sufficient evidence to commit to a decision).\nResponse caution: If decisions are made by accumulating evidence, there must be a policy that terminates the accumulation process, otherwise someone would keep accumulating evidence forever. This is the idea behind the construct of “response caution”, which is that, depending on the situation, people may adopt a policy of deciding quickly on the basis of very little evidence (low response caution) or deciding slowly by waiting for more evidence to accumulate (high response caution). Thus, this construct is directly related to the idea of speed-accuracy trade-off.\nResponse bias: It may be that a decision maker is willing to commit to some options more readily than others; in that case, we say they are “biased” in favor of some responses. Typically, this bias is modeled by assuming less response caution for some options than others. In other words, a participant may be willing to commit to some decisions on the basis of less accumulated evidence than others.\nResidual time: The time needed to accumulate sufficient evidence to make a decision is not the only thing that contributes to observed response times. After all, it takes time to realize that a trial of a task has actually begun. It may also take time to retrieve relevant information from memory, to focus attention on relevant features in the environment, or to evaluate a potential outcome. Finally, it takes some time to execute the motor actions associated with the chosen option (e.g., to press a button, move a lever, etc.). The time for all of these additional processes is often called non-decision time (NDT) or encoding and response execution time (\\(T_{ER}\\)). However, I prefer to call it simply “residual time” because that is what it is—it is the time “left over” besides the time needed for evidence accumulation.\n\n\n1.1.2 Models and parameters\nThe models we will encounter have parameters that pertain to each of the four constructs just described. We will see how differences in the values of these parameters result in different patterns of behavior from the model. This is also how the models are “fit” to data—by finding the combination of parameter values that produces behavior that most closely resembles that produced by a participant in some task. The value of doing this is that it helps us understand why that participant acted the way they did. For example, we might want to know whether someone was fast because they were able to quickly accumulate the evidence they needed, because they were uncautious, because they were biased, or because they could execute motor actions quickly. We can address that question by finding the values of the parameters associated with each construct that best fit their observed performance.\n\n\n1.1.3 Tasks amenable to choice/RT models\nIn this tutorial, we will primarily focus on tasks that involve choosing between two options. As a result, each trial of such a task produces a choice (which option was picked) as well as a response time (how long it took to pick that choice). Framed this way, it may seem like these models are only applicable to certain kinds of decision tasks, but in fact two-choice tasks of this kind abound in the psychological literature and in real life:\n\nIs a person or object a member of some category or not? (a categorization task)\nWhich of two products should I buy? (a common decision task)\nShould I take a risky gamble or a sure thing? (a common judgment and decision making task)\nHave I ever seen this thing before? (a lexical decision task)\nDid I encounter a person or thing in a specific context or not? (a recognition memory task)\nAre two items the same or different? (a same-different judgment)\nIs a person or object present in a scene or not? (a visual search task)\nShould I watch the next episode in a series or not? (no really, Netflix is using diffusion models to understand these kinds of decisions)\n\n\n\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and immediate memory. Psychological Review, 64(3), 205–215.\n\n\nCox, G. E., & Shiffrin, R. M. (In press). Computational models of event memory. In M. J. Kahana & A. Wagner (Eds.), Oxford handbook of human memory. Oxford University Press.\n\n\nNeisser, U. (1967). Cognitive psychology. Appleton-Century-Crofts.\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober, C. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D., Navarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service of science: Don’t let the tail wag the dog. Computational Brain & Behavior.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "history.html",
    "href": "history.html",
    "title": "2  Historical Perspectives",
    "section": "",
    "text": "2.1 Random walk and diffusion models\nThis chapter provides some historical context for the development of the two main classes of choice-RT models: random walk and diffusion models, which are chiefly employed to model situations where people choose between two options; and counter/accumulator models, which can also model situations with two options but also apply to situations with more than two options.\nEarly models of human choice behavior treated choice as a statistical decision of the sort described by Neyman & Pearson (1933), in which a sample of data (e.g., a stimulus) is presumed to be drawn from a set of underlying generating distributions and the task of the participant is to select the distribution most likely to have generated the data. Specifically, the decision, given data \\(x\\) and hypotheses \\(H_0\\) and \\(H_1\\), is governed by a likelihood ratio:\n\\[\nL(x) = \\frac{\\Pr (H_1 | x)}{\\Pr (H_0 | x)} = \\frac{\\Pr (x | H_1)}{\\Pr (x | H_0)} \\frac{\\Pr (H_1)}{\\Pr (H_0)} \\text{.}\n\\]\nIf this ratio is greater than a threshold value \\(\\theta\\), hypothesis \\(H_1\\) is selected otherwise \\(H_0\\) is chosen. Signal detection theory (Macmillan & Creelman, 2005) is the most prominent theoretical framework in this vein, and continues to be a useful and widely-applied model of choice. Its utility lies in being able to give clear interpretations to notions like bias (e.g., \\(\\theta\\)) and discriminability (proportional to \\(\\frac{\\Pr (x | H_1)}{\\Pr (x | H_0)}\\)). Signal detection theory, however, assumes that the decision is based on a fixed amount of evidence and thus ignores the dynamic process of evidence accumulation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Historical Perspectives</span>"
    ]
  },
  {
    "objectID": "history.html#random-walk-and-diffusion-models",
    "href": "history.html#random-walk-and-diffusion-models",
    "title": "2  Historical Perspectives",
    "section": "",
    "text": "2.1.1 The Sequential Probability Ratio Test\nThe question of how, when evidence accumulates over time, one might arrive at a final decision was first treated by Wald (1945), who proposed a sequential probability ratio test (SPRT). Assume that data samples \\(x_i\\), \\(i = 1, \\dotsc, n\\), arrive one at a time, and are sampled independently from the same underlying generating distribution, which is either \\(H_1\\) or \\(H_0\\). Then, the order in which the samples arrive is immaterial (they are “exchangeable”) and to compute the likelihood ratio \\(L(n)\\) given the \\(n\\) samples we currently possess, we need only multiply the ratios for each sample:\n\\[\nL(n) = \\left[ \\prod_{i=1}^n \\frac{\\Pr (x_i | H_1)}{\\Pr (x_i | H_0)} \\right] \\frac{\\Pr (H_1)}{\\Pr (H_0)} \\text{.}\n\\]\nThus, taking the logarithm of the likelihood ratio, we can express the change in log-likelihood that results from the \\(t\\)th new sample:\n\\[\n\\Delta L(t) = \\log \\frac{\\Pr (x_t | H_1)}{\\Pr (x_t | H_0)} \\text{,}\n\\]\nwhere \\(L(0) = \\log \\frac{\\Pr (H_1)}{\\Pr (H_0)}\\), the log of the ratio of the priors. The question that Wald addressed in this context was when to stop collecting new data samples and make a decision. Define two thresholds, \\(\\theta_1\\) and \\(\\theta_0\\), such that the decision maker will decide \\(H_1\\) if \\(L(t) \\geq \\theta_1\\) and will decide \\(H_0\\) if \\(L(t) \\leq \\theta_0\\) and \\(\\theta_1 &gt; 0 &gt; \\theta_0\\). Assuming the decision maker has a desired type I error rate \\(\\alpha\\) (probability of deciding in favor of \\(H_1\\) when \\(H_0\\) was the true generating distribution) and type II error rate \\(\\beta\\) (probability of deciding \\(H_0\\) when \\(H_1\\) is true), Wald (1945) showed that the thresholds should be set such that \\(\\theta_1 \\leq \\log (1 - \\beta) - \\log \\alpha\\) and \\(\\theta_0 \\geq \\log \\beta - \\log (1 - \\alpha)\\) in order to achieve maximum power. The thresholds may not be exactly equal to the specified values as a consequence of the fact that evidence arrives in a discrete manner and hence might “jump” over a threshold rather than actually equaling it.\nAn important consequence of the SPRT is that the amount of evidence required to make a decision for either \\(H_1\\) or \\(H_0\\)—and thus, in general, the number of samples required to make a decision—is tightly coupled to the expected error rates. For example, if the decision maker is willing to make more type I errors (with rate \\(\\alpha\\)), then both \\(\\theta_1\\) and \\(\\theta_0\\) will decrease, reflecting an increased willingness to respond \\(H_1\\) and not \\(H_0\\) (assuming \\(\\beta\\) is held constant). This has the consequence that, on average, it will take less time (fewer samples) before the decision maker is willing to respond \\(H_1\\) and more time (more samples) before the decision maker is willing to commit to \\(H_0\\). Thus, speed and accuracy can trade-off with one another, and the speed of particular responses (whether correct or incorrect) can be affected by the biases of the decision maker.\nStone (1960) suggested that the psychological process of decision making might be governed by something akin to the SPRT, an idea that received more explicit Bayesian treatment in Edwards (1965). Unfortunately, the SPRT predicts that the number of samples to reach a decision is independent of whether that decision was correct or not. That is, error and correct decision times are predicted to be equal (or, at least, drawn from the same distribution). This is very rarely true in observed data, hence a more general decision model is called for.\n\n\n2.1.2 Random Walk\nThe sequential probability ratio test can be considered a kind of stationary random walk in discrete time and continuous space. This is a consequence of the fact that evidence arrives sequentially and perturbs the decision maker’s current beliefs (\\(L(t)\\)) to a degree that is independent of those beliefs. Since the evidence acquired on each time step, \\(x_t\\), is sampled independently, we can treat the resulting likelihood ratio change \\(\\Delta L(t)\\) as an independent sample from some distribution. We can thus consider \\(L(t)\\) to simply accumulate samples of a random variable with density \\(f(\\Delta L)\\) and moment generating function \\(M(\\phi)\\).\nThe evidence density will, of course, depend on the true state of the world, such that if \\(H_1\\) is true, the evidence density \\(f_1(\\Delta L)\\) will produce more evidence in favor of \\(H_1\\) and likewise for density \\(f_0(\\Delta L)\\). The properties of the moment generating functions of these densities, \\(M_1(\\phi)\\) and \\(M_0(\\phi)\\), respectively, determine the properties of the random walk’s predicted RT’s. Because, in the SPRT, evidence takes the form of a likelihood ratio, the evidence distributions are symmetric, i.e., \\(f_1(\\Delta L) = f_0(-\\Delta L)\\), meaning the moment generating functions are related by translation: \\(M_1(\\phi + 1) = M_0(\\phi)\\). Swensson & Green (1977) showed that any random walk model for which the moment generating functions of the evidence distributions are related by translation must predict equal RTs to error and correct responses.\nA random walk model of human response dynamics was studied extensively as part of the theory of relative judgment (Link, 1975; Link & Heath, 1975). These authors generally assumed that the distributions of differences \\(\\Delta L(t)\\) are symmetric with respect to the two alternatives, in the way described above. They further assumed that the decision thresholds were symmetric, i.e., \\(\\theta_1 = -\\theta_0\\). Despite these restrictions, this random walk model can predict different RT’s for errors and correct responses. In particular, the difference between mean correct and error RTs in the theory of relative judgment is given by \\[\n\\begin{align}\nRT( \\text{Respond } H_1 | H_1) - RT( \\text{Respond } H_0 | H_1) & = \\left( \\frac{\\theta_1}{\\mu_1} \\right) \\left( \\frac{\\gamma_1 - 1}{\\gamma_1} \\right) \\\\\nRT( \\text{Respond } H_0 | H_0) - RT( \\text{Respond } H_1 | H_0) & = \\left( \\frac{\\theta_0}{\\mu_1} \\right) \\left( \\frac{\\gamma_1 - 1}{\\gamma_1} \\right)\n\\end{align}\n\\]\nwhere \\(\\mu_i\\) is the mean of evidence density \\(f_i(\\Delta L)\\) and \\(\\gamma_i\\) is its third moment, and \\(\\mu_1 = -\\mu_0\\) and \\(\\gamma_1 = -\\gamma_0\\) (Link & Heath, 1975). Thus, if \\(\\gamma_1 \\neq 1\\), errors may be either faster than correct responses (\\(\\gamma_1 &gt; 1\\)) or slower (\\(\\gamma_1 &lt; 1\\)). Critically, however, the relationship between error and correct RT must be of the same sign regardless of the true evidence generating distribution, which need not be the case in observed data. By relaxing the assumptions of symmetry, such that the moment generating functions of the evidence distributions are related by both scaling and translation (\\(M_0(\\phi) = k M_1(\\phi + 1)\\), where \\(k\\) is a constant), Ashby (1983) was able to show that a random walk could predict any ordering of mean RTs for correct and error responses.\n\n\n2.1.3 The Wiener Diffusion Process\nThe evidence generating density \\(f_i(\\Delta L)\\) can be decomposed into an expectation, \\(\\mu\\), and a noise distribution \\(\\nu\\), which is simply the original distribution with the expected value (\\(\\mu\\)) subtracted. The resulting stochastic difference equation for \\(L(t)\\) is\n\\[\n\\Delta L(t) = \\left[ \\mu + \\nu(t) \\right] \\Delta t \\text{,}\n\\]\nwhere we have now explicitly introduced \\(\\Delta t\\) (up to now, \\(\\Delta t = 1\\)) and \\(\\nu(t)\\) represents a sample drawn from the noise distribution \\(\\nu\\) at time \\(t\\).\nLet us now assume that the evidence generating distribution is Gaussian with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Then, we can consider the noise distribution in the above difference equation to be a Gaussian distribution with mean zero (we have subtracted out \\(\\mu\\)) and variance \\(\\sigma^2\\), which we denote \\(\\mathcal{N}(0, \\sigma^2)\\). We now have\n\\[\n\\Delta L(t) = \\left[ \\mu + \\mathcal{N}(0, \\sigma^2) \\right] \\Delta t \\text{.}\n\\]\nIn addition, we can rewrite \\(\\mathcal{N}(0, \\sigma^2)\\) as a sample from a standard (zero mean, unit variance) Gaussian, multiplied by \\(\\sigma\\). This gives us\n\\[\n\\Delta L(t) = \\mu \\Delta t + \\mathcal{N}(0, 1) \\sigma \\sqrt{\\Delta t} \\text{.}\n\\]\nBy taking the limit \\(\\Delta t \\rightarrow 0\\), we can move from discrete time to continuous time. In so doing, we have transformed the Gaussian random walk into the Wiener drift-diffusion process:\n\\[\nd L(t) = \\mu d t + \\mathcal{N}(0, 1) \\sigma \\sqrt{dt} \\text{.}\n\\]\nRatcliff (1978) modeled human responses as the outcome of a Wiener diffusion where the mean drift rate, \\(\\mu\\), reflects the relative amount of evidence favoring one response over the other while \\(\\sigma\\) reflects the noise inherent in the evidence-sampling process. Because each infinitesimal step of the evidence accumulation process comes from a normal distribution, the density over the accumulated evidence at time \\(t\\) is another normal distribution:\n\\[\n\\Pr (L(t) = x | t) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2 t}} \\exp \\left[ \\frac{\\left(x - \\mu t \\right)^2}{2 \\sigma^2 t} \\right] \\sim \\mathcal{N}(\\mu t, \\sigma^2 t) \\text{.}\n\\]\nThis makes it easy to calculate \\(d'\\), the familiar index of sensitivity from SDT, in the context of the diffusion model. Ratcliff (1978) assumed that the mean drift rate \\(\\mu\\) was itself sampled from a normal distribution with mean \\(u\\) and variance \\(\\eta\\) for each stimulus. We must thus integrate over \\(\\mu\\) to express the distribution of evidence as a function of time:\n\\[\n\\begin{align}\n\\Pr (L(t) = x | t) = & \\int_{-\\infty}^{\\infty} \\mathcal{N}(\\mu t, \\sigma^2 t) \\mathcal{N}(u, \\eta) d \\mu \\\\\n= & \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2 \\pi \\sigma^2 t}} \\exp \\left[ \\frac{\\left(x - \\mu t \\right)^2}{2 \\sigma^2 t} \\right] \\frac{1}{\\sqrt{2 \\pi \\eta^2}} \\exp \\left[ \\frac{\\left(\\mu - u \\right)^2}{2 \\eta^2} \\right] d \\mu \\\\\n= & \\frac{1}{\\sqrt{2 \\pi t ( \\eta^2 t + \\sigma^2 )}} \\exp \\left[ \\frac{\\left(x - u t \\right)^2}{2 t ( \\eta^2 t + \\sigma^2) } \\right] \\sim \\mathcal{N}(u t, t ( \\eta^2 t + \\sigma^2)) \\text{.}\n\\end{align}\n\\]\nIf \\(u\\) is the mean of the signal distribution (from which mean drift rates are drawn) and \\(v\\) is the mean of the noise distribution, \\(d'(t)\\) as a function of time \\(t\\) is simply:\n\\[\nd'(t) = \\frac{ut - vt}{ \\sqrt{t (\\eta^2 t + \\sigma^2)} } = \\frac{u - v}{\\eta \\sqrt{1 + \\frac{\\sigma^2}{\\eta^2 t}}} \\text{.}\n\\]\nThis is a negatively-accelerated function of time, and reaches an asymptote as \\(t \\rightarrow \\infty\\), \\(d'(t) \\rightarrow \\frac{u - v}{\\eta}\\). This formula for \\(d'\\) will prove useful in subsequent applications of the diffusion model to situations with nonstationary evidence distributions.\nFinally, we note the diffusion model predictions for response probabilities and latencies: Assuming that the process starts at some point \\(z &gt; 0\\) and \\(\\theta_1 &gt; z\\) and \\(\\theta_0 = 0\\), the probability of reaching \\(\\theta_0 = 0\\) (making a \\(H_0\\) decision) is\n\\[\n\\Pr ( H_0 | \\mu, z, \\theta_1, \\sigma ) = \\frac{ \\exp \\left( - \\frac{2 \\mu \\theta_1}{\\sigma^2} \\right) - \\exp \\left( - \\frac{2 \\mu z}{\\sigma^2} \\right)}{\\exp \\left( - \\frac{2 \\mu \\theta_1}{\\sigma^2} \\right) - 1}\n\\]\nwhile the probability density for times \\(t\\) at which \\(\\theta_0\\) is reached is\n\\[\nf_0 (t | \\mu, z, \\theta_1, \\sigma ) = \\frac{1}{\\Pr (H_0 | \\mu, z, \\theta_1, \\sigma)} \\frac{\\pi \\sigma^2}{\\theta_1^2} \\exp \\left( - \\frac{z \\mu}{\\sigma^2} \\right) \\sum_{k=1}^{\\infty} k \\sin \\left( \\frac{\\pi z k}{\\theta_1} \\right) \\exp \\left[- \\frac{1}{2} t \\left( \\frac{\\mu^2}{\\sigma^2} + \\frac{\\pi^2 k^2 \\sigma^2}{\\theta_1^2} \\right) \\right] \\text{.}\n\\]\nThe probability of making a \\(H_1\\) response is simply \\(1 - \\Pr (H_0 | \\mu, z, \\theta_1, \\sigma )\\) while the density for response times given an \\(H_1\\) response is\n\\[\n\\begin{align}\nf_1 (t | & \\mu, z, \\theta_1, \\sigma ) = \\\\\n& \\frac{1}{\\Pr (H_1 | \\mu, z, \\theta_1, \\sigma)} \\frac{\\pi \\sigma^2}{\\theta_1^2} \\exp \\left( \\frac{(\\theta_1 - z) \\mu}{\\sigma^2} \\right) \\sum_{k=1}^{\\infty} k \\sin \\left( \\frac{\\pi (\\theta_1 - z) k}{\\theta_1} \\right) \\exp \\left[ \\frac{1}{2} t \\left( \\frac{\\mu^2}{\\sigma^2} - \\frac{\\pi^2 k^2 \\sigma^2}{\\theta_1^2} \\right) \\right] \\text{.}\n\\end{align}\n\\]\nThese reaction time distributions are positively-skewed, as is usually observed in reaction time distributions. More “difficult” decisions, in which \\(u\\) and \\(v\\) do not differ substantially, thus reducing the absolute value of \\(\\mu\\), will naturally result not only in longer reaction times, but more skewed reaction times according to the diffusion model.\n\n\n2.1.4 Optimality and Multiple Alternatives\nThe Wiener diffusion process, as a natural extension of the SPRT, can be shown to be the optimal decision strategy when there are two alternatives and the evidence-generating distribution is stationary and perturbed by Gaussian noise (Bogacz et al., 2006). The diffusion model can be extended to model choices between more than two alternatives by extending the Wiener process into multiple dimensions (Smith, 2000). If the decision thresholds are orthogonal to one another (which might occur if they are parallel to the coordinate axes), a multidimensional diffusion essentially becomes a parallel race model (see below). While this extension is not conceptually difficult, it runs into the problem that a diffusion in more than two dimensions is no longer guaranteed to eventually hit every point in the state space. Thus, it is far harder to calculate the probability of a multidimensional diffusion process hitting a boundary, let alone the density of its first passage times. There are cases, however, where a multidimensional diffusion may be reduced a more tractable one in a single dimension (Ashby, 2000; Smith, 2000).\nInstead of treating a decision between multiple alternatives as a multidimensional diffusion, it can be explicitly modeled as a set of simultaneous diffusions that independently accumulate evidence for each alternative. Just as the unidimensional diffusion is equivalent to the SPRT, a set of \\(M\\) parallel diffusions is related to the “\\(M\\)-ary Sequential Probability Ratio Test” [MSPRT; Baum & Veeravalli (1994)]. The MSPRT has no single optimal decision rule, but one candidate procedure is to choose option \\(H_k\\) when its posterior probability given the evidence \\(X\\) up to time \\(t\\), \\(\\Pr (H_k | X_t)\\), exceeds a threshold level of probability. This threshold is equal to the expected hit rate, conditioned on response \\(H_k\\). This rule is optimal to the extent that it produces a decision with the desired level of accuracy in the shortest time (Bogacz & Gurney, 2007; Jones et al., 2009; Zhang & Chang, in review).\nTo formally express the diffusion version of the MSPRT, recall that Bayes rule relates the posterior probability of a hypothesis \\(H_k\\) to the likelihood, prior, and evidence: \\[\n\\Pr (H_k | X_t) = \\frac{\\Pr (X_t | H_k) \\Pr (H_k)}{\\sum_{i=1}^M \\Pr (X_t | H_i) \\Pr (H_i)} \\text{.}\n\\] Taking the logarithm of the above yields \\[\n\\log \\Pr (H_k | X_t) = \\log \\Pr (X_t | H_k) + \\log \\Pr (H_k) - \\log \\left[ \\sum_{i=1}^M \\exp \\left( \\log \\Pr (X_t | H_i) + \\log \\Pr (H_i) \\right) \\right] \\text{.}\n\\] Assuming, as we have all along, that evidence arrives sequentially and is sampled independently from a stationary evidence-generating distribution, we can let \\(L_k(t) = \\sum_{i=0}^t \\log \\Pr (x_i | H_k) + \\log \\Pr (H_k)\\), such that \\(\\Delta L_k(t) = \\log \\Pr (x_t | H_k) \\Delta t\\). Finally, by assuming that the likelihood functions are Gaussian and that \\(\\Delta t \\rightarrow 0\\), we obtain a Wiener drift-diffusion process for each alternative. The decision rule for the multi-alternative diffusion model thus requires that the aggregate state for an option \\(k\\) be sufficiently large relative to the sum of the aggregate states of all alternatives. Thus, while evidence may accumulate for each alternative independently and in parallel, the alternatives compete with each other in order to actually produce a decision. In the two-alternative case, the predictions are identical to the standard SPRT (and, thus, to the unidimensional diffusion model), in which only two alternatives compete with one another. This extension of the diffusion model to multiple alternatives can be made even more powerful by assuming that the decision maker must infer the underlying mean drift rates for each option, leading to a rational explanation for certain trial-order effects (Jones et al., 2009).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Historical Perspectives</span>"
    ]
  },
  {
    "objectID": "history.html#counter-and-accumulator-models",
    "href": "history.html#counter-and-accumulator-models",
    "title": "2  Historical Perspectives",
    "section": "2.2 Counter and Accumulator Models",
    "text": "2.2 Counter and Accumulator Models\nThe extension of the diffusion model to multiple alternatives leads directly into a potentially more general class of models for response dynamics, namely, the counter or accumulator models. The two-alternative SPRT, random walk, and diffusion models necessarily consider evidence for one alternative to be equal evidence the other alternative. This is also the case when there are more than two alternatives. However, there are situations in which it does not make sense to consider strict competition among alternatives. Consider a situation in which you are choosing between two desserts of equal price, the key lime pie and the German chocolate cake. The fact that you like coconut might increment your preference for German chocolate cake, but it is hard to see why it should reduce your preference for key lime pie. You may have different degrees of preference for either option, and that difference may drive your eventual decision, but there is no reason to think your preferences should be anti-correlated, as is assumed by the models we have considered thus far.\n\n2.2.1 Counter Models\n“Counter” models are so called because, in their original form, each choice alternative was presumed to be associated with a count of the number of “pieces” of evidence in favor of it, and the corresponding response would be made when one counter reached a threshold. The first such model was by LaBerge (1962), in which time progressed in discrete intervals of equal size. On each time-step, a single “piece” of evidence was added to a counter representing one of the possible alternatives, and a final decision made when one of the counters reaches a threshold. In other words, each alternative “races” to reach its threshold and produce a response.\nTwo (not mutually exclusive) ways to extend the counter model are apparent: First, to make the state space (the possible evidence values) continuous, rather than discrete; and second, to make time continuous rather than discrete. The accumulator model of Vickers (1970) and Smith & Vickers (1988) assumes that time remains discrete while the values of evidence may take on continuous values, perhaps from a truncated normal or exponential distribution. The parameters of each distribution reflect the amount of evidence for each alternative, and the thresholds on each accumulator reflect response biases. Alternatively, the Poisson counter model (Pike, 1973; Smith & Van Zandt, 2000; Townsend & Ashby, 1983) assumes that the amount of evidence accumulated at any one time is fixed, but the interarrival times for that evidence are variable. Specifically, they are sampled independently from an exponential distribution, with rates that differ between accumulators. In the Poisson counter model, thresholds again reflect response biases, while the rate of arrivals to a particular counter corresponds to the amount of evidence in favor of that response. Thus, unless there is a bias against the correct response, the Poisson counter model will predict faster RT for correct responses than errors, no matter what sources of variability are added to the model (Ratcliff & Smith, 2004).\nWhen \\(M\\) Poisson counters are running independently and in parallel with interarrival rates \\(\\lambda_1, \\lambda_2, \\dotsc, \\lambda_M\\), the entire decision process can be construed as a Poisson process with a rate that is the sum of the rates of the individual accumulators, \\(\\lambda_1 + \\lambda_2 + \\dotsb + \\lambda_M\\) (Townsend & Ashby, 1983). Thus, regardless of the final choice, if it is reached after \\(N\\) counts have accumulated across all the counters, the RT distribution is a Gamma distribution: \\[\nf (t | N, \\lambda_1, \\lambda_2, \\dotsc, \\lambda_M) = \\left(\\sum_{i=1}^M \\lambda_i \\right)^{-N} \\exp \\left( -\\frac{t}{\\sum_{i=1}^M \\lambda_i} \\right) \\frac{t^{N-1}}{\\left(N - 1 \\right)!} \\text{.}\n\\] This has two important consequences: First, RT distributions are predicted to become less skewed as the mean number of samples \\(N\\) increases (the skewness of a Gamma distribution is \\(\\frac{2}{\\sqrt{N}}\\)), which is not supported by most empirical RT distributions. More importantly, however, RT is predicted to be faster with increasing number of alternatives, owing to the fact that each counter contributes \\(\\lambda_i\\) to the overall processing rate. This is a general property of models with independent parallel accumulators for each decision, regardless of the choice of distributions or parameters (Townsend & Ashby, 1983). There are many situations, however, in which increasing the number of alternative responses (and thus the number of parallel accumulators) results in an increase in reaction time. This can limit the utility of parallel counter models to account for observed response dynamics unless accumulation rates decrease with the number of accumulators (Ratcliff & Smith, 2004; Teodorescu & Usher, 2013).\n\n\n2.2.2 Partially Correlated Accumulators\nIf random walk and diffusion models involve accumulators for each alternative that are perfectly anticorrelated, and counter/accumulator models posit accumulators that are totally uncorrelated, perhaps a middle ground might be found? The Leaky, Competing Accumulator model (LCA, Usher & McClelland, 2001) is one such example. In this model, each of the \\(M\\) accumulators is presumed to be subject to Gaussian noise and can be described by the following differential equation: \\[\nd L_i(t) = \\left( I_i - \\gamma L_i(t) - \\beta \\sum_{j \\neq i}^M L_j(t) \\right) dt + \\sigma \\mathcal{N}(0, 1) \\sqrt{dt} \\text{.}\n\\] This equation has several terms that we now parcel out: \\(I_i\\) is the exogenous (stimulus-driven) input to accumulator \\(i\\), analogous to the drift rate in a diffusion; the \\(-\\gamma L_i(t)\\) term implements “leakage”, similar to an OU process (see below) when \\(0 \\leq \\gamma \\leq 1\\); \\(\\beta \\sum_{j \\neq i}^M L_j(t)\\) implements a (partial) negative correlation between accumulators; and the final term is simply the familiar Gaussian noise term. There is, further, a critical nonlinearity in the model, namely, that \\(L_i\\) is never permitted to be negative. The theoretical consequence of this is that accumulators can only act to inhibit one another. The practical consequence is that the LCA model is not analytically tractable, although it can be approximated by two OU processes in the two-accumulator case (Bogacz et al., 2007; Usher & McClelland, 2001). This nonlinearity may, however, prove advantageous by reducing excessive inhibition from poor choices (Bogacz et al., 2007).\nIf this nonlinearity is ignored, the LCA can be made identical, at least in the two-alternative case, to a race model (by letting \\(\\gamma = \\beta = 0\\)), to a diffusion model (by letting \\(\\gamma = 0\\) and \\(\\beta = 1\\)), or to an OU process (by letting \\(\\beta = 1\\)). Thus, it has great flexibility in predicting a variety of patterns of reaction time and accuracy, especially when incorporating payoffs (Usher & McClelland, 2004).\n\n\n2.2.3 Ballistic Accumulators\nAlthough they will not be addressed subsequently, we briefly alight on a recent set of models that are “ballistic” in the sense that they are completely deterministic, once their initial conditions (parameters, starting points, and thresholds) are set. The first of these was proposed by Brown & Heathcote (2005) as a non-stochastic version of the LCA model. It is nonetheless able to account for decision data because, although the within-trial dynamics of the model are deterministic, it is subject to between-trial noise. In particular, the exact external input to each accumulator is perturbed by Gaussian noise on each trial, and the initial value of each accumulator is randomly sampled from a uniform distribution. Brown & Heathcote (2008) extend this idea to the diffusion model in the Linear Ballistic Accumulator (LBA). This, too, is able to account for observed reaction time and accuracy data quite well (Donkin et al., 2011).\nSequential sampling models rely on the idea that at any one time, evidence may be noisy, and so to make accurate decisions, noisy evidence samples must be integrated over time. What, then, are we to make of the idea that ballistic models without noisy evidence can still fit data? I argue that it is a question of interpretation: Sequential sampling models, from the SPRT to the diffusion model, attempt to model what is thought to be the “real” state of the world: that evidence itself is noisy. Ballistic models, on the other hand, are best thought of as “measurement models”, in that they re-describe or summarize the data (accuracy and reaction time) in a way that makes it amenable to cognitive interpretation. The fact that, by abandoning the notion of sampling noise, ballistic models are still able to fit data should not worry anyone: Ballistic models are trying to describe the data by making as few assumptions as possible, while stochastic models are trying instead to describe the underlying state of the world.\n\n\n\n\nAshby, F. G. (1983). A biased random walk model for two choice reaction times. Journal of Mathematical Psychology, 27, 277–297.\n\n\nAshby, F. G. (2000). A stochastic version of general recognition theory. Journal of Mathematical Psychology, 44, 310–329.\n\n\nBaum, C. W., & Veeravalli, V. V. (1994). A sequential procedure for multihypothesis testing. IEEE Transactions on Information Theory, 40(6), 1994–2007.\n\n\nBogacz, R., Brown, E., Moehlis, J., Holmes, P., & Cohen, J. D. (2006). The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks. Psychological Review, 113(4), 700–765.\n\n\nBogacz, R., & Gurney, K. (2007). The basal ganglia and cortex implement optimal decision making between alternative actions. Neural Computation, 19, 442–477.\n\n\nBogacz, R., Usher, M., Zhang, J., & McClelland, J. L. (2007). Extending a biologically inspired model of choice: Multi-alternatives, nonlinearity and value-based multidimensional choice. Philosophical Transactions of the Royal Society B, 362, 1655–1670.\n\n\nBrown, S., & Heathcote, A. (2005). A ballistic model of choice response time. Psychological Review, 112(1), 117–128.\n\n\nBrown, S., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive Psychology, 57, 153–178.\n\n\nDonkin, C., Brown, S., Heathcote, A., & Wagenmakers, E.-J. (2011). Diffusion versus linear ballistic accumulation: Different models but the same conclusions about psychological processes? Psychonomic Bulletin & Review, 55, 140–151.\n\n\nEdwards, W. (1965). Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing. Journal of Mathematical Psychology, 2, 312–329.\n\n\nJones, M., Mozer, M., & Kinoshita, S. (2009). Optimal response initiation: Why recent experience matters. In D. Koller, D. Schuurmans, Y. Bengio, & L. Bottou (Eds.), Advances in neural information processing systems (Vol. 21, pp. 785–792).\n\n\nLaBerge, D. (1962). A recruitment theory of simple behavior. Psychometrika, 27(4), 375–396.\n\n\nLink, S. W. (1975). The relative judgment theory of two choice response time. Journal of Mathematical Psychology, 12, 114–135.\n\n\nLink, S. W., & Heath, R. A. (1975). A sequential theory of psychological discrimination. Psychometrika, 40, 77–105.\n\n\nMacmillan, N. A., & Creelman, C. D. (2005). Detection theory: A user’s guide (2nd ed.). Erlbaum.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231, 289–337.\n\n\nPike, R. (1973). Response latency models for signal detection. Psychological Review, 80(1), 53–68.\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108.\n\n\nRatcliff, R., & Smith, P. L. (2004). A comparison of sequential sampling models for two-choice reaction time. Psychological Review, 111(2), 333–367.\n\n\nSmith, P. L. (2000). Stochastic dynamic models of response time and accuracy: A foundational primer. Journal of Mathematical Psychology, 44(3), 408–463.\n\n\nSmith, P. L., & Van Zandt, T. (2000). Time-dependent Poisson counter models of response latency in simple judgment. British Journal of Mathematical and Statistical Psychology, 53, 293–315.\n\n\nSmith, P. L., & Vickers, D. (1988). The accumulator model of two-choice decision. Journal of Mathematical Psychology, 32, 135–168.\n\n\nStone, M. (1960). Models for choice-reaction time. Psychometrika, 25, 251–260.\n\n\nSwensson, R. G., & Green, D. M. (1977). On the relations between random walk models for two-choice response times. Journal of Mathematical Psychology, 15, 282–291.\n\n\nTeodorescu, A. R., & Usher, M. (2013). Disentangling decision models: From independence to competition. Psychological Review, 120(1), 1–38.\n\n\nTownsend, J. T., & Ashby, F. G. (1983). Stochastic modeling of elementary psychological processes. Cambridge University Press.\n\n\nUsher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological Review, 108(3), 550–592.\n\n\nUsher, M., & McClelland, J. L. (2004). Loss aversion and inhibition in dynamical models of multialternative choice. Psychological Review, 111(3), 757–769.\n\n\nVickers, D. (1970). Evidence for an accumulator model of psychophysical discrimination. Ergonomics, 13(1), 37–58.\n\n\nWald, A. (1945). Sequential tests of statistical hypotheses. The Annals of Mathematical Statistics, 16(2), 117–186.\n\n\nZhang, J., & Chang, M. (in review). A Bayesian random-walk model of choice reaction times under prior knowledge of target onset uncertainty. Proceedings of the National Academy of Sciences.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Historical Perspectives</span>"
    ]
  },
  {
    "objectID": "random_walk.html",
    "href": "random_walk.html",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "3.1 Out for a random walk\nYou are in a bind. There are two piles of hay in front of you. They look pretty similar in size. You are hungry. Which of the two piles do you walk toward? I should also mention that you are a donkey, so this is pretty important to you! (The deliberating donkey shown above, Simon, is the resident donkey at Indian Ladder Farms near Albany, NY.)\nThe situation described above is a version of the parable of Buridan’s ass. In the parable, the unfortunate ass is unable to come to a decision because the two piles of hay are equally large, meaning he has no basis for choosing between them. As a result, the donkey starves to death.\nIn this chapter, we will build a model of two-choice behavior that rescues Buridan’s donkey from this dire fate. This model is called a random walk. As we will see, this model can be applied to any situation involving a choice between two options. The random walk model instantiates all four of the key constructs described in the Introduction. It is also a great example of the general structure of a computational cognitive model, in that it describes how an observable action (a choice) arises by applying a process of accumulation to a representation of the balance of evidence between the two options.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#out-for-a-random-walk",
    "href": "random_walk.html#out-for-a-random-walk",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "",
    "text": "3.1.1 Representing the current state of evidence\nThe random walk model assumes that, at any given time, a decision maker represents the current balance of evidence between two options as a number. We will creatively refer to this representation as \\(x(t)\\), where \\(x\\) stands for evidence and \\((t)\\) stands for the fact that it is the evidence at a specific time \\(t\\). The sign and magnitude of \\(x(t)\\) represents the extent to which the current value of evidence favors one option over the other.\nIf \\(x(t)\\) equals zero, then the evidence at time \\(t\\) does not favor either option. This is akin to the situation when Buridan’s ass first encounters the two piles of hay. If \\(x(t) &gt; 0\\), then the evidence favors one of the two options. For Buridan’s ass, perhaps positive values of evidence represent evidence in favor of going toward the pile of hay on the right. If \\(x(t) &lt; 0\\), then the evidence favors the other option. For Buridan’s ass, maybe negative values of evidence represent evidence in favor of going toward the pile of hay on the left. Notice that we could just as easily do it the other way around: positive evidence favors going left while negative evidence favors going right. The important thing is just that the two options are associated with opposite signs of evidence.\nIn a cognitive task, the two choices might be “word” and “non-word” in a lexical decision task, “old” and “new” in a recognition memory task, “present” and “absent” in a visual search task, “same” and “different” in a change detection task, “category A” and “category B” in a categorization task, etc. Again, the point is that, at any given time, the degree to which the decision maker’s accumulated evidence at time \\(t\\) favors one option or the other is represented by the value of a number \\(x(t)\\), with each option associated with opposite signs.\n\n\n3.1.2 Accumulating evidence\nThe value of \\(x(t)\\) represents the evidence that has been accumulated by time \\(t\\). But what does it mean to “accumulate” evidence? And what is the “evidence” that is accumulated?\nIn a random walk model, we assume that at regular time intervals (each interval has duration \\(Delta t\\)), the decision maker receives a “sample” of evidence, which we will label \\(\\Delta x(t)\\). This sample can take one of two values, \\(+1\\) or \\(-1\\). If it is \\(+1\\), the sample favors the option associated with positive evidence values (e.g., the pile of hay on the right) and if it is \\(-1\\), the sample favors the option associated with negative evidence values (e.g., the pile of hay on the left). To accumulate evidence means to add the new sample \\(\\Delta x(t)\\) to the current value of the accumulated evidence, i.e.: \\[\n\\overbrace{x(t + \\Delta t)}^{\\text{Updated evidence}} = \\overbrace{x(t)}^{\\text{Current accumulated evidence}} + \\overbrace{\\Delta x(t)}^{\\text{Current sample of evidence}}\n\\] Thus, the accumulated evidence \\(x(t)\\) is the sum of all the samples of evidence that were obtained by time \\(t\\).\n\n\n3.1.3 What is evidence?\nAt this point, it would be reasonable to ask where these samples of evidence come from. There is no single answer to this question because the random walk model, like most of the models of choice and RT we will consider, treats evidence in a very abstract sense. To return to Buridan’s ass, the evidence might be perceptual in nature: For an interval of time, the donkey looks at both piles of hay. Even though both piles are, by assumption, equally big, that may not always be visually apparent. During any finite interval of time, one pile might happen to look ever so slightly larger than the other, perhaps due to a quirk of the light, a sheaf fluttering in the breeze, the donkey’s visual acuity, etc. If the pile on the right happened to look a bit bigger than the one on the left during one of those intervals, then the sample of evidence for that interval would be \\(+1\\). Otherwise, it would be \\(-1\\). Because these minute differences are due to essentially chance factors, and they are equally likely to favor either pile, we can say that the probability of getting a sample that is either \\(+1\\) or \\(-1\\) is \\(0.5\\). While the evidence might not favor one pile over the other in the long run, it will favor one option over a finite interval of time, which is all any real decision maker has at their disposal. As we shall see shortly, this is the key to saving Buridan’s ass.\nTreating evidence as due, at least in part, to chance factors is why this model is called a “random” walk. It also highlights the fact that the evidence samples need not occur with equal frequency. Perhaps samples come up \\(+1\\) with probability \\(p\\) and otherwise come up \\(-1\\), like the proverbial biased coin flip. If the evidence consistently favors one option, that means that \\(p\\) is close to either 1 or 0. To the extent that chance factors influence the evidence, \\(p\\) will be closer to \\(0.5\\). We have now been introduced to the first parameter of the random walk model: \\(p\\), the probability of getting a sample of evidence that favors the option associated with positive evidence.\nThe figure below illustrates different ways that evidence might accumulate over time. Each step up or down is driven by the sample of evidence that was obtained at that time, which is assumed to be random with probability \\(p\\). The figure also illustrates why this model is called a random “walk”, because each trajectory kind of looks like a path that someone might have walked.\n\n\nCode\nexpand_grid(p = c(0.2, 0.5, 0.8), sim_index = 1:5, t = 1:20) %&gt;%\n    mutate(x_sample = 2 * rbinom(n = n(), size = 1, prob = p) - 1) %&gt;%\n    group_by(p, sim_index) %&gt;%\n    mutate(x_accum = cumsum(x_sample)) %&gt;%\n    ggplot(aes(x = t, y = x_accum, color = factor(p), group = interaction(p, sim_index))) +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_step(alpha = 0.5) +\n    labs(x = \"Time interval\", y = \"Accumulated evidence\", color = \"p\")\n\n\n\n\n\n\n\n\n\nWhat about evidence in cognitive tasks? Buridan’s ass relies on the same kind of sensory evidence as one needs to do, for example, psychophysical tasks like picking which stimulus is brighter, more leftward-oriented, etc. Evidence derived from memory can also be noisy—perhaps when retrieving an event, you sometimes recall the color of an object as blue and sometimes as green. When deciding between different gambles or products, we may also shift attention to different features of those options, leading us to judge them as better or worse depending on which features we attend to (Busemeyer & Townsend, 1993).\n\n\n3.1.4 Doing some code\nHaving now familiarized ourselves with how the random walk model represents a decision maker’s evidence and how it processes that evidence via accumulation, let’s see how we would write that model in code. Specifically, we will be writing code that simulates different possible random walks. The way we will do this is more of an intellectual exercise, since we will not be striving for efficiency (later on, we will use special-purposes R packages for that). Rather, the point here is to see how the conceptual aspects of a model can be implemented in code. We will add on to this code as we go.\nFor now, we know that we will have a line that looks something like the accumulation equation above:\n\n\nCode\nx &lt;- x + x_sample\n\n\nHere, x stands for the value of the accumulated evidence and x_sample stands for the current sample of evidence (which is either 1 or -1). The &lt;- evaluates the expression on the right and assigns it to the thing on the left, so the code above says “take the current value of x, add the new sample x_sample, and put it back as the new value of x”.\nWith the code above as the core of the model, we now need to do three things: first, specify how to get x_sample; second, obtain many such samples; third, keep a record of how the accumulated evidence changes over time.\n\n3.1.4.1 Sampling evidence\nTo get a value for x_sample, we will use R’s rbinom function, which generates a random sample from a binomial distribution. Specifically, the line rbinom(n = 1, size = 1, prob = 0.5) will generate a sample that equals 1 with probability 0.5, otherwise it equals zero. It is perhaps easiest to think of it in terms of a coin flip: The n parameter of the rbinom function says how many samples to draw, size says how many coins we flip at once, and prob is the probability that any single flip comes up heads. The number that rbinom gives is the number of heads per sample.\nFor Buridan’s ass, the sample of evidence favors each pile equally often, so prob = 0.5 makes sense. Note that because rbinom returns either a 0 or a 1, we need to do some math to turn the result into \\(+1\\) or \\(-1\\). This is shown below.\n\n\nCode\nx_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\nx &lt;- x + x_sample\n\n\n\n\n3.1.4.2 Obtaining many samples\nThere are a few ways we can write code that will obtain many samples. To anticipate what we will be doing later, we will use the while control structure. We can use it to specify a condition such that, so long as the condition is met, a block of code will continue to be executed in a loop.\nOur condition will depend on the current time. Remember that, in the random walk, each sample of evidence arrives at fixed intervals of time. We will therefore need to keep track of the current time as well as the accumulated evidence. Similar to how we updated the evidence, we will need to keep track of t, the current time. We will also need to specify dt, the duration of each interval, and t_max, the amount of time to keep accumulating evidence.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\nNotice that we specified values for t_max and dt outside the while loop. We can specify initial values for x and t the same way:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n}\n\n\n\n\n3.1.4.3 Keeping a record\nThe chunk of code above will work just fine! But unfortunately it does not leave a record of accumulated evidence over time that we can then examine, like we did with the graph above. In the chunk below, we use a fun trick to keep a record of each value of x and t: We create two vectors x_record and t_record and use the c function to append the current values of x and t to these vectors:\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\n\n\n\n3.1.4.4 Visualizing the record\nNow that we are keeping a record of evidence over time, let’s visualize it! The code below uses base R for that purpose, although the graph above uses ggplot2 which we will use again later. The type = \"s\" setting in the plot function at the end give the “step-like” plot.\n\n\nCode\nt_max &lt;- 5\ndt &lt;- 0.05\n\nx &lt;- 0\nt &lt;- 0\n\nx_record &lt;- x\nt_record &lt;- t\n\nwhile (t &lt; t_max) {\n    x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = 0.5) - 1\n    x &lt;- x + x_sample\n    t &lt;- t + dt\n    x_record &lt;- c(x_record, x)\n    t_record &lt;- c(t_record, t)\n}\n\nplot(t_record, x_record, type = \"s\", xlab = \"Time\", ylab = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nTry copy-pasting the code above and running it yourself a few times to see what it looks like!\n\n\n3.1.4.5 Making a function\nIf we have a chunk of code that we want to re-run many times, we would do better to write a function that we can call instead of having to re-run the whole chunk. Writing a function also makes it easier to deal with parameters that can have different settings, like dt and t_max. We will also make the probability \\(p\\) a parameter too. Finally, the values for these three parameters in the function line are defaults.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, dt = 0.05, t_max = 5) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nNow we can call the function rw_sim with different settings to simulate different random walks. Note that, because the function returns t_record and x_record as different columns of a data.frame, we can easily use ggplot2 to plot the results, as in the examples below.\n\n\nCode\nsim_result1 &lt;- rw_sim(p = 0.5, dt = 0.05, t_max = 5)\n\nsim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result2 &lt;- rw_sim(p = 0.2, dt = 0.05, t_max = 5)\n\nsim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.2\")\n\n\n\n\n\n\n\n\n\nCode\nsim_result3 &lt;- rw_sim(p = 0.8, dt = 0.05, t_max = 5)\n\nsim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.8\")\n\n\n\n\n\n\n\n\n\nGo ahead, try it out yourself with different values of p, dt, and/or t_max. It’s fun! And if you don’t think the step graphs are too interesting, just imagine that each of those steps is Simon the donkey trying to decide between his two piles of hay.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#making-a-decision",
    "href": "random_walk.html#making-a-decision",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.2 Making a decision",
    "text": "3.2 Making a decision\nSo far, we have built a simple model of evidence accumulation. In this model, samples of “evidence” arrive at regular intervals, with the sample supporting either one option (\\(+1\\)) or the other (\\(-1\\)) with probability \\(p\\), and the decision maker accumulates these samples by summation. The resulting accumulated evidence thus starts at zero and takes a “random walk” that can drift upward (if \\(p &gt; 0.5\\)), downward (if \\(p &lt; 0.5\\)), or in no particular direction (if \\(p = 0.5\\)).\n\n3.2.1 Response boundaries\nWhat we have not done is say how the decision maker uses this accumulated evidence to decide between their two options. According to the random walk model, the decision maker sets two values prior to accumulating evidence. These values are called thresholds, criteria, or boundaries (these terms are often used interchangeably). There is one positive boundary and one negative boundary. If and when the accumulated evidence crosses one of these boundaries, the decision maker selects the corresponding option.\nFor example, say that Buridan’s ass will pick the pile on the right if his accumulated evidence ever gets greater than \\(+5\\) and he will pick the pile on the left if his accumulated evidence ever gets less than \\(-5\\). We can visualize this situation by overlaying lines at those two boundaries on the “random walk” of accumulating evidence:\n\n\nCode\nburidan_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nHere’s another one:\n\n\nCode\nburidan_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nGo ahead and try it out yourself!\nThe point is that we can read from these graphs which option the donkey ends up picking by seeing which boundary gets crossed first. We can also see when the donkey makes his decision based on how long it took for that first boundary-crossing to occur. This is how the random walk model ultimately produces both a choice (which boundary was crossed first) and an RT (how long it took). It is also why the random walk saves Buridan’s ass: Even if the evidence in the long run does not favor either option, by chance the accumulated evidence will at some point cross one of the boundaries, enabling the donkey to make a decision.\n\n\n3.2.2 Response bias\nIn the examples above, Buridan’s ass set his response boundaries to be of equal distance from the initial evidence value of zero. Burdian’s ass might be more willing to go to the leftward pile than the rightward one—maybe it is more aesthetically appealing or the donkey has a limp that makes it easier for him to walk left than right. This would amount to a bias in favor of one option (going left) over the other (going right).\nWe can instantiate this bias in the random walk model via the donkey’s response boundaries. For example, the donkey may go to the left if the accumulated evidence ever gets less than \\(-4\\) but would only be willing to go to the right if the accumulated evidence ever gets greater than \\(+6\\). The following two graphs illustrate these biased response boundaries.\n\n\nCode\nburidan_bias_sim1 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 1\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nburidan_bias_sim2 &lt;- rw_sim(p = 0.5)\n\nburidan_bias_sim2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Response bias, simulation 2\")\n\n\n\n\n\n\n\n\n\nIntuitively, it seems reasonable to expect that, if one boundary is closer to the start than the other, that two things will happen: First, the option associated with the closer boundary will be picked more often (at least if the evidence against that option is not too strong). Second, the decision maker will tend to be faster to pick the option associated with the closer boundary. We will verify these intuitions later, but for now you can rest assured that these intuitions are correct.\n\n\n3.2.3 Revising our function\nNow that we have gotten acquainted with the notion of response boundaries and how they can be biased, let’s incorporate them into our random walk simulation function from earlier. This will involve two things: First, we will need to add two parameters to the function, one for each boundary. Second, we will need to change the condition in the while loop so that the random walk stops when it reaches a boundary. As a corrollary to this second step, we will keep the t_max condition but adjust the default value of t_max.\nThe revised function is shown below, with some additional explanation following:\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- 0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe key changes we made to the rw_sim function are:\n\nAdding parameters b_upper and b_lower for the upper and lower response boundaries, respectively.\nChanging the default value of t_max to Inf for “infinity”. This means that, by default, reaching a boundary is the only way the random walk will stop. However, by leaving t_max as a parameter, it means that we can set it to some real number like 5 or 10 to force the random walk to stop eventually.\nChanging the condition in the while loop. Now the walk will continue so long as the evidence x is below the upper boundary (x &lt; b_upper) and above the lower boundary (x &gt; b_lower) and so long as the maximum time hasn’t been reached (t &lt; t_max). Note that the & is a “logical and” operator.\n\nHere are a few simulation runs—try it out yourself!\n\n\nCode\nboundary_sim_result1 &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5)\n\nboundary_sim_result1 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 5, b_lower = -5\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result2 &lt;- rw_sim(p = 0.5, b_upper = 6, b_lower = -4)\n\nboundary_sim_result2 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.5, b_upper = 6, b_lower = -4\")\n\n\n\n\n\n\n\n\n\nCode\nboundary_sim_result3 &lt;- rw_sim(p = 0.7, b_upper = 6, b_lower = -4)\n\nboundary_sim_result3 %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    geom_hline(yintercept = c(-4, 6), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"p = 0.7, b_upper = 6, b_lower = -4\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#residual-time",
    "href": "random_walk.html#residual-time",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.3 Residual time",
    "text": "3.3 Residual time\nWe are nearly done with our simulation model! We can model accumulating evidence and making a decision. The final ingredient arises from the fact that, while a decision maker might select one option at a particular time, we can only observe the behavioral consequences of that decision. Those behavioral consequences might be hitting a key, clicking a button, pressing a lever, or walking toward a pile of hay. Executing that behavior takes time in addition to the time needed to accumulate evidence and reach a response boundary. That additional time goes by many names, often “non-decision time” (NDT) or “encoding and responding” time (\\(T_{ER}\\)), but I prefer to simply call it residual time.\nFor now, we will adopt a simple assumption that this residual time is constant. Therefore, the observed response time will be the sum of the time needed for the random walk to reach a boundary plus the residual time associated with all the other processes that are involved in taking an action but which our model doesn’t explicitly enumerate.\nTo make this concrete, let’s introduce a parameter called t0 that will stand for residual time. While I cannot speak to what a plausible value of t0 would be for Buridan’s ass, in many cognitive tasks, it tends to be around 0.2 or 0.3 seconds, to account for the time needed to execute a simple motor action like hitting a button.\n\n\nCode\nrw_sim &lt;- function(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- 2 * rbinom(n = 1, size = 1, prob = p) - 1\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nNote that the main change to our rw_sim function is that the initial value for the time t is no longer 0 but t0, i.e., the value of the residual time parameter.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#simulating-many-trials",
    "href": "random_walk.html#simulating-many-trials",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.4 Simulating many trials",
    "text": "3.4 Simulating many trials\nOur rw_sim function can now simulate single realizations of a random walk decision process. As we have seen, though, each realization of this process is different because the samples of evidence are random. If we want to get a sense of the kind of behavior the model tends to produce, we need to simulate many realizations of the decision and examine the distribution of choices and RT’s produced by the model. This is the same reason why, in a typical cognitive task, we collect multiple trials from each participant in each condition. With a real participant, we are limited by the time and energy that a participant is willing to commit. With a model, we are still limited by time and energy, but they are our time and the computer’s energy. Nonetheless, it is worth keeping in mind that all the techniques below for visualizing choices and RT’s apply to observed data as well as they apply to simulated data.\n\n3.4.1 Running and saving many simulation results\nWe will need to write some code that repeatedly calls our rw_sim function a large number of times and saves the results so we can examine them later. What follows is not necessarily the most efficient way of accomplishing those goals, but it is conceptually transparent and introduces the for loop. The comments (following the # marks) explain what is going on with the line below.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Get a quick sense of what the results look like\nglimpse(sim_results)\n\n\nRows: 25,884\nColumns: 3\n$ t         &lt;dbl&gt; 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, …\n$ x         &lt;dbl&gt; 0, -1, -2, -3, -2, -3, -4, -3, -2, -3, -4, -3, -4, -3, -2, -…\n$ sim_index &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, …\n\n\n\n\n3.4.2 Visualizing the random walks\nWhat we are about to do may be a bit silly but helps build some intuitions about what is going on in the model. We are going to make a plot that overlays all 1000 simulated random walks on top of each other. The point is to get a sense of how much variability there is from one realization to the next.\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x, group = sim_index)) +\n    geom_step(alpha = 0.1) +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\")\n\n\n\n\n\n\n\n\n\nOkay, maybe it is a bit silly after all. But it is possible to see that things “thin out” at longer times as more and more random walks end by hitting a boundary. If you check out the code that generates the plot, note how group = sim_index was used to make sure each individual simulation, indexed by sim_index, got its own step-line on the graph. Also note the use of alpha = 0.1 to make each line semi-transparent so they could be overlayed on one another.\nLet’s try a different approach to visualize the same thing, using a heatmap that indicates the relative frequency with which the accumulated evidence takes different values at different times:\n\n\nCode\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    geom_hline(yintercept = c(-5, 5), linetype = \"dashed\") +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\")\n\n\n\n\n\n\n\n\n\nAgain, what is important to see above is that all the random walks start at the same time and evidence value (the yellow region) and then “fan out” over time.\n\n\n3.4.3 Joint distributions of choice and RT\nWhat we visualized in the previous section are the internal states of the model, that is, how the model represents the decision maker’s current balance of evidence between their two options. Remember, though, that the model is ultimately judged on its externally-observable behavior, since that is all we have to compare it against. We are finally going to visualize the choices and response times produced by the model. As we shall see, however, there are a few ways to do this!\n\n3.4.3.1 Extracting choices and RT’s\nFor each simulation, the RT is the final value of t, since that is the time (plus residual time) at which the first boundary was crossed. Meanwhile, the choice is whether the evidence x is positive or negative. The chunk of code below takes our simulation results and extracts the final choices and RT from each simulation.\n\n\nCode\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\nglimpse(choice_rt)\n\n\nRows: 1,000\nColumns: 3\n$ sim_index &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ choice    &lt;fct&gt; lower, lower, lower, upper, upper, lower, upper, lower, uppe…\n$ rt        &lt;dbl&gt; 1.05, 2.35, 0.95, 0.75, 0.55, 2.45, 1.15, 0.45, 1.35, 3.25, …\n\n\n\n\n3.4.3.2 Joint frequency plot\nThe code below plots the frequency with which each choice (upper or lower) is made at different times. This kind of plot is not terribly common, but is a quick way to get a sense of both how often each choice is made as well as the shape of the distributions of RT’s.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_freqpoly(binwidth = 0.2) +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3.3 Conditional RT density\nThe code below plots the conditional density of the RT’s for each choice. This kind of plot is much more common, but doesn’t convey any information about the relative frequency with which different choices are made. Nonetheless, it illustrates how the random walk produces distributions of RT’s with a pronounced right skew, similar to RT distributions that are actually observed in choice tasks. Note that the conditional RT distributions for each choice are pretty similar to one another too.\n\n\nCode\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\")\n\n\n\n\n\n\n\n\n\n\n\n3.4.3.4 Quantile-probability plots\nIn the choice-RT modeling world, it is common to make “quantile-probability plots”, sometimes abbreviated to QP plots. These plots can be a bit confusing at first, but are useful because they convey information about choice proportions and RT distributions in a single graph.\nThe horizontal axis of a QP plot corresponds to the probability of having made a particular choice. In this case, that is the proportion of simulations that resulted in each choice. We can get that information in numerical form from our choice_rt data frame:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\n\n# A tibble: 2 × 3\n  choice     n p_resp\n  &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 upper    507  0.507\n2 lower    493  0.493\n\n\nThe vertical axis of a QP plot corresponds to different quantiles of the conditional RT distributions for each choice. Typically, those quantiles are the RT’s at the 10th, 30th, 50th, 70th, and 90th percentiles of the distribution. The reason for all of these quantiles is that they convey information about different aspects of the distribution: The 50th percentile, otherwise known as the median, conveys the central tendency. The 30th and 70th percentiles indicate where the “bulk” of the RT’s tend to fall. Finally, the 10th and 90th percentiles convey information about the lower and upper tails of the distribution, respectively. We can obtain those quantiles numerically like so:\n\n\nCode\nchoice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\n\n# A tibble: 10 × 2\n   choice  rt_q\n   &lt;fct&gt;  &lt;dbl&gt;\n 1 upper   0.55\n 2 upper   0.75\n 3 upper   1.05\n 4 upper   1.55\n 5 upper   2.65\n 6 lower   0.55\n 7 lower   0.85\n 8 lower   1.25\n 9 lower   1.75\n10 lower   2.75\n\n\nTo make a QP plot, we need to “join” together the response proportions and RT quantiles into the same data frame:\n\n\nCode\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q)\n\n\nJoining with `by = join_by(choice)`\n\n\n# A tibble: 10 × 4\n   choice     n p_resp  rt_q\n   &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 upper    507  0.507  0.55\n 2 upper    507  0.507  0.75\n 3 upper    507  0.507  1.05\n 4 upper    507  0.507  1.55\n 5 upper    507  0.507  2.65\n 6 lower    493  0.493  0.55\n 7 lower    493  0.493  0.85\n 8 lower    493  0.493  1.25\n 9 lower    493  0.493  1.75\n10 lower    493  0.493  2.75\n\n\nThat joined data frame can then be used as the basis for our QP plot:\n\n\nCode\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#putting-it-all-together",
    "href": "random_walk.html#putting-it-all-together",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.5 Putting it all together",
    "text": "3.5 Putting it all together\nWe have used R to build a random walk model of decision making, implemented via a function called rw_sim, that accumulates samples of evidence until the accumulated evidence reaches either an upper or lower boundary. This model depends on several parameters, of which the most theoretically important are:\n\np: The probability that any given sample of evidence favors the option associated with the upper response boundary.\nb_upper: The upper response boundary.\nb_lower: The lower response boundary.\nt0: Residual time.\n\nWe also saw different ways that we can visualize both the internal states and external behavior of the model. It may be useful at this point to put together everything we have done so far into a single chunk of code. This will make your own explorations of this model easier.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- rw_sim(p = 0.5, b_upper = 5, b_lower = -5, t0 = 0.2, dt = 0.05)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "random_walk.html#exercises",
    "href": "random_walk.html#exercises",
    "title": "3  Building a random walk model to simulate choice and RT",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\n\nSet the p parameter to something other than 0.5, so that the evidence tends to favor one option over the other. Do one set of simulations in which the response boundaries are equidistant from the starting value of 0 (you may need to play around to find values that you like). Do another set of simulations in which you keep the boundaries equidistant but make them closer to the starting point. What is the effect on the model’s choices and RT’s of having boundaries that are closer to the starting point?\nRun one set of simulations with the p parameter to 0.6 and the response boundaries equidistant from the starting point. Run another set of simulations keeping the response boundaries the same but increasing the p parameter to 0.8. What is the effect of increasing the p parameter on the RT distributions for making the “upper” choice? What is the effect of increasing the p parameter on the RT distributions for making the “lower” choice?\nImagine that, instead of each sample of evidence equalling either \\(+1\\) or \\(-1\\), the evidence could also equal \\(0\\). Write code to simulate this model and use your simulations to see how this model might differ from the random walk model we developed in this chapter.\n\nYou will need to introduce a new parameter to the model that represents the probability of getting a sample that equals zero. What ways can you think of to implement this aspect of the model? Which method did you pick and why?\nHow does the shape of the predicted RT distributions differ, if at all, from that predicted by the original random walk model? (Hint: you may want to explore settings in which there is zero probability of taking a step either up or down. It may also help to visualize the random walks themselves too.)\nWhat cognitive tasks might be better modeled by allowing for evidence to have a value of zero?\n\nTry implementing a model in which the residual time can vary randomly according to some distribution. Since residual time must be non-negative, you might consider distributions like the Gamma distribution or a uniform distribution between two positive values.\n\nHow did you implement random residual times?\nHow does random residual time affect the shape of the predicted RT distributions?\nWhat psychological factors might contribute to variability in residual time?\n\n\n\n\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A dynamic–cognitive approach to decision making in an uncertain environment. Psychological Review, 100(3), 432–459.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Building a random walk model to simulate choice and RT</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html",
    "href": "diffusion_sim.html",
    "title": "4  From random walk to diffusion",
    "section": "",
    "text": "4.1 Discrete to continuous evidence\nIn the previous chapter, we built a random walk model of how someone might decide between two options. In this chapter, we turn the random walk model into the more widely applied diffusion model, introduced to psychology by Ratcliff (1978). As we shall see, conceptually, the transition from a random walk to a diffusion model is not very large.\nLike most models of choice and RT, both random walk and diffusion models are premised on the idea that making a decision requires accumulating samples of “evidence” until the accumulated evidence reaches a response boundary. The “evidence” in these models is deliberately abstract because these models are meant to be applied in a variety of situations. The important thing is that “evidence” can be represented in these models as a number, where a sample of evidence supporting one option takes a positive value while a sample supporting the other option takes a negative value. A diffusion model differs from a random walk model in two aspects regarding the nature of the evidence that is accumulated:\nIn other words, the random walk model treats evidence as taking discrete values that are sampled at discrete intervals, whereas a diffusion model treats evidence as taking continuous values that are sampled continuously in time.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#discrete-to-continuous-evidence",
    "href": "diffusion_sim.html#discrete-to-continuous-evidence",
    "title": "4  From random walk to diffusion",
    "section": "",
    "text": "Samples of evidence take continuous values, rather than discrete values.\nSamples of evidence arrive continually, rather than at regular intervals.\n\n\n\n4.1.1 Evidence sampled from a normal distribution\nIn the random walk model, the magnitude of each sample of evidence was always equal to one. Each sample was either \\(+1\\) or \\(-1\\). In a diffusion model, evidence can take any real value, such that its magnitude is now important. Conceptually, this has some intuitive appeal. Some samples of evidence strongly favor one option, some samples only weakly support one option, and some are equivocal.\nIn a diffusion model, samples of evidence are specifically assumed to come from a normal distribution. The standard deviation of this distribution is typically fixed to some value like 0.1 or 1. Here, we will fix it to the value of 1. The reason for fixing this value is that “evidence” is abstract and therefore has no natural scale. We could multiply or divide all the evidence samples by a constant amount without changing their underlying meaning.\nThe mean of the evidence distribution represents how strongly the evidence tends to favor one option over the other, similar in meaning to the \\(p\\) parameter in the random walk model. The mean of the evidence distribution in a diffusion model is termed the drift rate, as it reflects the tendency for accumulated evidence to “drift” either upward or downward over time. As illustrated in the graph below, the mean of the evidence distribution governs the degree to which samples support one option versus the other.\n\n\nCode\nexpand_grid(v = c(-2, -1, 0, 1, 2), x = seq(-4, 4, length.out = 201)) %&gt;%\n    mutate(d = dnorm(x, mean = v, sd = 1)) %&gt;%\n    ggplot(aes(x = x, y = d, color = v, group = v)) +\n    geom_vline(xintercept = 0, linetype = \"dashed\") +\n    geom_line() +\n    scale_color_gradient2(mid = \"#444444\", midpoint = 0) +\n    labs(x = \"Value of evidence sample\", y = \"Relative frequency\", color = \"Mean of evidence\\ndistribution\")\n\n\n\n\n\n\n\n\n\n\n\n4.1.2 Evidence sampled continuously in time\nHere we come to a bit of a subtle issue: In the random walk, evidence arrived in discrete units at regular intervals, but the duration of the interval was not related to the magnitude of the evidence. In a diffusion model, we assume that evidence arrives continuously in time. One way to think about this—indeed, the way that we will simulate this—is that evidence is sampled in many very short intervals of time, each of which has duration \\(\\Delta t\\). When \\(\\Delta t\\) is small enough, those many little intervals will look like one continuous span of time. This principle is illustrated in the graph below.\n\n\nCode\ndiffusion_sim &lt;- expand_grid(dt = c(0.1, 0.01, 0.001)) %&gt;%\n    group_by(dt) %&gt;%\n    reframe(t = seq(0, 3, by = dt)) %&gt;%\n    ungroup() %&gt;%\n    mutate(x_sample = rnorm(n = n(), mean = 0, sd = 1 * sqrt(dt))) %&gt;%\n    group_by(dt) %&gt;%\n    mutate(x = cumsum(x_sample))\n\nscaled_plot &lt;- diffusion_sim %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    geom_step() +\n    facet_wrap(\"dt\", labeller = label_bquote(Delta * t == .(dt))) +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = expression(\"Evidence scaled by \" * Delta * t))\n\nunscaled_plot &lt;- diffusion_sim %&gt;%\n    ggplot(aes(x = t, y = x / sqrt(dt))) +\n    geom_step() +\n    facet_wrap(\"dt\", labeller = label_bquote(Delta * t == .(dt))) +\n    labs(x = \"Time\", y = \"Accumulated evidence\", title = \"Evidence not scaled\")\n\nscaled_plot / unscaled_plot\n\n\n\n\n\n\n\n\n\nThe top set of graphs above show how, when \\(\\Delta t\\) is sufficiently small, the trajectory of accumulated evidence looks essentially continuous—you can no longer see the “jumps” from one interval to the next.\nThe bottom set of graphs illustrate the subtlety I mentioned earlier. If we divide time into many small intervals but leave the mean and standard deviation of the evidence distribution the same, then we are essentially getting many more samples of evidence. As a result, accumulated evidence has a much larger scale than it would have if we had picked a smaller \\(\\Delta t\\). From a theoretical standpoint, this doesn’t make sense—the rate at which evidence accumulates for a decision should not be affected by the modeler’s arbitrary choice of \\(\\Delta t\\).\nSo what we do is scale the evidence samples by \\(\\Delta t\\). That’s what was done in the top set of graphs, but not the bottom set. The idea is that if you have very small time intervals, you shouldn’t be able to get as large of a sample of evidence. Again, this makes theoretical sense, if evidence is something that takes time to accumulate.\nSpecifically, a diffusion model assumes that each sample of evidence is drawn from a normal distribution with a mean of \\(v \\times \\Delta t\\), where \\(v\\) is the drift rate parameter, and a standard deviation of \\(\\sqrt{\\Delta t}\\). Why \\(\\sqrt{\\Delta t}\\) instead of just \\(\\Delta t\\)? Because it is the mean and variance that need to be scaled by \\(\\Delta t\\).\n\n\n4.1.3 A new simulation function\nLet’s take our rw_sim function from the previous chapter and turn it into a diffusion model. To do this, we make two modifications: First, we swap out the p parameter representing the probability of getting a positive sample for a parameter called v which is the drift rate. Second, instead of getting each evidence sample x_sample from a binomial distribution, we will get it from a normal distribution using R’s rnorm function. These changes are illustrated below.\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, b_upper = 1, b_lower = -1, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = v * dt, sd = sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nIn the code above, I also took the liberty of adjusting the default values of b_upper, b_lower, and dt so that the simulated choices and RT’s would look a bit more like those observed in cognitive tasks, but of course you may feel free to adjust those yourself as you like.\n\n\n4.1.4 Putting it all together—again\nAt the end of the last chapter, I included a chunk of code that simulated a random walk and produced some visualizations to help us understand both its internal states and its overt behavior (choices and RT). By swapping out rw_sim with the appropriately adjusted diffusion_sim line, we can apply the same chunk of code to the diffusion model! In the chunk below, I picked some arbitrary but reasonable values for the parameters.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, b_upper = 1, b_lower = -1)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\nYou may or may not be surprised to see that the RT distributions produced by the diffusion model closely resemble those produced by the random walk! The diffusion model also demonstrates an interesting feature of a random walk, namely, that the conditional RT distribution depends on the boundaries but not on the drift rate. In the example above, I set \\(v = 0.5\\), such that evidence would tend to favor the positive option. Even though the model ends up choosing that option more often, it does not do so any faster or slower than it chooses the negative option. This is something we will return to at the end of this chapter.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#response-caution-and-response-bias",
    "href": "diffusion_sim.html#response-caution-and-response-bias",
    "title": "4  From random walk to diffusion",
    "section": "4.2 Response caution and response bias",
    "text": "4.2 Response caution and response bias\nBefore confronting the issue of invariant RT distributions, it behooves us to consider a different way of specifying the response boundaries in our model. So far, we have specified those boundaries directly. We can speak of response caution in terms of how far those boundaries are from the starting point and response bias in terms of whether the boundaries are equidistant from the starting point.\nSpecifically, we could define a term \\(A\\) that is the total distance between the starting point (zero) and the two boundaries. If \\(B_{\\text{Upper}}\\) and \\(B_{\\text{Lower}}\\) are the upper and lower boundaries, respectively, then \\[\nA = B_{\\text{Upper}} - B_{\\text{Lower}}\n\\] In other words, \\(A\\) is how far apart the two boundaries are, called boundary separation. The term \\(A\\) can be seen to operationalize the construct of response caution in that a decision maker who wants to wait to accumulate evidence would put their response boundaries far apart.\nWe can also operationalize the construct of response bias by defining a term \\(w\\). This term will be a number between 0 and 1 that represents the degree to which response boundaries favor one choice over the other. Specifically, let \\[\nw = \\frac{-B_{\\text{Lower}}}{B_{\\text{Upper}} - B_{\\text{Lower}}}\n\\] As shown in the graph below, \\(w = 0.5\\) when the boundaries are equidistant from zero, \\(w &lt; 0.5\\) when the boundaries are biased in favor of the negative option, and \\(w &gt; 0.5\\) when the boundaries are biased in favor of the positive option.\n\n\nCode\nexpand_grid(b_upper = seq(1, 5), b_lower = seq(-1, -5)) %&gt;%\n    mutate(A = b_upper - b_lower) %&gt;%\n    mutate(w = -b_lower / A) %&gt;%\n    pivot_longer(c(A, w), names_to = \"par\", values_to = \"val\") %&gt;%\n    mutate(par = factor(par, levels = c(\"A\", \"w\"), labels = c(\"Response caution (A)\", \"Response bias (w)\"))) %&gt;%\n    ggplot(aes(x = b_upper, y = val, color = b_lower, group = b_lower)) +\n    geom_line() +\n    geom_point() +\n    facet_wrap(\"par\", scales = \"free_y\", strip.position = \"left\") +\n    labs(x = expression(B[\"Upper\"]), y = NULL, color = expression(B[\"Lower\"])) +\n    theme(strip.placement = \"outside\", strip.background = element_blank())\n\n\n\n\n\n\n\n\n\nHaving defined \\(A\\) and \\(w\\) as ways of operationalizing response caution and response bias, respectively, why not treat these values as parameters instead of the boundaries themselves? The value in doing so is that we can then specify these constructs directly, rather than having to work backwards from the boundaries. Specifically, if we pick values of \\(A\\) and \\(w\\) we can immediately compute what the upper and lower boundaries should be: \\[\\begin{align}\nB_{\\text{Upper}} & = w A \\\\\nB_{\\text{Lower}} & = -\\left(1 - w \\right) A \\\\\n\\end{align}\\]\nAnd we can adjust our diffusion_sim code accordingly to have a and w as parameters instead of b_upper and b_lower, which now get calculated in the function itself:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf) {\n    b_upper &lt;- (1 - w) * a\n    b_lower &lt;- -w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#trial-by-trial-variability",
    "href": "diffusion_sim.html#trial-by-trial-variability",
    "title": "4  From random walk to diffusion",
    "section": "4.3 Trial-by-trial variability",
    "text": "4.3 Trial-by-trial variability\nRecall that both the random walk and the diffusion model have the following property: The response times they produce depend on the distance between the starting point and the response boundary, not on the drift rate \\(v\\) or the step probability \\(p\\). To see why this might be problematic from a psychological perspective, imagine that the upper boundary corresponds to making a correct response while the lower boundary corresponds to making an error. Assume that \\(v &gt; 0\\), such that the evidence tends to favor making a correct response. The fact that response times do not depend on drift rates means that the model predicts that correct and error responses will be made in the same amount of time. To be more precise, the distribution of RT’s conditional on accuracy are the same.\nOften, errors are either faster or slower than correct responses. For example, it may be that errors occur more often when the decision maker happens to get poor evidence. In that case, we might expect errors to be slow because they result from the decision maker deliberating longer in the face of this poor evidence. On the other hand, maybe a decision maker tends to be correct when they take their time, but will sometimes “jump the gun” and pick the wrong option, in which case we would expect errors to be faster than correct responses.\nThe critical factor that Ratcliff (1978) introduced to the diffusion model that has made it into such a useful tool is that the drift rate is not the same on every trial, but varies randomly from trial to trial. On some trials, you happen to get a drift rate in the high positive tail of the distribution of drift rates, in which case you would probably make a fast correct response. On other trials, you happen to get a drift rate that is close to zero or even falls below zero by chance, in which case you would be more likely to make an error and would tend to do so more slowly. Thus, trial-by-trial variability in drift rates accounts for slow errors.\nWhat about fast errors? Ratcliff & Rouder (1998) showed that these can result if your response boundaries are not always fixed, but can also vary randomly from trial to trial. Sometimes, they happen to be very close to the starting point such that it takes very little evidence to commit to a response. Such rapid responses would be more likely to be errors, since they don’t give much time to accumulate evidence. Thus, trial-by-trial variability in boundaries (or, equivalently, in starting point) accounts for fast errors.\nThere is a final thing that can vary from trial to trial, and that is residual time. After all, if the time needed to accumulate evidence can vary between trials, so can the time needed to accomplish all the other processes involved in any given decision task. Trial-by-trial variability in residual time does not, of course, affect the probability of choosing either option, but it does affect the form of the RT distributions.\n\n4.3.1 Adding variability to our simulation code\nTo model each of these kinds of trial-by-trial variability, we need to decide how each of the values above (drift rate, boundaries, and residual time) can vary. This will also inform us as to what new parameters we will need to add to our model to specify that variability. In what follows, we will adopt common assumptions in the literature that are also implemented in the model-fitting functions we will use in later chapters. Check out the exercises (or explore on your own) to consider other forms of trial-by-trial variability!\n\n4.3.1.1 Trial-by-trial variability in drift rates\nOur model already has a parameter called \\(v\\) that stands for the “drift rate”. Let us instead treat \\(v\\) as the mean of a normal distribution of drift rates, which has standard deviation \\(s_v\\). If \\(s_v = 0\\), then we have our original diffusion model with the same drift rate on every trial. On the other hand, if \\(s_v &gt; 0\\), then the drift rate on any given trial will sometimes be greater or less than \\(v\\), even if the average drift rate across all trials is \\(v\\).\nTo implement this in our simulation code, we need to\n\nAdd a new parameter sv.\nAdd a line that randomly samples the drift rate (called trial_v) from a normal distribution with mean v and standard deviation sv.\nReplace v when drawing samples of evidence with trial_v.\n\nThese changes are reflected in the following adjusted code:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    \n    b_upper &lt;- (1 - w) * a\n    b_lower &lt;- -w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe chunk of code below has the same settings as that shown above, only now sv = 1. As you can see, responses on the lower boundary have a different RT distribution, which tends to be slower, than responses on the upper boundary. (Note, too, that I am using our revised code that uses a and w to define the response boundaries.)\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0.5)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n4.3.1.2 Trial-by-trial variability in boundaries/starting point\nThere are a number of ways that we could introduce variability in the starting point and/or boundaries. To be consistent with the model-fitting we will do later, we will assume that the bias parameter \\(w\\) is not fixed, but is sampled from a uniform distribution that goes from \\(w - \\frac{s_w}{2}\\) to \\(w + \\frac{s_w}{2}\\). Thus, the average bias is still \\(w\\) but has a range defined by parameter \\(s_w\\). As above, we need to add this new parameter and randomly sample a trial_w value at the top of our code. Note that the line that samples trial_w does some checking using the min and max functions to make sure that \\(w\\) never falls below 0 or greater than 1.\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0, sw = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    trial_w &lt;- runif(n = 1, min = max(0, w - 0.5 * sw), max = min(1, w + 0.5 * sw))\n    \n    b_upper &lt;- (1 - trial_w) * a\n    b_lower &lt;- -trial_w * a\n    \n    x &lt;- 0\n    t &lt;- t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe simulations below set \\(s_v = 0\\) and \\(s_w = 0.9\\), while \\(v = 0.5\\). In the simulations below, when the model picks the “incorrect” option associated with the lower boundary, it is predicted to do so faster than when it responds by choosing the “correct” option associated with the upper boundary.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0, sw = 0.9)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n4.3.1.3 Trial-by-trial variability in residual time\nOur final amendment to our diffusion simulation code involves adding variability to the residual time. Again, there are many ways we could do this, but we will adopt the same conventional approach used in our model-fitting later: We will assume that the residual time on any given trial is sampled from a uniform distribution that ranges from \\(t_0\\) to \\(t_0 + s_{t_0}\\). The code below adds the new st0 parameter and samples a residual time trial_t0 from a uniform distribution at the beginning of the simulation:\n\n\nCode\ndiffusion_sim &lt;- function(v = 0, a = 2, w = 0.5, t0 = 0.2, dt = 0.01, t_max = Inf, sv = 0, sw = 0, st0 = 0) {\n    trial_v &lt;- rnorm(n = 1, mean = v, sd = sv)\n    trial_w &lt;- runif(n = 1, min = max(0, w - 0.5 * sw), max = min(1, w + 0.5 * sw))\n    trial_t0 &lt;- runif(n = 1, min = t0, max = t0 + st0)\n    \n    b_upper &lt;- (1 - trial_w) * a\n    b_lower &lt;- -trial_w * a\n    \n    x &lt;- 0\n    t &lt;- trial_t0\n    \n    x_record &lt;- x\n    t_record &lt;- t\n    \n    while (x &lt; b_upper & x &gt; b_lower & t &lt; t_max) {\n        x_sample &lt;- rnorm(n = 1, mean = trial_v * dt, sd = 1 * sqrt(dt))\n        x &lt;- x + x_sample\n        t &lt;- t + dt\n        x_record &lt;- c(x_record, x)\n        t_record &lt;- c(t_record, t)\n    }\n    \n    return(data.frame(t = t_record, x = x_record))\n}\n\n\nThe simulations below again assume that \\(v = 0.5\\) and set \\(s_v = s_w = 0\\) while \\(s_t = 0.5\\). Note that the resulting RT distributions end up having a longer early tail, reflecting greater variability in the fastest RT’s due to variability in residual time.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0, sw = 0, st0 = 0.6)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n\n\n\n\n\n\n\n\nCode\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n\n\n\n\n\n\n\n\nCode\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")\n\n\nJoining with `by = join_by(choice)`\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Putting it all together (finally!)\nFinally, for completeness, let’s collect our code to run a set of simulations that allows for all three kinds of variability. This code is not executed here, but is included so it can serve as the basis for your own simulations and explorations.\n\n\nCode\n# Specify the number of simulations to run\nn_sims &lt;- 1000\n\n# This is initially empty, but will eventually save all our random walk simulations\nsim_results &lt;- c()\n\n# The for loop increments a counter (called \"i\" here) over a specified range (from 1 up to n_sims)\nfor (i in 1:n_sims) {\n    # Simulate a single realization of the random walk with the given parameters\n    current_result &lt;- diffusion_sim(v = 0.5, a = 2, w = 0.5, sv = 0.5, sw = 0.2, st0 = 0.4)\n    \n    # \"Bind\" the current simulation to the ongoing record of simulation results\n    sim_results &lt;- rbind(\n        sim_results,\n        # Add a new column that identifies which simulation this was\n        current_result %&gt;% mutate(sim_index = i)\n    )\n}\n\n# Visualize the internal states of the model\nsim_results %&gt;%\n    ggplot(aes(x = t, y = x)) +\n    stat_density2d_filled() +\n    labs(x = \"Time\", y = \"Accumulated evidence\", fill = \"Relative frequency\", title = \"Internal evidence states over time\")\n\n# Extract simulated choices and RT's\nchoice_rt &lt;- sim_results %&gt;%\n    group_by(sim_index) %&gt;%\n    summarize(\n        choice = factor(last(x) &gt; 0, levels = c(TRUE, FALSE), labels = c(\"upper\", \"lower\")),\n        rt = last(t)\n    )\n\n# Plot conditional RT distributions\nchoice_rt %&gt;%\n    ggplot(aes(x = rt, color = choice)) +\n    geom_density() +\n    labs(x = \"Response time\", y = \"Frequency\", color = \"Choice\", title = \"Conditional RT distributions\")\n\n# Quantile-probability plot\n\nsim_choice_p &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    count() %&gt;%\n    ungroup() %&gt;%\n    mutate(p_resp = n / sum(n))\n\nsim_rt_q &lt;- choice_rt %&gt;%\n    group_by(choice) %&gt;%\n    reframe(rt_q = quantile(rt, probs = c(0.1, 0.3, 0.5, 0.7, 0.9)))\n\nfull_join(sim_choice_p, sim_rt_q) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = choice)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response proportion\", y = \"RT Quantile\", title = \"Quantile-Probability Plot\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#shiny-app",
    "href": "diffusion_sim.html#shiny-app",
    "title": "4  From random walk to diffusion",
    "section": "4.4 Shiny App",
    "text": "4.4 Shiny App\nTo have a good deal of fun exploring how the different parameters of a diffusion model influence its predicted choice and RT distributions, download this Shiny app and run it from RStudio. You will also need to download this R script into the same directory as the Shiny app. The Shiny app has some additional functionality that we will see more of in the next chapter.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_sim.html#exercises",
    "href": "diffusion_sim.html#exercises",
    "title": "4  From random walk to diffusion",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\nUnder what circumstances do you think it is more likely for errors to be faster than correct responses? What about circumstances in which errors are more likely to be slower than correct responses? What do you think about the psychological implications of how the diffusion model produces either fast or slow errors?\nWrite a new diffusion simulation that uses a different distribution of drift rates from trial to trial—you might try distributions that are skewed (like an ExGaussian) or have heavy tails (like the T distribution with few degrees of freedom).\n\nDescribe the distribution you picked and whether it corresponds to a theory or hypothesis about how evidence may vary from trial-to-trial in a particular cognitive task.\nDescribe any differences you find between the model you wrote and the model in the chapter that assumes a normal distribution of drift rates across trials.\n\n\n\n\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108.\n\n\nRatcliff, R., & Rouder, J. N. (1998). Modeling response times for two-choice decisions. Psychological Science, 9(5), 347–356.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>From random walk to diffusion</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html",
    "href": "diffusion_fit.html",
    "title": "5  Fitting a diffusion model to data",
    "section": "",
    "text": "5.1 Fitting a model\nIn the previous chapter, we adapted our random walk model into a diffusion model. We saw how the different parameters of the diffusion model produce different patterns of choice and RT behavior. This is what makes the diffusion model a useful cognitive model in so many cases: It has parameters that correspond to meaningful, if unobservable, psychological constructs (evidence accumulation, response caution, response bias) and we can see how differences in those constructs manifest in observable behavior.\nIn this chapter, we turn the model around: Instead of taking parameters and using them to produce behavior, we are taking behavior and inferring what values of the model parameters most likely produced that behavior. In doing so, we are performing a kind of “mind reading”—we are learning about unobservable psychological constructs via how those constructs manifest in behavior.\nThe foundational material puts us in a position to do three things in the next chapter:\nFitting a model to data means finding the values of that model’s parameters that assign the highest likelihood to the observed data. Given a set of parameter values, we can use the model to compute how likely it would be to have seen each observation in our dataset.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-a-model",
    "href": "diffusion_fit.html#fitting-a-model",
    "title": "5  Fitting a diffusion model to data",
    "section": "",
    "text": "5.1.1 Parameters, likelihoods, and log-likelihoods\nUsing \\(\\theta\\) to stand for a set of parameter values and \\(x_i\\) to stand for a particular observation, we can use \\(f \\left( x \\mid \\theta \\right)\\) to stand for the likelihood of the datum \\(x_i\\) given the parameter values \\(\\theta\\) and a model with a likelihood function \\(f\\).\nConsider the familiar normal distribution. This distribution has two parameters, a mean \\(\\mu\\) and a standard deviation \\(\\sigma\\). So for the normal distribution, \\(\\theta\\) is actually a vector with two elements: \\(\\theta = \\left[ \\mu, \\sigma \\right]\\). The normal distribution is a simple model in that it says that observed values fall in a particular shape around the mean \\(\\mu\\) with a spread described by \\(\\sigma\\). The likelihood function for the normal distribution, written below, indicates how likely it would be to observe datum \\(x_i\\) given specific values of \\(\\mu\\) and \\(\\sigma\\): \\[\nf_{\\text{Normal}} \\left( x_i \\mid \\mu, \\sigma \\right) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} \\exp \\left[ - \\frac{\\left(x_i - \\mu \\right)^2}{2 \\sigma^2} \\right]\n\\]\nThe graph below assumes that we have just a single observation, \\(x_i = 0\\). The plots show how the likelihood assigned to that datum depends on both parameters of the normal distribution, \\(\\mu\\) and \\(\\sigma\\).\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = 0) %&gt;%\n    mutate(d = dnorm(x, mean = mu, sd = sigma))\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = d)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = d)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = d)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Joint likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\n\n\n\nData: (0)\n\n\n\n\nWhen we have more than one observation, the likelihood of all observations is the product of the likelihoods of each individual observation: \\[\nf \\left( \\mathbf{x} \\mid \\theta \\right) = \\prod_{i = 1}^N f \\left( x_i \\mid \\theta \\right)\n\\] This situation is illustrated in the graphs below. These graphs again assume a normal distribution as the model, but now we have observed the values \\(\\mathbf{x} = \\left[ 0, 1 \\right]\\).\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = c(0, 1)) %&gt;%\n    mutate(d = dnorm(x, mean = mu, sd = sigma)) %&gt;%\n    group_by(mu, sigma) %&gt;%\n    summarize(d = prod(d), .groups = \"keep\")\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = d)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = d)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = d)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(f[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Joint likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nData: (0, 1)\n\n\n\n\n\n\n5.1.2 Log-likelihood\nYou may have noticed that the scale on the bottom graph in the second set of plots (where the data were \\(0, 1\\)) has a smaller maximum than it did in the bottom graph in the first set of plots (where the data were just \\(0\\)). This is because the likelihood of the whole dataset is a product of many small numbers, so the result also tends to be small. Unfortunately, this can lead to technical issues when we have many observations because the resulting likelihood may be too small for the computer to accurately calculate.\nAs a result, we often work with the natural logarithm of the likelihood function. Because multiplication turns into addition on the log-scale, this saves the computer from needing to work with very tiny numbers. We often write \\(LL\\) to stand for this “log-likelihood”: \\[\nLL \\left( \\mathbf{x} \\mid \\theta \\right) = \\log \\left[ \\prod_{i = 1}^N f \\left( x_i \\mid \\theta \\right) \\right] = \\sum_{i = 1}^N \\log f \\left( x_i \\mid \\theta \\right)\n\\]\nFortunately, since the logarithm is a monotonic transformation, the parameters that maximize the likelihood are the very same parameters that maximize the log-likelihood. To get a sense of this, the graphs below replicate the graph above with observed values \\(\\mathbf{x} = \\left[ 0, 1 \\right]\\), but showing the log-likelihood instead of the likelihood.\n\n\nCode\nnorm_like_df &lt;- expand_grid(mu = seq(-3, 3, by = 0.1), sigma = seq(0, 3, by = 0.1), x = c(0, 1)) %&gt;%\n    mutate(ll = dnorm(x, mean = mu, sd = sigma, log = TRUE)) %&gt;%\n    group_by(mu, sigma) %&gt;%\n    summarize(ll = sum(ll), .groups = \"keep\")\n\nmu_plot &lt;- norm_like_df %&gt;%\n    filter(sigma == 1) %&gt;%\n    ggplot(aes(x = mu, y = ll)) +\n    geom_line() +\n    labs(x = expression(mu), y = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, 1), \")\")), title = expression(\"Assuming \" * sigma == 1))\n\nsigma_plot &lt;- norm_like_df %&gt;%\n    filter(mu == 1) %&gt;%\n    ggplot(aes(x = sigma, y = ll)) +\n    geom_line() +\n    labs(x = expression(sigma), y = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(1, sigma), \")\")), title = expression(\"Assuming \" * mu == 1))\n\njoint_plot &lt;- norm_like_df %&gt;%\n    ggplot(aes(x = mu, y = sigma, fill = ll)) +\n    geom_raster(interpolate = TRUE) +\n    geom_vline(xintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    geom_hline(yintercept = 1, linetype = \"dashed\", color = \"lightgrey\") +\n    scale_fill_viridis_c() +\n    coord_equal() +\n    labs(x = expression(mu), y = expression(sigma), fill = expression(LL[Normal] * bgroup(\"(\", x[i] * \"|\" * list(mu, sigma), \")\")), title = \"Total log-likelihood\")\n\nmu_plot + sigma_plot + joint_plot + plot_layout(design = \"12\\n33\", guides = \"keep\", heights = c(1, 2))\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\nData: (0, 1)\n\n\n\n\n\n\n5.1.3 Maximizing log-likelihood\nThe combination of parameter values that assigns the highest total log-likelihood to all the data is where the bright spot is in the bottom graph of each set of plots above. For a normal model, the values of \\(\\mu\\) and \\(\\sigma\\) that assign the highest total log-likelihood to the data can be computed directly: they are the sample mean and the population standard deviation computed on the same (i.e., where you divide by \\(N\\) instead of \\(N - 1\\)).\nFor a more complex model, like our diffusion model, we will not be able to calculate these “optimal” parameter values directly. Instead, we will need to use the computer to search for these values. The topic of parameter optimization is a large one that we cannot fully address here. However, the functions supplied with this tutorial make use of two search methods: the Nelder-Mead simplex algorithm and the ucminf function from the ucminf R package.\nThe essence of these parameter optimization algorithms is this: They begin with an initial “guess” of the parameter values and compute the log-likelihood of the data given that initial guess. They then “explore” by calculating the log-likelihood of the data using slightly adjusted parameter values. If this exploration finds a set of adjusted parameter values that assign a higher log-likelihood to the data than the original guess, then these adjusted values are considered a “better guess”. The search process then begins again starting from that better guess. As a result, the “guess” gets gradually better on each step of the algorithm until it can no longer find any way to adjust the parameters to find a higher log-likelihood.\nOne can think of this parameter search as like trying to find a mountain peak in a snowstorm: The snowstorm obscures your visibility so you can only search areas in your immediate vicinity (similar to how the parameter optimizer tries to adjust values of the parameters starting from an initial guess). However, you can still figure out which direction is “uphill” from your current position (similar to how the algorithm finds adjusted parameters that yield a higher log-likelihood than the current best guess). Eventually, you will reach a point where you can’t go uphill any more.\nThe metaphor in the previous paragraph serves to highlight the fact that parameter optimizers are not necessarily guaranteed to find the “global optimum”—the best possible set of parameter values. It is possible that they instead find a “local optimum”—a set of values for which no small adjustment yields an improvement, but which is not the best you could possibly do. To return to the metaphor, the tallest peak may be a mile away from the one you found, but you’ll never know that because you can’t see it.\nThe utility functions we will use in this tutorial are generally pretty good at finding global optima, but it is not guaranteed! This is why it is important to develop some intuitions about how model parameters manifest in behavior, so you can detect when you might have reached a local optimum instead of a global one.\n\n\n5.1.4 Minimizing negative log-likelihood\nDue to the vagaries of history, algorithms that search for optimal parameter values are often written not to maximize something, but to minimize it instead. As a result, what a parameter optimization algorithm actually does is minimize the negative log-likelihood. Basically, it flips the “maximization” problem over, although it does not change anything conceptually. However, it does mean that a more appropriate metaphor is finding the lowest point in a valley rather than the highest peak of a mountain range.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-a-diffusion-model",
    "href": "diffusion_fit.html#fitting-a-diffusion-model",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.2 Fitting a diffusion model",
    "text": "5.2 Fitting a diffusion model\nTo find the set of parameters for a diffusion model that assign the highest likelihood to the data, we need to be able to compute the likelihood of making a specific choice at a specific time, given a set of diffusion model parameters. This computation is not something we can do by hand—we have to rely on the computer. Fortunately, many folks have contributed to the development of efficient means of doing this computation (e.g., Blurton et al., 2012; Gondan et al., 2014; Hartmann & Klauer, 2021; Navarro & Fuss, 2009; Tuerlincx, 2004).\nWe will make use specifically of an R package that implements these methods called WienR (Hartmann & Klauer, 2023). The name comes from the fact that Norbert Wiener was associated with the development of the “bare-bones” diffusion model without any of the trial-by-trial variability introduced by Ratcliff (1978). That said, the WienR package allows for all of those additional forms of variability as described in the previous chapter.\nBe sure you have the WienR package installed and loaded!\n\n\nCode\nlibrary(WienR)\n\n\n\n5.2.1 Diffusion model likelihood\nThe WienR package provides a function called WienerPDF which returns both the likelihood and the log-likelihood of a set of responses, given a set of diffusion model parameters.\nUnlike with the normal distribution model, where an observation was characterized by a single number, an observation for a diffusion model is characterized by a choice and a response time. Thus, if we want to compute the likelihood of responding at the upper boundary in 1 second given a drift rate of \\(v = 0.5\\), response caution of \\(a = 2\\), response bias of \\(w = 0.5\\), and residual time \\(t_0 = 0.2\\), we use\n\n\nCode\nWienerPDF(t = 1, response = \"upper\", a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n\n\nFirst-passage time PDF\n\n[1] 0.4362052\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.8296426\n\n---------------------------\n\n\nThe “First-passage time PDF” is the likelihood of having made that response at that time.\nLet’s imagine that we observed a few more trials, one in which a decision-maker responded at the upper boundary in 1.5 seconds and one in which the decision-maker responded at the lower boundary in 2 seconds. We can compute the likelihood and log-likelihood of all of those trials:\n\n\nCode\nWienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n\n\nFirst-passage time PDF\n\n[1] 0.43620517 0.22137809 0.04128626\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.8296426 -1.5078832 -3.1872255\n\n---------------------------\n\n\nNote two things: First, t and response are allowed to be vectors, where the \\(i\\)th entry in the t vector corresponds to the \\(i\\)th entry in the response vector. Second, we get the likelihood and log-likelihood for each trial individually. So if we want the total log-likelihood, we have to do that ourselves:\n\n\nCode\nresult &lt;- WienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n(total_log_likelihood &lt;- sum(result$logvalue))\n\n\n[1] -5.524751\n\n\nThe upshot of this is that WienerPDF gives us a way to evaluate the log-likelihood of a set of choices and response times given a set of values for the diffusion model’s parameters. WienerPDF also allows us to include variability in drift rates via the sv parameter, variability in boundaries via the sw parameter, and variability in residual time via the st0 parameter, like so:\n\n\nCode\nWienerPDF(t = c(1, 1.5, 2), response = c(\"upper\", \"upper\", \"lower\"), a = 2, v = 0.5, w = 0.5, t0 = 0.2, sv = 0.5, sw = 0.1, st0 = 0.4)\n\n\n\nFirst-passage time PDF\n\n[1] 0.56113640 0.26562047 0.06165999\n\n---------------------------\n\nLog of first-passage time PDF\n\n[1] -0.5777913 -1.3256868 -2.7861200\n\n---------------------------\n\n\nNotice that the likelihoods and log-likelihoods changed when we included those three new parameters (which, by default, are set to zero).\n\n\n5.2.2 Finding the best-fitting parameters\nTo find the diffusion model parameters that assign the highest log-likelihood to a given set of choices and RT’s, I have provided a helpful function called fit_wienr. To use this function, download the wienr_fit_utils.r R script to your working directory and run\n\n\nCode\nsource(\"wienr_fit_utils.r\")\n\n\nWe shall see later that the fit_wienr function has some useful bells-and-whistles, but for now let’s just see how it works in its basic form. To do this, let’s use another function from the WienR package called sampWiener which simulates a sample of data from a diffusion model, just like we did in the last chapter (actually, you could even use the diffusion_sim function you built for that purpose!):\n\n\nCode\n(sim_data &lt;- sampWiener(N = 50, a = 2, v = 0.5, w = 0.5, t0 = 0.2))\n\n\n$q\n [1] 1.0145267 0.7785001 0.4830922 0.7476763 0.6889558 0.3996333 0.7652827\n [8] 1.0678441 1.0589824 1.1778599 1.1916915 2.0070563 0.4737943 0.5687575\n[15] 0.9735880 0.7182124 0.7907633 1.5717658 0.6528604 0.8988441 0.6722051\n[22] 0.3394198 0.8275921 2.0176933 0.6527308 1.3267482 1.0114098 0.7283250\n[29] 1.6299191 1.8353343 1.2566600 1.2643379 2.0130723 1.5419533 1.0620593\n[36] 0.5713716 2.5825087 0.7561459 1.1029754 0.6381128 0.5454809 0.6359990\n[43] 3.0614166 1.6769220 0.8270179 2.9357647 1.0710890 0.3431315 0.4737332\n[50] 3.6870701\n\n$response\n [1] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[10] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[19] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[28] \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\" \"upper\"\n[37] \"upper\" \"upper\" \"upper\" \"lower\" \"lower\" \"lower\" \"lower\" \"lower\" \"lower\"\n[46] \"lower\" \"lower\" \"lower\" \"lower\" \"lower\"\n\n$call\nsampWiener(N = 50, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\nattr(,\"class\")\n[1] \"Diffusion_samp\"\n\n\nThe simulated choices are in sim_data$response and the simulated RT’s are in sim_data$q.\nBecause we are using the diffusion model to simulate data, it’s worth asking how likely the data are given the parameter values we actually used for the simulation:\n\n\nCode\noriginal_likelihood &lt;- WienerPDF(t = sim_data$q, response = sim_data$response, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\nsum(original_likelihood$logvalue)\n\n\n[1] -66.06148\n\n\nRemember, though, that the optimization algorithm will actually be minimizing the negative log-likelihood. The negative log-likelihood given the original values of the parameters is\n\n\nCode\n-sum(original_likelihood$logvalue)\n\n\n[1] 66.06148\n\n\nIt may be that the “best-fitting” parameters differ from those used to simulate the data, just due to sampling variability. Thus, what we are about to do is a form of parameter recovery, in that we are seeing how well we can “recover” the original model parameters, despite this sampling variability.\nThe following code uses the fit_wienr function to find the best-fitting diffusion model parameter values for the simulated data above:\n\n\nCode\n(fit &lt;- fit_wienr(rt = sim_data$q, response = sim_data$response))\n\n\n$par\n     a[1]      v[1]      w[1]     t0[1] \n2.0672467 0.7208941 0.4525921 0.2034778 \n\n$value\n[1] 65.09442\n\n$convergence\n[1] 1\n\n$message\n[1] \"Stopped by small gradient (grtol).\"\n\n$invhessian.lt\n [1]  0.0233247552  0.0059470005 -0.0003678730 -0.0039030749  0.0343417878\n [6] -0.0053634481 -0.0010979615  0.0025483504  0.0004887555  0.0017438879\n\n$info\n maxgradient     laststep      stepmax        neval \n3.672338e-08 2.012289e-07 1.500625e-02 1.700000e+01 \n\n\nThe best negative log-likelihood that the algorithm was able to find is fit$value—as we can see it is slightly lower than the negative log-likelihood associated with the original simulating parameters, suggesting that the best-fitting parameters really do a slightly better job of “fitting” the data. Those parameter estimates reside in fit$par, where we can compare them against the values used to actually simulate the data.\n\n\n5.2.3 Visualizing model fit\nMinimizing the negative log-likelihood is well and good, but it doesn’t tell us much about how well the model actually “fits” the data. Does it predict similar choice and RT patterns?\nTo address this, it is helpful to visually inspect the fit of the model. There are many ways to do this, but here we will make use of the quantile-probability plots we introduced in previous chapters. We will overlay the quantile-probability plots of the original data with those that would be predicted by the best-fitting diffusion model parameters. To the extent that the model and data are close to one another, we can feel confident that the model is accurately reproducing the major features of the data.\nThe qp_fit function in the wienr_fit_utils.r script calculates the response probabilities and RT quantiles for both the observed data and the fitted model, like so:\n\n\nCode\n(obs_fit_data &lt;- qp_fit(rt = sim_data$q, response = sim_data$response, par = fit$par))\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\n# A tibble: 20 × 12\n# Groups:   drift_index, bound_index, resid_index, sv_index, sw_index,\n#   st0_index [1]\n   drift_index bound_index resid_index sv_index sw_index st0_index response\n         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   \n 1           1           1           1        1        1         1 lower   \n 2           1           1           1        1        1         1 lower   \n 3           1           1           1        1        1         1 lower   \n 4           1           1           1        1        1         1 lower   \n 5           1           1           1        1        1         1 lower   \n 6           1           1           1        1        1         1 upper   \n 7           1           1           1        1        1         1 upper   \n 8           1           1           1        1        1         1 upper   \n 9           1           1           1        1        1         1 upper   \n10           1           1           1        1        1         1 upper   \n11           1           1           1        1        1         1 upper   \n12           1           1           1        1        1         1 upper   \n13           1           1           1        1        1         1 upper   \n14           1           1           1        1        1         1 upper   \n15           1           1           1        1        1         1 upper   \n16           1           1           1        1        1         1 lower   \n17           1           1           1        1        1         1 lower   \n18           1           1           1        1        1         1 lower   \n19           1           1           1        1        1         1 lower   \n20           1           1           1        1        1         1 lower   \n# ℹ 5 more variables: n_resp &lt;int&gt;, p_resp &lt;dbl&gt;, rt_p &lt;dbl&gt;, rt_q &lt;dbl&gt;,\n#   source &lt;chr&gt;\n\n\nWe can then use the result to overlay the quantile-probabilities from the fitted model over those computed from the observed data:\n\n\nCode\nobs_fit_data %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\", title = \"50 simulated trials\")\n\n\n\n\n\n\n\n\n\nThis visualization highlights a few things: While the diffusion model fits the response probabilities and central tendency of the RT’s quite well, it doesn’t do as good a job with the error RT’s nor with the tails of the RT distributions. This is not because of a qualitative difference between the model and data—after all, we used the diffusion model to simulate these data! Rather, this apparent misfit is due to sampling error: With a small sample, it is harder to estimate RT’s for rare responses (like errors) and it is harder to estimate the tails of the RT distributions (since, by definition, we have fewer observations in the tails).\nSo let’s see what happens if we simulate 1000 trials instead of just 50.\n\n\nCode\nsim_data_large &lt;- sampWiener(N = 1000, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\n\n(fit_large &lt;- fit_wienr(rt = sim_data_large$q, response = sim_data_large$response))\n\n\n$par\n     a[1]      v[1]      w[1]     t0[1] \n2.0145409 0.4891320 0.4895752 0.1936399 \n\n$value\n[1] 1394.557\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n  0.3267429   0.0000000   1.0000000   1.0000000 \n\n\nCode\nobs_fit_data_large &lt;- qp_fit(rt = sim_data_large$q, response = sim_data_large$response, par = fit_large$par)\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\nCode\nobs_fit_data_large %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\", title = \"1000 simulated trials\")\n\n\n\n\n\n\n\n\n\nMuch better! And notice that the best-fitting parameter values (fit_large$par, above) are quite close to those used to simulate the data.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#fitting-multiple-conditions",
    "href": "diffusion_fit.html#fitting-multiple-conditions",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.3 Fitting multiple conditions",
    "text": "5.3 Fitting multiple conditions\nImagine that we are modeling someone doing a recognition memory task. In this task, participants study a set of items like words or images. Later, during a test phase participants are shown many items and, for each one, they have to decide whether it had been on the study list or not. Therefore, on any given test trial, the item shown could have been studied—called a target—or not studied—called a foil. The participant needs to accumulate evidence from their memory in order to decide whether the item had or had not been studied. It seems reasonable to assume that, if the item is a target, the drift rate for that evidence would tend to be positive, i.e., supporting the choice that the item had been studied. If the item is a foil, the drift rate would tend to be negative, since the samples of evidence from memory would support the choice that the item wasn’t studied. Modeling this task would therefore require estimating two drift rate parameters, one for trials in which a target is shown and one for trials in which a foil is shown. However, because the participant cannot know which type of item they were shown, their response boundaries and residual time should be the same regardless of whether the trial shows a target or a foil.\nThe example above is just one case in which we need to model a decision task by assuming that some parameters differ between conditions (like between targets and foils) while others stay the same (like the response boundaries and residual time). For example, we could simulate the situation above by assuming that \\(v_1 = 0.5\\) is the drift rate for targets while \\(v_2 = -0.5\\) is the drift rate for foils, while keeping \\(a = 2\\), \\(w = 0.5\\), and \\(t_0 = 0.2\\) constant:\n\n\nCode\ntarget_trials &lt;- sampWiener(N = 80, a = 2, v = 0.5, w = 0.5, t0 = 0.2)\nfoil_trials &lt;- sampWiener(N = 80, a = 2, v = -0.5, w = 0.5, t0 = 0.2)\n\n(all_trials &lt;- tibble(\n    rt = c(target_trials$q, foil_trials$q),\n    response = c(target_trials$response, foil_trials$response),\n    item = factor(rep(c(\"Target\", \"Foil\"), each = 80), levels = c(\"Target\", \"Foil\"))\n))\n\n\n# A tibble: 160 × 3\n      rt response item  \n   &lt;dbl&gt; &lt;chr&gt;    &lt;fct&gt; \n 1 1.77  upper    Target\n 2 1.95  upper    Target\n 3 0.486 upper    Target\n 4 0.396 upper    Target\n 5 0.543 upper    Target\n 6 1.40  upper    Target\n 7 0.748 upper    Target\n 8 0.721 upper    Target\n 9 0.938 upper    Target\n10 1.99  upper    Target\n# ℹ 150 more rows\n\n\nWe can use the fit_wienr function to fit these data by supplying it with a drift_index vector. This is a vector of positive integers (1, 2, 3, …) that indicate which drift rate to use when computing the log-likelihood of a particular trial. In this case, since we want drift rate to depend on the type of item shown, we can use the item column of our simulated data to define the drift index:\n\n\nCode\nas.numeric(all_trials$item)\n\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [75] 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[112] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[149] 2 2 2 2 2 2 2 2 2 2 2 2\n\n\nHere is how we supply that to fit_wienr:\n\n\nCode\n(recog_fit &lt;- fit_wienr(rt = all_trials$rt, response = all_trials$response, drift_index = as.numeric(all_trials$item)))\n\n\n$par\n      a[1]       v[1]       v[2]       w[1]      t0[1] \n 2.0345129  0.3167632 -0.7274032  0.5145780  0.2058107 \n\n$value\n[1] 219.4175\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n 0.04339481  0.00000000  1.00000000  1.00000000 \n\n\nAs we can see, the estimated drift rates v[1] and v[2] go in the direction we would expect, given that drift_index = 1 indicates a target (positive drift) and drift_index = 2 indicates a foil (negative drift).\nAnd how well does the best-fitting model do? Again, we can supply drift_index to the qp_fit function and make a set of quantile-probability plots.\n\n\nCode\nrecog_obs_fit_data &lt;- qp_fit(rt = all_trials$rt, response = all_trials$response, par = recog_fit$par, drift_index = as.numeric(all_trials$item))\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response, p_resp, rt_p, rt_q, source)`\n\n\nCode\nrecog_obs_fit_data %&gt;%\n    mutate(drift_index_label = factor(drift_index, levels = 1:2, labels = c(\"Target\", \"Foil\"))) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = source, shape = response)) +\n    geom_line(aes(group = interaction(rt_p, source), linetype = source), alpha = 0.5) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    facet_wrap(\"drift_index_label\") +\n    labs(x = \"Response probability\", y = \"RT Quantile (s)\", color = NULL, linetype = NULL, shape = \"Response\")\n\n\n\n\n\n\n\n\n\nNot too bad, though as we saw earlier, the fit isn’t as good for errors or for the tails of the RT distributions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#comparing-model-fits",
    "href": "diffusion_fit.html#comparing-model-fits",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.4 Comparing model fits",
    "text": "5.4 Comparing model fits\nContinuing with the recognition memory example, imagine that we wanted to address the question: Can this participant distinguish between studied and unstudied items? That question can be reframed in terms of diffusion model parameters: is the drift rate the same or different between target and foil trials?\nTo address that question, we can fit one version of a diffusion model that uses the drift_index vector to estimate separate drift rates for targets and foils, like we just did. We can then fit another version that does not include drift_index, so that it estimates a single drift rate for all trials. The second model would correspond to the hypothesis that the participant cannot distinguish between targets and foils, because they get the same quality of evidence from their memory either way. By comparing how well those two models account for the data, taking into account the fact that the one-drift-rate model is less complex, then we can get evidence to help us address our question.\nIn the previous section, we already fit the two-drift-rate model. Now let’s fit the one-drift-rate version:\n\n\nCode\n(recog_fit_onedrift &lt;- fit_wienr(rt = all_trials$rt, response = all_trials$response))\n\n\n$par\n      a[1]       v[1]       w[1]      t0[1] \n 1.9376960 -0.1943884  0.5129813  0.2166252 \n\n$value\n[1] 239.2321\n\n$convergence\n[1] 4\n\n$message\n[1] \"Stopped by zero step from line search\"\n\n$invhessian.lt\n [1] 1 0 0 0 1 0 0 1 0 1\n\n$info\nmaxgradient    laststep     stepmax       neval \n 0.06124639  0.00000000  1.00000000  1.00000000 \n\n\n\n5.4.1 Information criteria\nTo compare the fit of the two models, we have a number of techniques at our disposal, but one of the most common is to use an information criterion. These values essentially “score” a model, with higher scores being worse (like golf). The score takes into account how well the model fits the data as well as how complex the model is. Taking into account complexity is critical because, generally speaking, a more complex model will be able to fit data better, so it needs to be “handicapped” to account for this advantage (again, sort of like golf). The information criteria we will use here measure a model’s complexity in terms of the number of free parameters it has.\n\n5.4.1.1 Akaike Information Criterion (AIC)\nThe Akaike Information Criterion (AIC, Akaike, 1974) is defined: \\[\nAIC = 2 \\times NLL + 2 \\times k\n\\] where \\(NLL\\) is the negative log-likelihood of the fitted model (i.e., the quantity that is minimized during model fitting) and \\(k\\) is the number of free parameters in the model.\nWhen we use fit_wienr, the negative log-likelihood is the $value entry in the result. Meanwhile, we can get the number of free parameters as the length of the vector of best-fitting parameter estimates, as illustrated below:\n\n\nCode\naic_twodrift &lt;- 2 * recog_fit$value + 2 * length(recog_fit$par)\naic_onedrift &lt;- 2 * recog_fit_onedrift$value + 2 * length(recog_fit_onedrift$par)\n\nc(\"Two drift\" = aic_twodrift, \"One drift\" = aic_onedrift)\n\n\nTwo drift One drift \n 448.8351  486.4642 \n\n\nRecall that lower scores are better. Since the two-drift model has the lower AIC, we have evidence that this (simulated) participant is able to distinguish between targets and foils.\n\n\n5.4.1.2 Bayesian Information Criterion (BIC)\nThe Bayesian Information Criterion (BIC, Schwarz (1978)) is similar to the AIC but places a stronger penalty on the number of free parameters. Specifically, the penalty scales up with the logarithm of the number of observations. Letting \\(N\\) stand for the number of observed trials, the BIC is defined \\[\nBIC = 2 \\times NLL + k \\log N\n\\] where, again, \\(NLL\\) is the negative log-likelihood and \\(k\\) is the number of free parameters. We can now calculate BIC for each model:\n\n\nCode\nbic_twodrift &lt;- 2 * recog_fit$value + log(nrow(all_trials)) * length(recog_fit$par)\nbic_onedrift &lt;- 2 * recog_fit_onedrift$value + log(nrow(all_trials)) * length(recog_fit_onedrift$par)\n\nc(\"Two drift\" = bic_twodrift, \"One drift\" = bic_onedrift)\n\n\nTwo drift One drift \n 464.2109  498.7649 \n\n\nOnce again, the two-drift model gets the lower—and therefore better—score.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#shiny-app",
    "href": "diffusion_fit.html#shiny-app",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.5 Shiny App",
    "text": "5.5 Shiny App\nThe “Manual parameter fitting” tab of the Shiny app from the previous chapter allows you to try searching for optimal parameters yourself. You will find how difficult it is to do by hand! There is also a “Parameter recovery” tab that replicates what we did in this chapter, namely, using the diffusion model to simulate data and then fitting the diffusion model to the simulated data. Finally, note that the App allows you to play around with other parameters, like the trial-by-trial variability parameters, that we did not use in this chapter.\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/blast_data.rdata\", \"blast_data.rdata\")\nload(\"blast_data.rdata\")\n\n\n\n\nCode\nglimpse(blast_data)\n\n\nRows: 21,628\nColumns: 15\n$ dateCompleted    &lt;chr&gt; \"30/6/2017 @ 10:15:24\", \"30/6/2017 @ 10:15:26\", \"30/6…\n$ block            &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ blockType        &lt;fct&gt; Speed, Speed, Speed, Speed, Speed, Speed, Speed, Spee…\n$ trial            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17…\n$ stimulus         &lt;chr&gt; \"nonBlastEasy/SNE_25598565.jpg\", \"blastHard/BL_406213…\n$ difficulty       &lt;fct&gt; Easy, Hard, Easy, Hard, Hard, Easy, Easy, Hard, Easy,…\n$ response         &lt;fct&gt; Non-blast, Blast, Blast, Blast, Non-blast, Non-blast,…\n$ rt               &lt;dbl&gt; 0.662, 0.496, 0.528, 0.431, 0.817, 0.495, 0.540, 0.68…\n$ correct_response &lt;fct&gt; Non-blast, Blast, Blast, Blast, Blast, Non-blast, Non…\n$ bias_shown       &lt;fct&gt; Bias not shown, Bias not shown, Bias not shown, Bias …\n$ subject          &lt;chr&gt; \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002…\n$ group            &lt;fct&gt; Experienced, Experienced, Experienced, Experienced, E…\n$ nomt_corr        &lt;dbl&gt; 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 9…\n$ nomt_n           &lt;int&gt; 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108…\n$ nomt             &lt;dbl&gt; 0.9166667, 0.9166667, 0.9166667, 0.9166667, 0.9166667…\n\n\n\n\nCode\nblast_data_cond &lt;- blast_data %&gt;%\n    filter(group == \"Inexperienced\", subject == \"M003\", blockType == \"Accuracy\")\n\n\n\n\nCode\nfit_model_nosv &lt;- fit_wienr(rt = blast_data_cond$rt, response = (blast_data_cond$response == \"Blast\") + 1, fit_sv = F, fit_sw = F, fit_st0 = F, optim_control = list(trace = 1))\n\nfit_model_wsv &lt;- fit_wienr(rt = blast_data_cond$rt, response = (blast_data_cond$response == \"Blast\") + 1, fit_sv = T, fit_sw = F, fit_st0 = F, optim_control = list(trace = 1))\n\n\n\n\nCode\nto_fit &lt;- expand_grid(fit_sv = c(TRUE, FALSE), fit_sw = c(TRUE, FALSE), fit_st0 = c(TRUE, FALSE)) %&gt;%\n    mutate(nll = NA, np = NA)\n\nfits &lt;- list()\n\nfor (i in 1:nrow(to_fit)) {\n    fits[[i]] &lt;- fit_wienr(rt = blast_data_cond$rt, response = (blast_data_cond$response == \"Blast\") + 1, fit_sv = to_fit$fit_sv[i], fit_sw = to_fit$fit_sw[i], fit_st0 = to_fit$fit_st0[i], optim_control = list(trace = 1))\n    \n    to_fit$nll[i] &lt;- fits[[i]]$value\n    to_fit$np[i] &lt;- length(fits[[i]]$par)\n    to_fit$nobs[i] &lt;- nrow(blast_data_cond)\n}\n\nto_fit %&gt;%\n    mutate(nobs = nrow(blast_data_cond)) %&gt;%\n    mutate(aic = 2 * nll + 2 * np, bic = 2 * nll + log(nobs) * np) %&gt;%\n    mutate(daic = exp(-0.5 * (aic - min(aic))), dbic = exp(-0.5 * (bic - min(bic)))) %&gt;%\n    mutate(waic = daic / sum(daic), wbic = dbic / sum(dbic))\n\n\n\n\nCode\nlibrary(modelr)\n\nto_fit &lt;- blast_data %&gt;%\n    data_grid(nesting(group, subject), blockType)\n\nmodel_pars &lt;- c()\nmodel_pred &lt;- c()\n\npb &lt;- txtProgressBar(min = 0, max = nrow(to_fit), initial = 0, style = 3)\n\nfor (fit_index in 1:nrow(to_fit)) {\n    this_subj_data &lt;- semi_join(blast_data, to_fit[fit_index,]) %&gt;%\n        mutate(\n            drift_index = as.numeric(interaction(difficulty, correct_response))\n        )\n    \n    this_fit_init &lt;- fit_wienr(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        fit_sv = F,\n        fit_sw = F,\n        fit_st0 = F,\n        optim_control = list(trace = 1),\n        drift_index = this_subj_data$drift_index\n    )\n    \n    this_fit &lt;- fit_wienr(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        fit_sv = TRUE,\n        fit_sw = F,\n        fit_st0 = TRUE,\n        init_par = this_fit_init$par,\n        optim_control = list(trace = 1),\n        drift_index = this_subj_data$drift_index\n    )\n    \n    this_ddm_pars &lt;- coef(this_ddm_fit, dpar = \"full\")\n    \n    ddm_pars &lt;- rbind(\n        ddm_pars,\n        cbind(to_fit[fit_index,], tibble(par_name = names(this_ddm_pars), val = this_ddm_pars) %&gt;% extract(par_name, into = c(\"coef\", \"dpar\"), regex = \"(.+) \\\\((.+)\\\\)\"))\n    )\n    \n    this_pred_pars &lt;- this_subj_data %&gt;%\n        mutate(rownum = 1:nrow(this_subj_data)) %&gt;%\n        group_by(blockType, difficulty, correct_response) %&gt;%\n        summarize(n = n(), i = first(rownum), .groups = \"keep\") %&gt;%\n        mutate(a = c(this_ddm_fit$mmatrix$boundary[i,] %*% as.matrix(this_ddm_fit$coefficients$boundary))) %&gt;%\n        mutate(v = c(this_ddm_fit$mmatrix$drift[i,] %*% as.matrix(this_ddm_fit$coefficients$drift))) %&gt;%\n        mutate(t0 = c(this_ddm_fit$mmatrix$ndt[i,] %*% as.matrix(this_ddm_fit$coefficients$ndt))) %&gt;%\n        mutate(bias = c(this_ddm_fit$mmatrix$bias[i,] %*% as.matrix(this_ddm_fit$coefficients$bias))) %&gt;%\n        mutate(sv = c(this_ddm_fit$mmatrix$sv[i,] %*% as.matrix(this_ddm_fit$coefficients$sv))) %&gt;%\n        # mutate(sv = 0) %&gt;%\n        mutate(z = bias * a)\n    \n    this_pred_data &lt;- c()\n    \n    for (i in 1:nrow(this_pred_pars)) {\n        p_resp_upper &lt;- pdiffusion(rt = 5, response = \"upper\", a = this_pred_pars$a[i], v = this_pred_pars$v[i], t0 = this_pred_pars$t0[i], z = this_pred_pars$z[i], sv = this_pred_pars$sv[i], maxt = 5)\n        p_resp_lower &lt;- pdiffusion(rt = 5, response = \"lower\", a = this_pred_pars$a[i], v = this_pred_pars$v[i], t0 = this_pred_pars$t0[i], z = this_pred_pars$z[i], sv = this_pred_pars$sv[i], maxt = 5)\n        \n        upper_q &lt;- qdiffusion(p = rt_quantiles, response = \"upper\", a = this_pred_pars$a[i], v = this_pred_pars$v[i], t0 = this_pred_pars$t0[i], z = this_pred_pars$z[i], sv = this_pred_pars$sv[i], scale_p = TRUE, maxt = 5, interval = c(0, 5))\n        lower_q &lt;- qdiffusion(p = rt_quantiles, response = \"lower\", a = this_pred_pars$a[i], v = this_pred_pars$v[i], t0 = this_pred_pars$t0[i], z = this_pred_pars$z[i], sv = this_pred_pars$sv[i], scale_p = TRUE, maxt = 5, interval = c(0, 5))\n        \n        this_pred_data &lt;- rbind(\n            this_pred_data,\n            cbind(this_pred_pars[i,], tibble(response = \"Blast\", p_resp = p_resp_upper / (p_resp_upper + p_resp_lower), rt_p = rt_quantiles, rt_q = upper_q)),\n            cbind(this_pred_pars[i,], tibble(response = \"Non-blast\", p_resp = p_resp_lower / (p_resp_upper + p_resp_lower), rt_p = rt_quantiles, rt_q = lower_q))\n        )\n    }\n    \n    ddm_pred &lt;- rbind(\n        ddm_pred,\n        cbind(to_fit[fit_index,], this_pred_data)\n    )\n    \n    setTxtProgressBar(pb, fit_index)\n}\n\nclose(pb)\n\nddm_pars %&gt;%\n    ggplot(aes(x = coef, y = val, color = group, shape = group)) +\n    geom_point(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.4), alpha = 0.5, size = 0.5) +\n    stat_summary(geom = \"pointrange\", fun.data = mean_cl_boot, position = position_dodge(width = 0.4)) +\n    facet_wrap(\"dpar\", scales = \"free\")\n\nobs_rt_quantiles &lt;- blast_data %&gt;%\n    group_by(group, subject, blockType, difficulty, correct_response, response) %&gt;%\n    reframe(rt_q = quantile(rt, probs = rt_quantiles)) %&gt;%\n    mutate(rt_p = rep(rt_quantiles, n() / length(rt_quantiles))) %&gt;%\n    complete(nesting(group, subject), blockType, difficulty, correct_response, response, rt_p, fill = list(rt_q = NA))\n\nobs_p_resp &lt;- blast_data %&gt;%\n    group_by(group, subject, blockType, difficulty, correct_response, response) %&gt;%\n    summarize(n_resp = n(), .groups = \"keep\") %&gt;%\n    ungroup() %&gt;%\n    complete(nesting(group, subject), blockType, difficulty, correct_response, response, fill = list(n_resp = 0)) %&gt;%\n    group_by(group, subject, blockType, difficulty, correct_response) %&gt;%\n    mutate(p_resp = n_resp / sum(n_resp))\n\nobs_pred_data &lt;- full_join(\n    full_join(obs_p_resp, obs_rt_quantiles) %&gt;% mutate(source = \"Observed\"),\n    ddm_pred %&gt;% mutate(source = \"Predicted\")\n) %&gt;%\n    mutate(correct = factor(correct_response == response, levels = c(TRUE, FALSE), labels = c(\"Correct\", \"Incorrect\")))\n\nobs_pred_data %&gt;%\n    group_by(blockType, difficulty, correct_response, response, correct, source, rt_p) %&gt;%\n    summarize(rt_q = mean(rt_q, na.rm = TRUE), p_resp = mean(p_resp, na.rm = TRUE)) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = interaction(correct, correct_response))) +\n    geom_point(aes(alpha = difficulty, shape = source)) +\n    geom_line(aes(linetype = source, group = interaction(correct, correct_response, rt_p, source))) +\n    facet_wrap(\"blockType\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "diffusion_fit.html#exercises",
    "href": "diffusion_fit.html#exercises",
    "title": "5  Fitting a diffusion model to data",
    "section": "5.6 Exercises",
    "text": "5.6 Exercises\n\nConsider a dataset with one particularly short RT. Would you want to allow for variability in residual time when fitting these data? Why or why not?\nUsing the Shiny App, see if you can “fool” the model! Specifically, try simulating data until there is a notable discrepancy between the best-fitting parameter values and the values you used to simulate the data. What features of the simulated data may have resulted in this discrepancy?\nWe saw an example in the chapter of how drift rates might vary between conditions of an experiment even while the other parameters of the model would stay the same.\n\nWhat other examples can you think of where the properties of the evidence change but other model parameters do not?\nGive an example of a situation in which you would expect response boundaries to differ between conditions, but not drift rates.\nGive an example of a situation in which you would expect residual time to differ between conditions, but not drift rates or boundaries.\n\nRepeat our recognition memory simulations and model comparisons, but instead of simulating data where the drift rate actually differs between targets and foils, simulate data in which targets and foils have the same drift rate. Use both AIC and BIC to compare the fits of the two-drift and one-drift models. Do these information criteria favor the “correct” model?\n\n\n\n\n\nAkaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19(6), 716–723.\n\n\nBlurton, S. P., Kesselmeier, M., & Gondan, M. (2012). Fast and accurate calculations for cumulative first-passage time distributions in wiener diffusion models. Journal of Mathematical Psychology, 56(6), 470–475. https://doi.org/https://doi.org/10.1016/j.jmp.2012.09.002\n\n\nGondan, M., Blurton, S. P., & Kesselmeier, M. (2014). Even faster and even more accurate first-passage time densities and distributions for the wiener diffusion model. Journal of Mathematical Psychology, 60, 20–22. https://doi.org/https://doi.org/10.1016/j.jmp.2014.05.002\n\n\nHartmann, R., & Klauer, K. C. (2021). Partial derivatives for the first-passage time distribution in wiener diffusion models. Journal of Mathematical Psychology, 103, 102550. https://doi.org/https://doi.org/10.1016/j.jmp.2021.102550\n\n\nHartmann, R., & Klauer, K. C. (2023). WienR: Derivatives of the first-passage time density and cumulative distribution function, and random sampling from the (truncated) first-passage time distribution. https://CRAN.R-project.org/package=WienR\n\n\nNavarro, D. J., & Fuss, I. G. (2009). Fast and accurate calculations for first-passage times in wiener diffusion models. Journal of Mathematical Psychology, 53(4), 222–230. https://doi.org/https://doi.org/10.1016/j.jmp.2009.02.003\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85(2), 59–108.\n\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2), 461–464.\n\n\nTuerlincx, F. (2004). The efficient computation of the cumulative distribution and probability density functions in the diffusion model. Behavior Research Methods, Instruments, & Computers, 36(4), 702–716.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Fitting a diffusion model to data</span>"
    ]
  },
  {
    "objectID": "blast_example.html",
    "href": "blast_example.html",
    "title": "6  A worked example",
    "section": "",
    "text": "6.1 The data\nThis chapter presents a complete worked example of applying the diffusion model to a two-choice task. In doing so, we illustrate the kinds of data that can be modeled within this framework, how to fit the diffusion model to a typical cognitive dataset, and some ways we can use the resulting fits to draw inferences about the cognitive processes behind the choices people made.\nThe data for this example were reported originally by Trueblood et al. (2018). There’s a lot about this study that we won’t get to here, and I encourage you to check out the original paper.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#the-data",
    "href": "blast_example.html#the-data",
    "title": "6  A worked example",
    "section": "",
    "text": "6.1.1 Participants and procedures\nParticipants in this study did several blocks of a categorization task. The stimuli used in this task were images of cells that were either indicative of cancer—these are called “blast” cells—or normal—these are “non-blast” cells. The images were further subdivided into “easy” and “hard” versions, based on expert judgments. The image below illustrates the kinds of images that participants would see in this task.\n\n\nCode\nknitr::include_graphics(\"img/blast_example_stimuli.png\")\n\n\n\n\n\n(a) An easy blast image. (b) A hard blast image. (c) An easy non-blast image. (d) A hard non-blast image.\n\n\n\n\nAfter several blocks of training in which participants became familiar with these kinds of images (if they were not already; see below), participants moved on to the categorization task. On each trial of this task, an image was shown. Blast and non-blast images were shown equally often. Easy and hard versions of each type were also shown at the same rates. The participant’s job was to decide whether or not each image was a “blast” cell. The categorization task was itself divided into several blocks, each of which was a different type. We will be looking at data from two types of block: “Accuracy” blocks in which participants were encouraged to take their time and be accurate in their categorization of each image; and “Speed” blocks in which participants were encouraged to make their decisions quickly without regard to accuracy.\nThe participants in this study came from three different groups. Novice participants were just that—typical undergraduate university students who had no prior experience with these kinds of medical images. Inexperienced participants were pathologists who had just begun their training, so while they would be knowledgeable about these kinds of images, they might not have much practice categorizing them. Experienced participants were pathologists who had completed at least four training rotations who would have had plenty of practice dealing with these kinds of images.\nFinally, I note that, in addition to the blast/non-blast categorization task, all participants did a “Novel Object Memory Task” (NOMT) designed to measure their general ability to recognize visual objects, not just medical images of cells.\n\n\n6.1.2 Getting the data\nYou can download the data from this study that we will be examining in this tutorial by running the code below. The first line downloads the data to a file called blast_data.rdata in your current working directory. The second line loads that data into your R environment.\n\n\nCode\ndownload.file(\"https://github.com/gregcox7/choice_rt_models/raw/refs/heads/main/data/blast_data.rdata\", \"blast_data.rdata\")\nload(\"blast_data.rdata\")\n\n\nThe data should now be in your R environment in a data frame called blast_data. Let’s take a look at that data now:\n\n\nCode\nglimpse(blast_data)\n\n\nRows: 21,628\nColumns: 15\n$ dateCompleted    &lt;chr&gt; \"30/6/2017 @ 10:15:24\", \"30/6/2017 @ 10:15:26\", \"30/6…\n$ block            &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ blockType        &lt;fct&gt; Speed, Speed, Speed, Speed, Speed, Speed, Speed, Spee…\n$ trial            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17…\n$ stimulus         &lt;chr&gt; \"nonBlastEasy/SNE_25598565.jpg\", \"blastHard/BL_406213…\n$ difficulty       &lt;fct&gt; Easy, Hard, Easy, Hard, Hard, Easy, Easy, Hard, Easy,…\n$ response         &lt;fct&gt; Non-blast, Blast, Blast, Blast, Non-blast, Non-blast,…\n$ rt               &lt;dbl&gt; 0.662, 0.496, 0.528, 0.431, 0.817, 0.495, 0.540, 0.68…\n$ correct_response &lt;fct&gt; Non-blast, Blast, Blast, Blast, Blast, Non-blast, Non…\n$ bias_shown       &lt;fct&gt; Bias not shown, Bias not shown, Bias not shown, Bias …\n$ subject          &lt;chr&gt; \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002\", \"M002…\n$ group            &lt;fct&gt; Experienced, Experienced, Experienced, Experienced, E…\n$ nomt_corr        &lt;dbl&gt; 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 9…\n$ nomt_n           &lt;int&gt; 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108…\n$ nomt             &lt;dbl&gt; 0.9166667, 0.9166667, 0.9166667, 0.9166667, 0.9166667…\n\n\nWe can already see the columns that will be most important for us:\n\nblockType: Whether the block instructions emphasized Accuracy or Speed.\ncorrect_response: Whether the image on that trial was a Blast or Non-blast cell.\ndifficulty: Whether the image on that trial was Easy or Hard.\nrt: The response time (RT) in seconds.\nresponse: Whether the participant classified the image as a Blast or Non-blast cell.\nsubject: An identifier for each individual participant.\ngroup: Which of the three groups the participant came from (Experienced, Inexperienced, or Novice).\nnomt: The score on the Novel Object Memory Test (NOMT) for the participant on that trial.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#a-single-participant",
    "href": "blast_example.html#a-single-participant",
    "title": "6  A worked example",
    "section": "6.2 A single participant",
    "text": "6.2 A single participant\nIn the next section, we will fit a diffusion model to data from every participant. Before we do that, though, let’s see how to do it for a single participant. We will replicate this procedure for each individual participant in the next section.\n\n6.2.1 A single participant’s data\nI arbitrarily picked the participant with ID “M003” for us to examine. The code below uses the filter function to extract the data from just this participant:\n\n\nCode\nsubj_data &lt;- blast_data %&gt;%\n    filter(subject == \"M003\")\n\n\n\n\n6.2.2 Grouping the trials\nFor the next bit, make sure that you have sourced the wienr_fit_utils.r script:\n\n\nCode\nsource(\"wienr_fit_utils.r\")\n\n\nIf we omit the par argument, we can use the qp_fit function to get the observed response proportions and RT quantiles and make a quantile-probability plot of the observed data. However, to do this, we need to decide how to group the individual trials using the “indexing” trick we used in the last chapter. The way we do this will ultimately inform what diffusion model parameters we will estimate, so it is worth putting in the thought now.\nSpecifically, we need to think about what factors would influence the drift rate of the evidence being accumulated on each trial, what factors would influence how the participant sets their response boundaries on a given trial, and what factors might influence the residual time on each trial. Later, we will also consider how trial-by-trial variability in these three aspects of the model might or might not vary between conditions.\n\n6.2.2.1 What factors influence drift rates?\nThe “evidence” in this task arises from some kind of evaluation of how much the image looks like what the participant thinks of as a “blast” cell versus a “non-blast” cell. In other words, the “evidence” should depend on whether the image on that trial shows a blast or non-blast cell, just like how “evidence” in recognition memory depends on whether the test item is a target or foil. In addition, we would expect “hard” images to yield worse evidence than “easy” images, by definition. These two aspects of the data are reflected in the difficulty and correct_response columns. So we can specify a drift_index based on the interaction between these two factors.\nThe emphasis of the current block—Accuracy vs. Speed—could also impact drift rates (Rae et al., 2014), though exploring that possibility is left as an exercise for the reader.\n\n\n6.2.2.2 What factors influence response boundaries?\nThe response boundaries cannot be influenced by the type of image shown on a trial—if they were, then the participant would already know what kind of image they were seeing! On the other hand, it is reasonable to expect that participants would adjust their response boundaries depending on whether the current block emphasized speed or accuracy. This suggests that we can define a bound_index using the blockType column in the data.\n\n\n6.2.2.3 What factors influence residual time?\nIf residual time reflects only the processes involved in executing the motor response associated with a choice, then we might expect it to be unaffected by any experimental factors. On the other hand, it may be that participants are able to adjust their “response vigor” in light of speed/accuracy emphasis. In addition, it may be that participants can more quickly orient their attention to a stimulus if speed is emphasized. So we can specify a resid_index that also depends on blockType.\n\n\n6.2.2.4 Defining indices\nOn the basis of the considerations above, we will define three indices: one that specifies what conditions can have different drift rates (drift_index), one that specifies what conditions can have different response boundaries (bound_index), and one that specifies what conditions can have different residual time (resid_index):\n\n\nCode\nsubj_data &lt;- subj_data %&gt;%\n    mutate(\n        drift_index = as.numeric(interaction(difficulty, correct_response)),\n        bound_index = as.numeric(blockType),\n        resid_index = as.numeric(blockType)\n    )\n\n\nIt is important to keep in mind that the grouping defined above is not necessarily the “one true grouping”! It is merely meant to give a sense of the kind of things to think about when deciding how different model parameters will be assigned to different conditions.\n\n\n\n6.2.3 Plotting the observed data\nHaving defined our indices, we can pass them to the qp_fit function so that we can make a quantile-probability plot of this participant’s data. Note that I had to\n\n\nCode\nobs_qp &lt;- qp_fit(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\n\nJoining with `by = join_by(drift_index, bound_index, resid_index, sv_index,\nsw_index, st0_index, response)`\n\n\nWhen making the plot, I found it helpful to “undo” the transformation of the different factors into numerical indices. That “undoing” is the purpose of the two mutate lines.\n\n\nCode\nobs_qp %&gt;%\n    mutate(item_type = factor(drift_index, levels = 1:4, labels = levels(interaction(blast_data$difficulty, blast_data$correct_response)))) %&gt;%\n    mutate(blockType = factor(bound_index, levels = 1:2, labels = levels(blast_data$blockType))) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = item_type, shape = response)) +\n    geom_point() +\n    expand_limits(x = c(0, 1)) +\n    labs(x = \"Response probability\", y = \"RT quantile\") +\n    facet_wrap(\"blockType\")\n\n\n\n\n\n\n\n\n\nIt is worth noting a few features of these data that are apparent from the quantile-probability plot. First, this participant was indeed faster in the Speed block than the Accuracy block. Even the faster RT’s (the 0.1 quantiles) are faster in the Speed block, supporting the idea that residual time could differ between blocks if residual time represents the minimal time needed to respond. It also looks like this participant was less accurate in the Speed block—at least for Blast images, they had nearly perfect accuracy in the Accuracy block but not in the speed block. This participant was not very good in either block at categorizing Non-blast images. It doesn’t look like difficulty (Easy vs. Hard) made a big difference for this participant in terms of their choice/RT behavior. Finally, it looks like this participant’s errors tended to be a bit slower than their correct responses, suggesting that the diffusion model will need to allow for trial-by-trial variability in drift rates to accommodate these data. This same consideration suggests that we don’t need to assume variability in boundaries (since that would produce fast errors instead).\n\n\n6.2.4 Fitting a diffusion model\nWith all the preliminaries out of the way, let’s try fitting a diffusion model to this participant’s data. This will look just like it did in the last chapter, only with real data instead of simulated data!\nWe have already decided how to assign parameters to trials using the indices we defined in the previous section. We also have good reason to believe that drift rates can vary from trial to trial. We can estimate \\(s_v\\), the standard deviation of the trial-by-trial distribution of drift rates, by including the argument fit_sv = TRUE to the fit_wienr function. We don’t have reason to assume variability in boundaries, which would be reflected in the \\(s_w\\) parameter, but we could do so if we passed fit_sw = TRUE to fit_wienr. Finally, we will allow for variability in residual time by including fit_st0 = TRUE in the function call to fit_wienr.\nFor present purposes, we will only estimate one value of \\(s_v\\) and one value of \\(s_{t_0}\\) parameter, and these values will apply to all trials. If we wanted to allow them to vary, we could pass a sv_index, sw_index, or st0_index vector to the fit_wienr function—these index vectors work just like the drift_index, bound_index, and resid_index vectors we defined above.\nPutting it all together, the code below fits our desired diffusion model to this participant’s choice and RT data.\n\n\nCode\nsubj_fit &lt;- fit_wienr(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    fit_sv = TRUE,\n    fit_sw = FALSE,\n    fit_st0 = TRUE,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\n\nLet’s have a look at the estimated parameter values:\n\n\nCode\nsubj_fit$par\n\n\n      a[1]       a[2]       v[1]       v[2]       v[3]       v[4]       w[1] \n 1.3875689  0.9074497 -0.9075545 -0.3305451  1.5610599  1.6110799  0.6583813 \n      w[2]      t0[1]      t0[2]      sv[1]     st0[1] \n 0.6743305  0.3969458  0.3926721  0.7117295  0.1218538 \n\n\nThe first two parameters are the response caution parameters, with a[1] corresponding to the Accuracy blocks and a[2] to the Speed blocks. As we might expect, the fact thata a[2] \\(&lt;\\) a[1] tells us that this participant was less cautious in the Speed blocks, being more willing to sacrifice accuracy for speed. Skipping ahead to w[1] and w[2], these parameters tell us that this participant was biased toward calling images “Blast” images in both Accuracy and Speed blocks (the response caution and response bias parameters have the same indices). Although we allowed for residual time to vary between Accuracy and Speed blocks, the estimates t0[1] and t0[2] look pretty similar to one another.\nThe drift rate parameters also make some sense: v[1], for easy non-blast images, is negative and has a greater magnitude than v[2], for hard non-blast images. The magnitudes of the drift rates for Blast images, v[3] and v[4], are greater than for the non-blast images and are not too different from one another, in accord with our observation that this participant was better at identifying blast images than non-blasts and that the difficulty of the blast image didn’t seem to matter much.\nFinally, we can see that the drift-rate variability parameter sv[1] and the residual time variability parameter st0[1] are both greater than zero. That said, we did not have strong theoretical reasons to expect these parameters to take any particular value—we just suspected they would be important to account for the data. We can verify that intuition by fitting a model without any trial-by-trial variability and seeing whether AIC and/or BIC still prefers the more complex model with both forms of variability.\n\n\nCode\nsubj_fit_novar &lt;- fit_wienr(\n    rt = subj_data$rt,\n    response = subj_data$response,\n    fit_sv = FALSE,\n    fit_sw = FALSE,\n    fit_st0 = FALSE,\n    drift_index = subj_data$drift_index,\n    bound_index = subj_data$bound_index,\n    resid_index = subj_data$resid_index\n)\n\naic_wvar &lt;- 2 * subj_fit$value + 2 * length(subj_fit$par)\naic_novar &lt;- 2 * subj_fit_novar$value + 2 * length(subj_fit_novar$par)\n\nbic_wvar &lt;- 2 * subj_fit$value + log(nrow(subj_data)) * length(subj_fit$par)\nbic_novar &lt;- 2 * subj_fit_novar$value + log(nrow(subj_data)) * length(subj_fit_novar$par)\n\nc(aic_wvar, aic_novar)\n\n\n[1]  8.878357 64.029238\n\n\nCode\nc(bic_wvar, bic_novar)\n\n\n[1]  56.68559 103.86860\n\n\nBoth AIC and BIC are lower for the model with trial-by-trial variability, suggesting that this additional complexity is warranted in light of the data.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#all-the-participants",
    "href": "blast_example.html#all-the-participants",
    "title": "6  A worked example",
    "section": "6.3 All the participants",
    "text": "6.3 All the participants\nHaving fit a diffusion model to one participant, we will now replicate that procedure for every participant. First, it will be convenient to define our three index vectors using the whole dataset:\n\n\nCode\nblast_data &lt;- blast_data %&gt;%\n    mutate(\n        drift_index = as.numeric(interaction(difficulty, correct_response, drop = TRUE)),\n        bound_index = as.numeric(blockType),\n        resid_index = as.numeric(blockType)\n    )\n\n\nNow comes the big stuff. We will write a for loop that does the following for each participant:\n\nExtracts that participant’s data from the complete dataset.\nFits a diffusion model to that participant’s data.\nExtracts the estimated parameters for that participant and saves them in a data frame called model_pars. This is so we can examine the estimated parameters later.\nComputes both observed and model-produced RT quantiles and response probabilities and saves them in a data frame called model_qp. This is so we can verify that the model is fitting the data.\n\nAll of that is accomplished with the following chunk of R code, which begins by using the unique function to extract all the unique participant ID’s in the dataset. Note that this is used to define what the for loop iterates over. This will take a while to run, but patience is a virtue!\n\n\nCode\nsubj_to_fit &lt;- unique(blast_data$subject)\n\nmodel_pars &lt;- c()\nmodel_qp &lt;- c()\n\nfor (id in subj_to_fit) {\n    this_subj_data &lt;- blast_data %&gt;%\n        filter(subject == id)\n    \n    this_fit &lt;- fit_wienr(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        fit_sv = TRUE,\n        fit_sw = FALSE,\n        fit_st0 = TRUE,\n        drift_index = this_subj_data$drift_index,\n        bound_index = this_subj_data$bound_index,\n        resid_index = this_subj_data$resid_index\n    )\n    \n    model_pars &lt;- rbind(\n        model_pars,\n        cbind(to_fit[fit_index,], tibble(par_name = names(this_fit$par), val = this_fit$par) %&gt;% extract(par_name, into = c(\"par\", \"index\"), regex = \"(.+)\\\\[(.+)\\\\]\"))\n    )\n    \n    this_qp &lt;- qp_fit(\n        rt = this_subj_data$rt,\n        response = (this_subj_data$response == \"Blast\") + 1,\n        par = this_fit$par,\n        drift_index = this_subj_data$drift_index,\n        bound_index = this_subj_data$bound_index,\n        resid_index = this_subj_data$resid_index\n    )\n    \n    model_qp &lt;- rbind(\n        model_qp,\n        cbind(to_fit[fit_index,], this_qp)\n    )\n}\n\n\n\n6.3.1 Comparing parameters between groups\nOnce we have our parameter estimates safely stored in model_pars, we can visualize the resulting estimates using color to distinguish between the three groups. The plot below was made by using tiny, slightly faded points for each individual participant (note the alpha = 0.5, size = 0.5 settings in the geom_point line). Overlaid on those is a big point with error bars that shows the mean and 95% confidence interval for the mean, computed separately for each group.\n\n\nCode\nmodel_pars %&gt;%\n    ggplot(aes(x = index, y = val, color = group, shape = group)) +\n    geom_point(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.4), alpha = 0.5, size = 0.5) +\n    stat_summary(geom = \"pointrange\", fun.data = mean_cl_boot, position = position_dodge(width = 0.4)) +\n    labs(x = \"Index\", y = \"Estimated value\", color = \"Group\") +\n    facet_wrap(\"par\", scales = \"free\")\n\n\n\n\n\n\n\n\n\n\n6.3.1.1 Response caution\nLet’s focus first on a, the response caution parameter. As we know, a[1] corresponds to the Accuracy blocks while a[2] corresponds to the Speed blocks. It certainly looks like participants, on average, had lower response caution in the Speed blocks than in the Accuracy blocks. It also looks like the more experienced participants tended to have greater response caution in both block types.\nTo get some statistical evidence for differences between groups and between conditions, we can use our old friend, the Analysis of Variance (ANOVA). While you might normally think of applying ANOVA to observed values, like mean response time or accuracy, it can be applied just as well to estimated parameter values. In both cases, we have a single value for each participant in each condition and we are testing the null hypothesis that the parameter estimate does not differ, on average, between conditions/groups.\nTo do ANOVA, I’ll use the afex R package and make sure to run its set_sum_contrasts() function (by default, R uses “treatment” contrasts, which are not always appropriate).\n\n\nCode\nlibrary(afex)\n\n\nLoading required package: lme4\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nRegistered S3 methods overwritten by 'car':\n  method                          from\n  influence.merMod                lme4\n  cooks.distance.influence.merMod lme4\n  dfbeta.influence.merMod         lme4\n  dfbetas.influence.merMod        lme4\n\n\n************\nWelcome to afex. For support visit: http://afex.singmann.science/\n\n\n- Functions for ANOVAs: aov_car(), aov_ez(), and aov_4()\n- Methods for calculating p-values with mixed(): 'KR', 'S', 'LRT', and 'PB'\n- 'afex_aov' and 'mixed' objects can be passed to emmeans() for follow-up tests\n- NEWS: library('emmeans') now needs to be called explicitly!\n- Get and set global package options with: afex_options()\n- Set orthogonal sum-to-zero contrasts globally: set_sum_contrasts()\n- For example analyses see: browseVignettes(\"afex\")\n************\n\n\n\nAttaching package: 'afex'\n\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\n\nCode\nset_sum_contrasts()\n\n\nsetting contr.sum globally: options(contrasts=c('contr.sum', 'contr.poly'))\n\n\nNow, we can use the aov_ez function to do the ANOVA on the a parameter estimates.\n\n\nCode\naov_ez(\n    id = \"subject\",      # Specify the name of the column that identifies unique participants\n    dv = \"val\",          # Specify the name of the column that contains the values to be analyzed\n    data = model_pars %&gt;% filter(par == \"a\"), # The data for this ANOVA is stored in \"model_pars\", but we are only interested in the estimates of the \"a\" parameter\n    between = \"group\",   # Specify the name of the column that identifies between-subject comparisons\n    within = \"index\"     # Specify the name of the column that identifies within-subject comparisons\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n       Effect    df  MSE          F  ges p.value\n1       group 2, 52 0.15  17.86 *** .264   &lt;.001\n2       index 1, 52 0.14 129.70 *** .544   &lt;.001\n3 group:index 2, 52 0.14   9.23 *** .145   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nAs we can see, there is a main effect of “group”, consistent with our observation that more experienced participants had higher response caution. There is also a main effect of “index”, consistent with our observation that participants tended to set lower response caution in Speed blocks. Finally, there is a significant interaction between “group” and “index”, although it looks from the graph above that this is likely to be a “fan” interaction, with a bigger increase from Speed to Accuracy for the more experienced participants.\n\n\n6.3.1.2 Drift rates\nNow, let’s consider the drift rate parameters. Again, we will use ANOVA to look for statistical evidence of differences in drift rates between groups and between conditions. Things are a little more complicated, though, because drift rate was allowed to vary by both difficulty and image type (blast vs. non-blast). To properly specify the ANOVA, then, we should “undo” the drift rate indices back into those original two factors. That’s what the mutate lines in the data specification do in the code below.\n\n\nCode\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\"))),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\")\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                             Effect    df  MSE          F   ges p.value\n1                             group 2, 52 1.65       0.02 &lt;.001    .980\n2                        difficulty 1, 52 0.25  68.87 ***  .052   &lt;.001\n3                  group:difficulty 2, 52 0.25     3.24 *  .005    .047\n4                  correct_response 1, 52 3.37 252.60 ***  .728   &lt;.001\n5            group:correct_response 2, 52 3.37  21.45 ***  .313   &lt;.001\n6       difficulty:correct_response 1, 52 0.83 164.02 ***  .300   &lt;.001\n7 group:difficulty:correct_response 2, 52 0.83  16.01 ***  .077   &lt;.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nThe ANOVA finds evidence for significant differences for all but “group” on its own. However, this analysis is a bit misleading in that, as you’ll recall, drift rates for non-blast images tend to be negative while drift rates for blast images tend to be positive. We may be more interested in analyzing how drift rates toward the correct response boundary may or may not differ between groups/conditions.\nTo do this, we can add another mutate line that reverses the sign of the estimated drift rates for non-blast images:\n\n\nCode\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\")),\n            val = if_else(correct_response == \"Blast\", val, -val)),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\")\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                             Effect    df  MSE          F   ges p.value\n1                             group 2, 52 3.37  21.45 ***  .313   &lt;.001\n2                        difficulty 1, 52 0.83 164.02 ***  .300   &lt;.001\n3                  group:difficulty 2, 52 0.83  16.01 ***  .077   &lt;.001\n4                  correct_response 1, 52 1.65       0.31  .002    .578\n5            group:correct_response 2, 52 1.65       0.02 &lt;.001    .980\n6       difficulty:correct_response 1, 52 0.25  68.87 ***  .052   &lt;.001\n7 group:difficulty:correct_response 2, 52 0.25     3.24 *  .005    .047\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nNow the ANOVA correctly detects a main effect of group that was obscured in the previous analysis, among other things.\n\n\n6.3.1.3 Individual differences\nFinally, recall that each participant also completed the “NOMT”, a test of general visual object processing ability. It would be reasonable to ask whether participants who have high NOMT scores also tend to have higher drift rates toward the correct response boundary. To analyze this, we need to first extract the NOMT scores for each participant, append them to the model parameter estimates, and include NOMT as a covariate in the ANOVA. For interpretability, I also “center” the NOMT scores by subtracting the group mean.\n\n\nCode\n# Extract NOMT scores and center them.\nnomt_scores &lt;- blast_data %&gt;%\n    group_by(group, subject) %&gt;%\n    summarize(nomt = first(nomt)) %&gt;%\n    mutate(nomt_centered = nomt - mean(nomt))\n\n\n`summarise()` has grouped output by 'group'. You can override using the\n`.groups` argument.\n\n\nCode\n# Append the NOMT scores to the parameter estimates\nmodel_pars_nomt &lt;- left_join(model_pars, nomt_scores)\n\n\nJoining with `by = join_by(group, subject)`\n\n\nCode\n# Run the same ANOVA as above, now including `nomt_centered` as a `covariate`\naov_ez(\n    id = \"subject\",\n    dv = \"val\",\n    data = model_pars_nomt %&gt;%\n        filter(par == \"v\") %&gt;%\n        mutate(\n            difficulty = factor(index, levels = 1:4, labels = c(\"Easy\", \"Hard\", \"Easy\", \"Hard\")),\n            correct_response = factor(index, levels = 1:4, labels = c(\"Non-blast\", \"Non-blast\", \"Blast\", \"Blast\")),\n            val = if_else(correct_response == \"Blast\", val, -val)),\n    between = \"group\",\n    within = c(\"difficulty\", \"correct_response\"),\n    covariate = \"nomt_centered\",\n    factorize = FALSE  # This last setting is necessary to ensure that \"nomt_centered\" isn't accidentally treated like a factor\n)\n\n\nAnova Table (Type 3 tests)\n\nResponse: val\n                                      Effect    df  MSE          F   ges\n1                                      group 2, 51 3.05  23.64 ***  .334\n2                              nomt_centered 1, 51 3.05     6.33 *  .063\n3                                 difficulty 1, 51 0.68 199.27 ***  .320\n4                           group:difficulty 2, 51 0.68  19.46 ***  .084\n5                   nomt_centered:difficulty 1, 51 0.68   12.18 **  .028\n6                           correct_response 1, 51 1.67       0.31  .002\n7                     group:correct_response 2, 51 1.67       0.02 &lt;.001\n8             nomt_centered:correct_response 1, 51 1.67       0.34  .002\n9                difficulty:correct_response 1, 51 0.24  71.48 ***  .057\n10         group:difficulty:correct_response 2, 51 0.24     3.36 *  .006\n11 nomt_centered:difficulty:correct_response 1, 51 0.24     2.97 +  .003\n   p.value\n1    &lt;.001\n2     .015\n3    &lt;.001\n4    &lt;.001\n5     .001\n6     .581\n7     .980\n8     .562\n9    &lt;.001\n10    .043\n11    .091\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nIn fact, it looks like NOMT not only has a main effect on drift rates, it also interacts with difficulty, suggesting that group differences alone do not account for individual differences in performance on this task—categorizing images of cells also seems to depend on general object processing ability.\n\n\n\n6.3.2 Visualizing model fit\nFinally, we come to the most challenging section: How to visualize the quality of the model fit. We could, of course, produce quantile-probability plots for each participant separately, but this would only be feasible with very few participants.\nInstead, the code below plots the observed and fitted RT quantiles and response probabilities averaged over the participants in each group. This is not meant to be the final word, but just a way to verify that the model is close to the data and that it is accurately reproducing the important aspects of the data.\n\n\nCode\nmodel_qp %&gt;%\n    mutate(\n        blockType = factor(bound_index, labels = levels(blast_data$blockType)),\n        item_type = factor(drift_index, labels = levels(interaction(blast_data$difficulty, blast_data$correct_response, sep = \" \", drop = T)))\n    ) %&gt;%\n    group_by(group, blockType, item_type, response, source, rt_p) %&gt;%\n    summarize(rt_q = mean(rt_q, na.rm = TRUE), p_resp = mean(p_resp, na.rm = TRUE)) %&gt;%\n    ggplot(aes(x = p_resp, y = rt_q, color = item_type)) +\n    geom_point(aes(shape = source), fill = \"white\") +\n    scale_linetype_manual(values = c(\"Observed\" = \"solid\", \"Fitted\" = \"dashed\")) +\n    scale_shape_manual(values = c(\"Observed\" = 16, \"Fitted\" = 21)) +\n    facet_grid(blockType ~ group, scales = \"free_y\")\n\n\n`summarise()` has grouped output by 'group', 'blockType', 'item_type',\n'response', 'source'. You can override using the `.groups` argument.\n\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's linetype values.\n\n\n\n\n\n\n\n\n\nThe upshot is that it looke like the model is, at least on average, doing a very good job of capturing the response proportion and a pretty good one capturing the RT quantiles. That said, some of the misfits for the highest and lowest quantiles (see, e.g., the green points in the “Speed” conditions) may be due to sampling error, as discussed earlier.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "blast_example.html#exercises",
    "href": "blast_example.html#exercises",
    "title": "6  A worked example",
    "section": "6.4 Exercises",
    "text": "6.4 Exercises\n\nRun an ANOVA analysis on other estimated model parameters, like bias (w), residual time (t0), and the two variability parameters (sv and st0). Do you find evidence for differences, on average, between groups or between conditions (for sv and st0, you can only compare between groups)?\nUsing the sv_index and st0_index parameters, modify the diffusion model we used above so that drift rate variability and residual time variability can also vary by block type. Does this more complex model provide a better account of the data, as scored by either AIC or BIC?\n\n\n\n\n\nRae, B., Heathcote, A., Donkin, C., Averell, L., & Brown, S. (2014). The hare and the tortoise: Emphasizing speed can change the evidence used to make decisions. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(5), 1226–1243.\n\n\nTrueblood, J. S., Holmes, W. R., Seegmiller, A. C., Douds, J., Compton, M., Szentirmai, E., Woodruff, M., Huang, W., Stratton, C., & Eichbaum, Q. (2018). The impact of speed and bias on the cognitive processes of experts and novices in medical image decision-making. Cognitive Research: Principles and Implications, 3, 1–14.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>A worked example</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Akaike, H. (1974). A new look at the\nstatistical model identification. IEEE Transactions on Automatic\nControl, 19(6), 716–723.\n\n\nAshby, F. G. (1983). A biased random walk model for two choice reaction\ntimes. Journal of Mathematical Psychology, 27,\n277–297.\n\n\nAshby, F. G. (2000). A stochastic version of general recognition theory.\nJournal of Mathematical Psychology, 44, 310–329.\n\n\nBaum, C. W., & Veeravalli, V. V. (1994). A sequential procedure for\nmultihypothesis testing. IEEE Transactions on\nInformation Theory, 40(6), 1994–2007.\n\n\nBlurton, S. P., Kesselmeier, M., & Gondan, M. (2012). Fast and\naccurate calculations for cumulative first-passage time distributions in\nwiener diffusion models. Journal of Mathematical Psychology,\n56(6), 470–475. https://doi.org/https://doi.org/10.1016/j.jmp.2012.09.002\n\n\nBogacz, R., Brown, E., Moehlis, J., Holmes, P., & Cohen, J. D.\n(2006). The physics of optimal decision making: A formal analysis of\nmodels of performance in two-alternative forced-choice tasks.\nPsychological Review, 113(4), 700–765.\n\n\nBogacz, R., & Gurney, K. (2007). The basal ganglia and cortex\nimplement optimal decision making between alternative actions.\nNeural Computation, 19, 442–477.\n\n\nBogacz, R., Usher, M., Zhang, J., & McClelland, J. L. (2007).\nExtending a biologically inspired model of choice: Multi-alternatives,\nnonlinearity and value-based multidimensional choice. Philosophical\nTransactions of the Royal Society B, 362, 1655–1670.\n\n\nBroadbent, D. E. (1957). A mechanical model for human attention and\nimmediate memory. Psychological Review, 64(3),\n205–215.\n\n\nBrown, S., & Heathcote, A. (2005). A ballistic model of choice\nresponse time. Psychological Review, 112(1), 117–128.\n\n\nBrown, S., & Heathcote, A. (2008). The simplest complete model of\nchoice response time: Linear ballistic accumulation. Cognitive\nPsychology, 57, 153–178.\n\n\nBusemeyer, J. R., & Townsend, J. T. (1993). Decision field theory: A\ndynamic–cognitive approach to decision making in an uncertain\nenvironment. Psychological Review, 100(3), 432–459.\n\n\nCox, G. E., & Shiffrin, R. M. (In press). Computational models of\nevent memory. In M. J. Kahana & A. Wagner (Eds.), Oxford\nhandbook of human memory. Oxford University Press.\n\n\nDonkin, C., Brown, S., Heathcote, A., & Wagenmakers, E.-J. (2011).\nDiffusion versus linear ballistic accumulation: Different models but the\nsame conclusions about psychological processes? Psychonomic Bulletin\n& Review, 55, 140–151.\n\n\nEdwards, W. (1965). Optimal strategies for seeking information: Models\nfor statistics, choice reaction times, and human information processing.\nJournal of Mathematical Psychology, 2, 312–329.\n\n\nGondan, M., Blurton, S. P., & Kesselmeier, M. (2014). Even faster\nand even more accurate first-passage time densities and distributions\nfor the wiener diffusion model. Journal of Mathematical\nPsychology, 60, 20–22. https://doi.org/https://doi.org/10.1016/j.jmp.2014.05.002\n\n\nHartmann, R., & Klauer, K. C. (2021). Partial derivatives for the\nfirst-passage time distribution in wiener diffusion models. Journal\nof Mathematical Psychology, 103, 102550.\nhttps://doi.org/https://doi.org/10.1016/j.jmp.2021.102550\n\n\nHartmann, R., & Klauer, K. C. (2023). WienR: Derivatives of the\nfirst-passage time density and cumulative distribution function, and\nrandom sampling from the (truncated) first-passage time\ndistribution. https://CRAN.R-project.org/package=WienR\n\n\nJones, M., Mozer, M., & Kinoshita, S. (2009). Optimal response\ninitiation: Why recent experience matters. In D. Koller, D. Schuurmans,\nY. Bengio, & L. Bottou (Eds.), Advances in neural information\nprocessing systems (Vol. 21, pp. 785–792).\n\n\nLaBerge, D. (1962). A recruitment theory of simple behavior.\nPsychometrika, 27(4), 375–396.\n\n\nLink, S. W. (1975). The relative judgment theory of two choice response\ntime. Journal of Mathematical Psychology, 12, 114–135.\n\n\nLink, S. W., & Heath, R. A. (1975). A sequential theory of\npsychological discrimination. Psychometrika, 40,\n77–105.\n\n\nMacmillan, N. A., & Creelman, C. D. (2005). Detection theory: A\nuser’s guide (2nd ed.). Erlbaum.\n\n\nNavarro, D. J., & Fuss, I. G. (2009). Fast and accurate calculations\nfor first-passage times in wiener diffusion models. Journal of\nMathematical Psychology, 53(4), 222–230.\nhttps://doi.org/https://doi.org/10.1016/j.jmp.2009.02.003\n\n\nNeisser, U. (1967). Cognitive psychology.\nAppleton-Century-Crofts.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most\nefficient tests of statistical hypotheses. Philosophical\nTransactions of the Royal Society of London. Series A, Containing Papers\nof a Mathematical or Physical Character, 231, 289–337.\n\n\nPike, R. (1973). Response latency models for signal detection.\nPsychological Review, 80(1), 53–68.\n\n\nRae, B., Heathcote, A., Donkin, C., Averell, L., & Brown, S. (2014).\nThe hare and the tortoise: Emphasizing speed can change the evidence\nused to make decisions. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 40(5), 1226–1243.\n\n\nRatcliff, R. (1978). A theory of memory retrieval. Psychological\nReview, 85(2), 59–108.\n\n\nRatcliff, R., & Rouder, J. N. (1998). Modeling response times for\ntwo-choice decisions. Psychological Science, 9(5),\n347–356.\n\n\nRatcliff, R., & Smith, P. L. (2004). A comparison of sequential\nsampling models for two-choice reaction time. Psychological\nReview, 111(2), 333–367.\n\n\nSchwarz, G. (1978). Estimating the dimension of a model. The Annals\nof Statistics, 6(2), 461–464.\n\n\nSingmann, H., Kellen, D., Cox, G. E., Chandramouli, S. H., Davis-Stober,\nC. P., Dunn, J. C., Gronau, Q. F., Kalish, M. L., McMullin, S. D.,\nNavarro, D. J., & Shiffrin, R. M. (2022). Statistics in the service\nof science: Don’t let the tail wag the dog. Computational Brain\n& Behavior.\n\n\nSmith, P. L. (2000). Stochastic dynamic models of response time and\naccuracy: A foundational primer. Journal of Mathematical\nPsychology, 44(3), 408–463.\n\n\nSmith, P. L., & Van Zandt, T. (2000). Time-dependent\nPoisson counter models of response latency in simple\njudgment. British Journal of Mathematical and Statistical\nPsychology, 53, 293–315.\n\n\nSmith, P. L., & Vickers, D. (1988). The accumulator model of\ntwo-choice decision. Journal of Mathematical Psychology,\n32, 135–168.\n\n\nStone, M. (1960). Models for choice-reaction time.\nPsychometrika, 25, 251–260.\n\n\nSwensson, R. G., & Green, D. M. (1977). On the relations between\nrandom walk models for two-choice response times. Journal of\nMathematical Psychology, 15, 282–291.\n\n\nTeodorescu, A. R., & Usher, M. (2013). Disentangling decision\nmodels: From independence to competition. Psychological Review,\n120(1), 1–38.\n\n\nTownsend, J. T., & Ashby, F. G. (1983). Stochastic modeling of\nelementary psychological processes. Cambridge University Press.\n\n\nTrueblood, J. S., Holmes, W. R., Seegmiller, A. C., Douds, J., Compton,\nM., Szentirmai, E., Woodruff, M., Huang, W., Stratton, C., &\nEichbaum, Q. (2018). The impact of speed and bias on the cognitive\nprocesses of experts and novices in medical image decision-making.\nCognitive Research: Principles and Implications, 3,\n1–14.\n\n\nTuerlincx, F. (2004). The efficient computation of the cumulative\ndistribution and probability density functions in the diffusion model.\nBehavior Research Methods, Instruments, & Computers,\n36(4), 702–716.\n\n\nUsher, M., & McClelland, J. L. (2001). The time course of perceptual\nchoice: The leaky, competing accumulator model. Psychological\nReview, 108(3), 550–592.\n\n\nUsher, M., & McClelland, J. L. (2004). Loss aversion and inhibition\nin dynamical models of multialternative choice. Psychological\nReview, 111(3), 757–769.\n\n\nVickers, D. (1970). Evidence for an accumulator model of psychophysical\ndiscrimination. Ergonomics, 13(1), 37–58.\n\n\nWald, A. (1945). Sequential tests of statistical hypotheses. The\nAnnals of Mathematical Statistics, 16(2), 117–186.\n\n\nZhang, J., & Chang, M. (in review). A Bayesian\nrandom-walk model of choice reaction times under prior knowledge of\ntarget onset uncertainty. Proceedings of the National Academy of\nSciences.",
    "crumbs": [
      "References"
    ]
  }
]