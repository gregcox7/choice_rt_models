<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Historical Perspectives – Modeling Choice and RT</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./random_walk.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7593ef76ee4b520e6bec3acdccc89eb3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./history.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historical Perspectives</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modeling Choice and RT</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./history.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historical Perspectives</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./random_walk.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Building a random walk model to simulate choice and RT</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./diffusion_sim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">From random walk to diffusion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#random-walk-and-diffusion-models" id="toc-random-walk-and-diffusion-models" class="nav-link active" data-scroll-target="#random-walk-and-diffusion-models"><span class="header-section-number">2.1</span> Random walk and diffusion models</a>
  <ul class="collapse">
  <li><a href="#the-sequential-probability-ratio-test" id="toc-the-sequential-probability-ratio-test" class="nav-link" data-scroll-target="#the-sequential-probability-ratio-test"><span class="header-section-number">2.1.1</span> The Sequential Probability Ratio Test</a></li>
  <li><a href="#random-walk" id="toc-random-walk" class="nav-link" data-scroll-target="#random-walk"><span class="header-section-number">2.1.2</span> Random Walk</a></li>
  <li><a href="#the-wiener-diffusion-process" id="toc-the-wiener-diffusion-process" class="nav-link" data-scroll-target="#the-wiener-diffusion-process"><span class="header-section-number">2.1.3</span> The Wiener Diffusion Process</a></li>
  <li><a href="#optimality-and-multiple-alternatives" id="toc-optimality-and-multiple-alternatives" class="nav-link" data-scroll-target="#optimality-and-multiple-alternatives"><span class="header-section-number">2.1.4</span> Optimality and Multiple Alternatives</a></li>
  </ul></li>
  <li><a href="#counter-and-accumulator-models" id="toc-counter-and-accumulator-models" class="nav-link" data-scroll-target="#counter-and-accumulator-models"><span class="header-section-number">2.2</span> Counter and Accumulator Models</a>
  <ul class="collapse">
  <li><a href="#counter-models" id="toc-counter-models" class="nav-link" data-scroll-target="#counter-models"><span class="header-section-number">2.2.1</span> Counter Models</a></li>
  <li><a href="#partially-correlated-accumulators" id="toc-partially-correlated-accumulators" class="nav-link" data-scroll-target="#partially-correlated-accumulators"><span class="header-section-number">2.2.2</span> Partially Correlated Accumulators</a></li>
  <li><a href="#ballistic-accumulators" id="toc-ballistic-accumulators" class="nav-link" data-scroll-target="#ballistic-accumulators"><span class="header-section-number">2.2.3</span> Ballistic Accumulators</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Historical Perspectives</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>This chapter provides some historical context for the development of the two main classes of choice-RT models: random walk and diffusion models, which are chiefly employed to model situations where people choose between two options; and counter/accumulator models, which can also model situations with two options but also apply to situations with more than two options.</p>
<section id="random-walk-and-diffusion-models" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="random-walk-and-diffusion-models"><span class="header-section-number">2.1</span> Random walk and diffusion models</h2>
<p>Early models of human choice behavior treated choice as a statistical decision of the sort described by <span class="citation" data-cites="NeymanPearson1933">Neyman &amp; Pearson (<a href="references.html#ref-NeymanPearson1933" role="doc-biblioref">1933</a>)</span>, in which a sample of data (e.g., a stimulus) is presumed to be drawn from a set of underlying generating distributions and the task of the participant is to select the distribution most likely to have generated the data. Specifically, the decision, given data <span class="math inline">\(x\)</span> and hypotheses <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span>, is governed by a likelihood ratio:</p>
<p><span class="math display">\[
L(x) = \frac{\Pr (H_1 | x)}{\Pr (H_0 | x)} = \frac{\Pr (x | H_1)}{\Pr (x | H_0)} \frac{\Pr (H_1)}{\Pr (H_0)} \text{.}
\]</span></p>
<p>If this ratio is greater than a threshold value <span class="math inline">\(\theta\)</span>, hypothesis <span class="math inline">\(H_1\)</span> is selected otherwise <span class="math inline">\(H_0\)</span> is chosen. Signal detection theory <span class="citation" data-cites="MacmillanCreelman2005">(<a href="references.html#ref-MacmillanCreelman2005" role="doc-biblioref">Macmillan &amp; Creelman, 2005</a>)</span> is the most prominent theoretical framework in this vein, and continues to be a useful and widely-applied model of choice. Its utility lies in being able to give clear interpretations to notions like bias (e.g., <span class="math inline">\(\theta\)</span>) and discriminability (proportional to <span class="math inline">\(\frac{\Pr (x | H_1)}{\Pr (x | H_0)}\)</span>). Signal detection theory, however, assumes that the decision is based on a fixed amount of evidence and thus ignores the dynamic process of evidence accumulation.</p>
<section id="the-sequential-probability-ratio-test" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="the-sequential-probability-ratio-test"><span class="header-section-number">2.1.1</span> The Sequential Probability Ratio Test</h3>
<p>The question of how, when evidence accumulates over time, one might <em>arrive at</em> a final decision was first treated by <span class="citation" data-cites="Wald1945">Wald (<a href="references.html#ref-Wald1945" role="doc-biblioref">1945</a>)</span>, who proposed a sequential probability ratio test (SPRT). Assume that data samples <span class="math inline">\(x_i\)</span>, <span class="math inline">\(i = 1, \dotsc, n\)</span>, arrive one at a time, and are sampled independently from the same underlying generating distribution, which is either <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_0\)</span>. Then, the order in which the samples arrive is immaterial (they are “exchangeable”) and to compute the likelihood ratio <span class="math inline">\(L(n)\)</span> given the <span class="math inline">\(n\)</span> samples we currently possess, we need only multiply the ratios for each sample:</p>
<p><span class="math display">\[
L(n) = \left[ \prod_{i=1}^n \frac{\Pr (x_i | H_1)}{\Pr (x_i | H_0)} \right] \frac{\Pr (H_1)}{\Pr (H_0)} \text{.}
\]</span></p>
<p>Thus, taking the logarithm of the likelihood ratio, we can express the change in log-likelihood that results from the <span class="math inline">\(t\)</span>th new sample:</p>
<p><span class="math display">\[
\Delta L(t) = \log \frac{\Pr (x_t | H_1)}{\Pr (x_t | H_0)} \text{,}
\]</span></p>
<p>where <span class="math inline">\(L(0) = \log \frac{\Pr (H_1)}{\Pr (H_0)}\)</span>, the log of the ratio of the priors. The question that Wald addressed in this context was when to stop collecting new data samples and make a decision. Define two thresholds, <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_0\)</span>, such that the decision maker will decide <span class="math inline">\(H_1\)</span> if <span class="math inline">\(L(t) \geq \theta_1\)</span> and will decide <span class="math inline">\(H_0\)</span> if <span class="math inline">\(L(t) \leq \theta_0\)</span> and <span class="math inline">\(\theta_1 &gt; 0 &gt; \theta_0\)</span>. Assuming the decision maker has a desired type I error rate <span class="math inline">\(\alpha\)</span> (probability of deciding in favor of <span class="math inline">\(H_1\)</span> when <span class="math inline">\(H_0\)</span> was the true generating distribution) and type II error rate <span class="math inline">\(\beta\)</span> (probability of deciding <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_1\)</span> is true), <span class="citation" data-cites="Wald1945">Wald (<a href="references.html#ref-Wald1945" role="doc-biblioref">1945</a>)</span> showed that the thresholds should be set such that <span class="math inline">\(\theta_1 \leq \log (1 - \beta) - \log \alpha\)</span> and <span class="math inline">\(\theta_0 \geq \log \beta - \log (1 - \alpha)\)</span> in order to achieve maximum power. The thresholds may not be exactly equal to the specified values as a consequence of the fact that evidence arrives in a discrete manner and hence might “jump” over a threshold rather than actually equaling it.</p>
<p>An important consequence of the SPRT is that the amount of evidence required to make a decision for either <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_0\)</span>—and thus, in general, the number of samples required to make a decision—is tightly coupled to the expected error rates. For example, if the decision maker is willing to make more type I errors (with rate <span class="math inline">\(\alpha\)</span>), then both <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_0\)</span> will decrease, reflecting an increased willingness to respond <span class="math inline">\(H_1\)</span> and <em>not</em> <span class="math inline">\(H_0\)</span> (assuming <span class="math inline">\(\beta\)</span> is held constant). This has the consequence that, on average, it will take less time (fewer samples) before the decision maker is willing to respond <span class="math inline">\(H_1\)</span> and more time (more samples) before the decision maker is willing to commit to <span class="math inline">\(H_0\)</span>. Thus, speed and accuracy can trade-off with one another, and the speed of particular responses (whether correct or incorrect) can be affected by the biases of the decision maker.</p>
<p><span class="citation" data-cites="Stone1960">Stone (<a href="references.html#ref-Stone1960" role="doc-biblioref">1960</a>)</span> suggested that the psychological process of decision making might be governed by something akin to the SPRT, an idea that received more explicit Bayesian treatment in <span class="citation" data-cites="Edwards1965">Edwards (<a href="references.html#ref-Edwards1965" role="doc-biblioref">1965</a>)</span>. Unfortunately, the SPRT predicts that the number of samples to reach a decision is independent of whether that decision was correct or not. That is, error and correct decision times are predicted to be equal (or, at least, drawn from the same distribution). This is very rarely true in observed data, hence a more general decision model is called for.</p>
</section>
<section id="random-walk" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="random-walk"><span class="header-section-number">2.1.2</span> Random Walk</h3>
<p>The sequential probability ratio test can be considered a kind of stationary random walk in discrete time and continuous space. This is a consequence of the fact that evidence arrives sequentially and perturbs the decision maker’s current beliefs (<span class="math inline">\(L(t)\)</span>) to a degree that is independent of those beliefs. Since the evidence acquired on each time step, <span class="math inline">\(x_t\)</span>, is sampled independently, we can treat the resulting likelihood ratio change <span class="math inline">\(\Delta L(t)\)</span> as an independent sample from some distribution. We can thus consider <span class="math inline">\(L(t)\)</span> to simply accumulate samples of a random variable with density <span class="math inline">\(f(\Delta L)\)</span> and moment generating function <span class="math inline">\(M(\phi)\)</span>.</p>
<p>The evidence density will, of course, depend on the true state of the world, such that if <span class="math inline">\(H_1\)</span> is true, the evidence density <span class="math inline">\(f_1(\Delta L)\)</span> will produce more evidence in favor of <span class="math inline">\(H_1\)</span> and likewise for density <span class="math inline">\(f_0(\Delta L)\)</span>. The properties of the moment generating functions of these densities, <span class="math inline">\(M_1(\phi)\)</span> and <span class="math inline">\(M_0(\phi)\)</span>, respectively, determine the properties of the random walk’s predicted RT’s. Because, in the SPRT, evidence takes the form of a likelihood ratio, the evidence distributions are symmetric, i.e., <span class="math inline">\(f_1(\Delta L) = f_0(-\Delta L)\)</span>, meaning the moment generating functions are related by translation: <span class="math inline">\(M_1(\phi + 1) = M_0(\phi)\)</span>. <span class="citation" data-cites="SwenssonGreen1977">Swensson &amp; Green (<a href="references.html#ref-SwenssonGreen1977" role="doc-biblioref">1977</a>)</span> showed that any random walk model for which the moment generating functions of the evidence distributions are related by translation must predict equal RTs to error and correct responses.</p>
<p>A random walk model of human response dynamics was studied extensively as part of the theory of relative judgment <span class="citation" data-cites="Link1975 LinkHeath1975">(<a href="references.html#ref-Link1975" role="doc-biblioref">Link, 1975</a>; <a href="references.html#ref-LinkHeath1975" role="doc-biblioref">Link &amp; Heath, 1975</a>)</span>. These authors generally assumed that the distributions of differences <span class="math inline">\(\Delta L(t)\)</span> are symmetric with respect to the two alternatives, in the way described above. They further assumed that the decision thresholds were symmetric, i.e., <span class="math inline">\(\theta_1 = -\theta_0\)</span>. Despite these restrictions, this random walk model can predict different RT’s for errors and correct responses. In particular, the difference between mean correct and error RTs in the theory of relative judgment is given by <span class="math display">\[
\begin{align}
RT( \text{Respond } H_1 | H_1) - RT( \text{Respond } H_0 | H_1) &amp; = \left( \frac{\theta_1}{\mu_1} \right) \left( \frac{\gamma_1 - 1}{\gamma_1} \right) \\
RT( \text{Respond } H_0 | H_0) - RT( \text{Respond } H_1 | H_0) &amp; = \left( \frac{\theta_0}{\mu_1} \right) \left( \frac{\gamma_1 - 1}{\gamma_1} \right)
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\mu_i\)</span> is the mean of evidence density <span class="math inline">\(f_i(\Delta L)\)</span> and <span class="math inline">\(\gamma_i\)</span> is its third moment, and <span class="math inline">\(\mu_1 = -\mu_0\)</span> and <span class="math inline">\(\gamma_1 = -\gamma_0\)</span> <span class="citation" data-cites="LinkHeath1975">(<a href="references.html#ref-LinkHeath1975" role="doc-biblioref">Link &amp; Heath, 1975</a>)</span>. Thus, if <span class="math inline">\(\gamma_1 \neq 1\)</span>, errors may be either faster than correct responses (<span class="math inline">\(\gamma_1 &gt; 1\)</span>) or slower (<span class="math inline">\(\gamma_1 &lt; 1\)</span>). Critically, however, the relationship between error and correct RT must be of the same sign regardless of the true evidence generating distribution, which need not be the case in observed data. By relaxing the assumptions of symmetry, such that the moment generating functions of the evidence distributions are related by both scaling and translation (<span class="math inline">\(M_0(\phi) = k M_1(\phi + 1)\)</span>, where <span class="math inline">\(k\)</span> is a constant), <span class="citation" data-cites="Ashby1983">Ashby (<a href="references.html#ref-Ashby1983" role="doc-biblioref">1983</a>)</span> was able to show that a random walk could predict any ordering of mean RTs for correct and error responses.</p>
</section>
<section id="the-wiener-diffusion-process" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="the-wiener-diffusion-process"><span class="header-section-number">2.1.3</span> The Wiener Diffusion Process</h3>
<p>The evidence generating density <span class="math inline">\(f_i(\Delta L)\)</span> can be decomposed into an expectation, <span class="math inline">\(\mu\)</span>, and a noise distribution <span class="math inline">\(\nu\)</span>, which is simply the original distribution with the expected value (<span class="math inline">\(\mu\)</span>) subtracted. The resulting stochastic difference equation for <span class="math inline">\(L(t)\)</span> is</p>
<p><span class="math display">\[
\Delta L(t) = \left[ \mu + \nu(t) \right] \Delta t \text{,}
\]</span></p>
<p>where we have now explicitly introduced <span class="math inline">\(\Delta t\)</span> (up to now, <span class="math inline">\(\Delta t = 1\)</span>) and <span class="math inline">\(\nu(t)\)</span> represents a sample drawn from the noise distribution <span class="math inline">\(\nu\)</span> at time <span class="math inline">\(t\)</span>.</p>
<p>Let us now assume that the evidence generating distribution is Gaussian with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Then, we can consider the noise distribution in the above difference equation to be a Gaussian distribution with mean zero (we have subtracted out <span class="math inline">\(\mu\)</span>) and variance <span class="math inline">\(\sigma^2\)</span>, which we denote <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span>. We now have</p>
<p><span class="math display">\[
\Delta L(t) = \left[ \mu + \mathcal{N}(0, \sigma^2) \right] \Delta t \text{.}
\]</span></p>
<p>In addition, we can rewrite <span class="math inline">\(\mathcal{N}(0, \sigma^2)\)</span> as a sample from a standard (zero mean, unit variance) Gaussian, multiplied by <span class="math inline">\(\sigma\)</span>. This gives us</p>
<p><span class="math display">\[
\Delta L(t) = \mu \Delta t + \mathcal{N}(0, 1) \sigma \sqrt{\Delta t} \text{.}
\]</span></p>
<p>By taking the limit <span class="math inline">\(\Delta t \rightarrow 0\)</span>, we can move from discrete time to continuous time. In so doing, we have transformed the Gaussian random walk into the Wiener drift-diffusion process:</p>
<p><span class="math display">\[
d L(t) = \mu d t + \mathcal{N}(0, 1) \sigma \sqrt{dt} \text{.}
\]</span></p>
<p><span class="citation" data-cites="Ratcliff1978">Ratcliff (<a href="references.html#ref-Ratcliff1978" role="doc-biblioref">1978</a>)</span> modeled human responses as the outcome of a Wiener diffusion where the mean drift rate, <span class="math inline">\(\mu\)</span>, reflects the relative amount of evidence favoring one response over the other while <span class="math inline">\(\sigma\)</span> reflects the noise inherent in the evidence-sampling process. Because each infinitesimal step of the evidence accumulation process comes from a normal distribution, the density over the accumulated evidence at time <span class="math inline">\(t\)</span> is another normal distribution:</p>
<p><span class="math display">\[
\Pr (L(t) = x | t) = \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp \left[ \frac{\left(x - \mu t \right)^2}{2 \sigma^2 t} \right] \sim \mathcal{N}(\mu t, \sigma^2 t) \text{.}
\]</span></p>
<p>This makes it easy to calculate <span class="math inline">\(d'\)</span>, the familiar index of sensitivity from SDT, in the context of the diffusion model. <span class="citation" data-cites="Ratcliff1978">Ratcliff (<a href="references.html#ref-Ratcliff1978" role="doc-biblioref">1978</a>)</span> assumed that the mean drift rate <span class="math inline">\(\mu\)</span> was itself sampled from a normal distribution with mean <span class="math inline">\(u\)</span> and variance <span class="math inline">\(\eta\)</span> for each stimulus. We must thus integrate over <span class="math inline">\(\mu\)</span> to express the distribution of evidence as a function of time:</p>
<p><span class="math display">\[
\begin{align}
\Pr (L(t) = x | t) = &amp; \int_{-\infty}^{\infty} \mathcal{N}(\mu t, \sigma^2 t) \mathcal{N}(u, \eta) d \mu \\
= &amp; \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi \sigma^2 t}} \exp \left[ \frac{\left(x - \mu t \right)^2}{2 \sigma^2 t} \right] \frac{1}{\sqrt{2 \pi \eta^2}} \exp \left[ \frac{\left(\mu - u \right)^2}{2 \eta^2} \right] d \mu \\
= &amp; \frac{1}{\sqrt{2 \pi t ( \eta^2 t + \sigma^2 )}} \exp \left[ \frac{\left(x - u t \right)^2}{2 t ( \eta^2 t + \sigma^2) } \right] \sim \mathcal{N}(u t, t ( \eta^2 t + \sigma^2)) \text{.}
\end{align}
\]</span></p>
<p>If <span class="math inline">\(u\)</span> is the mean of the signal distribution (from which mean drift rates are drawn) and <span class="math inline">\(v\)</span> is the mean of the noise distribution, <span class="math inline">\(d'(t)\)</span> as a function of time <span class="math inline">\(t\)</span> is simply:</p>
<p><span class="math display">\[
d'(t) = \frac{ut - vt}{ \sqrt{t (\eta^2 t + \sigma^2)} } = \frac{u - v}{\eta \sqrt{1 + \frac{\sigma^2}{\eta^2 t}}} \text{.}
\]</span></p>
<p>This is a negatively-accelerated function of time, and reaches an asymptote as <span class="math inline">\(t \rightarrow \infty\)</span>, <span class="math inline">\(d'(t) \rightarrow \frac{u - v}{\eta}\)</span>. This formula for <span class="math inline">\(d'\)</span> will prove useful in subsequent applications of the diffusion model to situations with nonstationary evidence distributions.</p>
<p>Finally, we note the diffusion model predictions for response probabilities and latencies: Assuming that the process starts at some point <span class="math inline">\(z &gt; 0\)</span> and <span class="math inline">\(\theta_1 &gt; z\)</span> and <span class="math inline">\(\theta_0 = 0\)</span>, the probability of reaching <span class="math inline">\(\theta_0 = 0\)</span> (making a <span class="math inline">\(H_0\)</span> decision) is</p>
<p><span class="math display">\[
\Pr ( H_0 | \mu, z, \theta_1, \sigma ) = \frac{ \exp \left( - \frac{2 \mu \theta_1}{\sigma^2} \right) - \exp \left( - \frac{2 \mu z}{\sigma^2} \right)}{\exp \left( - \frac{2 \mu \theta_1}{\sigma^2} \right) - 1}
\]</span></p>
<p>while the probability density for times <span class="math inline">\(t\)</span> at which <span class="math inline">\(\theta_0\)</span> is reached is</p>
<p><span class="math display">\[
f_0 (t | \mu, z, \theta_1, \sigma ) = \frac{1}{\Pr (H_0 | \mu, z, \theta_1, \sigma)} \frac{\pi \sigma^2}{\theta_1^2} \exp \left( - \frac{z \mu}{\sigma^2} \right) \sum_{k=1}^{\infty} k \sin \left( \frac{\pi z k}{\theta_1} \right) \exp \left[- \frac{1}{2} t \left( \frac{\mu^2}{\sigma^2} + \frac{\pi^2 k^2 \sigma^2}{\theta_1^2} \right) \right] \text{.}
\]</span></p>
<p>The probability of making a <span class="math inline">\(H_1\)</span> response is simply <span class="math inline">\(1 - \Pr (H_0 | \mu, z, \theta_1, \sigma )\)</span> while the density for response times given an <span class="math inline">\(H_1\)</span> response is</p>
<p><span class="math display">\[
\begin{align}
f_1 (t | &amp; \mu, z, \theta_1, \sigma ) = \\
&amp; \frac{1}{\Pr (H_1 | \mu, z, \theta_1, \sigma)} \frac{\pi \sigma^2}{\theta_1^2} \exp \left( \frac{(\theta_1 - z) \mu}{\sigma^2} \right) \sum_{k=1}^{\infty} k \sin \left( \frac{\pi (\theta_1 - z) k}{\theta_1} \right) \exp \left[ \frac{1}{2} t \left( \frac{\mu^2}{\sigma^2} - \frac{\pi^2 k^2 \sigma^2}{\theta_1^2} \right) \right] \text{.}
\end{align}
\]</span></p>
<p>These reaction time distributions are positively-skewed, as is usually observed in reaction time distributions. More “difficult” decisions, in which <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> do not differ substantially, thus reducing the absolute value of <span class="math inline">\(\mu\)</span>, will naturally result not only in longer reaction times, but more skewed reaction times according to the diffusion model.</p>
</section>
<section id="optimality-and-multiple-alternatives" class="level3" data-number="2.1.4">
<h3 data-number="2.1.4" class="anchored" data-anchor-id="optimality-and-multiple-alternatives"><span class="header-section-number">2.1.4</span> Optimality and Multiple Alternatives</h3>
<p>The Wiener diffusion process, as a natural extension of the SPRT, can be shown to be the optimal decision strategy when there are two alternatives and the evidence-generating distribution is stationary and perturbed by Gaussian noise <span class="citation" data-cites="BogaczEtAl2006">(<a href="references.html#ref-BogaczEtAl2006" role="doc-biblioref">Bogacz et al., 2006</a>)</span>. The diffusion model can be extended to model choices between more than two alternatives by extending the Wiener process into multiple dimensions <span class="citation" data-cites="Smith2000">(<a href="references.html#ref-Smith2000" role="doc-biblioref">Smith, 2000</a>)</span>. If the decision thresholds are orthogonal to one another (which might occur if they are parallel to the coordinate axes), a multidimensional diffusion essentially becomes a parallel race model (see below). While this extension is not conceptually difficult, it runs into the problem that a diffusion in more than two dimensions is no longer guaranteed to eventually hit every point in the state space. Thus, it is far harder to calculate the probability of a multidimensional diffusion process hitting a boundary, let alone the density of its first passage times. There are cases, however, where a multidimensional diffusion may be reduced a more tractable one in a single dimension <span class="citation" data-cites="Ashby2000 Smith2000">(<a href="references.html#ref-Ashby2000" role="doc-biblioref">Ashby, 2000</a>; <a href="references.html#ref-Smith2000" role="doc-biblioref">Smith, 2000</a>)</span>.</p>
<p>Instead of treating a decision between multiple alternatives as a multidimensional diffusion, it can be explicitly modeled as a set of simultaneous diffusions that independently accumulate evidence for each alternative. Just as the unidimensional diffusion is equivalent to the SPRT, a set of <span class="math inline">\(M\)</span> parallel diffusions is related to the “<span class="math inline">\(M\)</span>-ary Sequential Probability Ratio Test” [MSPRT; <span class="citation" data-cites="BaumVeeravelli1994">Baum &amp; Veeravalli (<a href="references.html#ref-BaumVeeravelli1994" role="doc-biblioref">1994</a>)</span>]. The MSPRT has no single optimal decision rule, but one candidate procedure is to choose option <span class="math inline">\(H_k\)</span> when its posterior probability given the evidence <span class="math inline">\(X\)</span> up to time <span class="math inline">\(t\)</span>, <span class="math inline">\(\Pr (H_k | X_t)\)</span>, exceeds a threshold level of probability. This threshold is equal to the expected hit rate, conditioned on response <span class="math inline">\(H_k\)</span>. This rule is optimal to the extent that it produces a decision with the desired level of accuracy in the shortest time <span class="citation" data-cites="BogaczGurney2007 JonesEtAl2009 ZhangChangInRev">(<a href="references.html#ref-BogaczGurney2007" role="doc-biblioref">Bogacz &amp; Gurney, 2007</a>; <a href="references.html#ref-JonesEtAl2009" role="doc-biblioref">Jones et al., 2009</a>; <a href="references.html#ref-ZhangChangInRev" role="doc-biblioref">Zhang &amp; Chang, in review</a>)</span>.</p>
<p>To formally express the diffusion version of the MSPRT, recall that Bayes rule relates the posterior probability of a hypothesis <span class="math inline">\(H_k\)</span> to the likelihood, prior, and evidence: <span class="math display">\[
\Pr (H_k | X_t) = \frac{\Pr (X_t | H_k) \Pr (H_k)}{\sum_{i=1}^M \Pr (X_t | H_i) \Pr (H_i)} \text{.}
\]</span> Taking the logarithm of the above yields <span class="math display">\[
\log \Pr (H_k | X_t) = \log \Pr (X_t | H_k) + \log \Pr (H_k) - \log \left[ \sum_{i=1}^M \exp \left( \log \Pr (X_t | H_i) + \log \Pr (H_i) \right) \right] \text{.}
\]</span> Assuming, as we have all along, that evidence arrives sequentially and is sampled independently from a stationary evidence-generating distribution, we can let <span class="math inline">\(L_k(t) = \sum_{i=0}^t \log \Pr (x_i | H_k) + \log \Pr (H_k)\)</span>, such that <span class="math inline">\(\Delta L_k(t) = \log \Pr (x_t | H_k) \Delta t\)</span>. Finally, by assuming that the likelihood functions are Gaussian and that <span class="math inline">\(\Delta t \rightarrow 0\)</span>, we obtain a Wiener drift-diffusion process for each alternative. The decision rule for the multi-alternative diffusion model thus requires that the aggregate state for an option <span class="math inline">\(k\)</span> be sufficiently large relative to the sum of the aggregate states of all alternatives. Thus, while evidence may accumulate for each alternative independently and in parallel, the alternatives compete with each other in order to actually produce a decision. In the two-alternative case, the predictions are identical to the standard SPRT (and, thus, to the unidimensional diffusion model), in which only two alternatives compete with one another. This extension of the diffusion model to multiple alternatives can be made even more powerful by assuming that the decision maker must <em>infer</em> the underlying mean drift rates for each option, leading to a rational explanation for certain trial-order effects <span class="citation" data-cites="JonesEtAl2009">(<a href="references.html#ref-JonesEtAl2009" role="doc-biblioref">Jones et al., 2009</a>)</span>.</p>
</section>
</section>
<section id="counter-and-accumulator-models" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="counter-and-accumulator-models"><span class="header-section-number">2.2</span> Counter and Accumulator Models</h2>
<p>The extension of the diffusion model to multiple alternatives leads directly into a potentially more general class of models for response dynamics, namely, the counter or accumulator models. The two-alternative SPRT, random walk, and diffusion models necessarily consider evidence for one alternative to be equal evidence the other alternative. This is also the case when there are more than two alternatives. However, there are situations in which it does not make sense to consider strict competition among alternatives. Consider a situation in which you are choosing between two desserts of equal price, the key lime pie and the German chocolate cake. The fact that you like coconut might increment your preference for German chocolate cake, but it is hard to see why it should reduce your preference for key lime pie. You may have different degrees of preference for either option, and that difference may drive your eventual decision, but there is no reason to think your preferences should be anti-correlated, as is assumed by the models we have considered thus far.</p>
<section id="counter-models" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="counter-models"><span class="header-section-number">2.2.1</span> Counter Models</h3>
<p>“Counter” models are so called because, in their original form, each choice alternative was presumed to be associated with a count of the number of “pieces” of evidence in favor of it, and the corresponding response would be made when one counter reached a threshold. The first such model was by <span class="citation" data-cites="LaBerge1962">LaBerge (<a href="references.html#ref-LaBerge1962" role="doc-biblioref">1962</a>)</span>, in which time progressed in discrete intervals of equal size. On each time-step, a single “piece” of evidence was added to a counter representing one of the possible alternatives, and a final decision made when one of the counters reaches a threshold. In other words, each alternative “races” to reach its threshold and produce a response.</p>
<p>Two (not mutually exclusive) ways to extend the counter model are apparent: First, to make the state space (the possible evidence values) continuous, rather than discrete; and second, to make time continuous rather than discrete. The accumulator model of <span class="citation" data-cites="Vickers1970">Vickers (<a href="references.html#ref-Vickers1970" role="doc-biblioref">1970</a>)</span> and <span class="citation" data-cites="SmithVickers1988">Smith &amp; Vickers (<a href="references.html#ref-SmithVickers1988" role="doc-biblioref">1988</a>)</span> assumes that time remains discrete while the values of evidence may take on continuous values, perhaps from a truncated normal or exponential distribution. The parameters of each distribution reflect the amount of evidence for each alternative, and the thresholds on each accumulator reflect response biases. Alternatively, the Poisson counter model <span class="citation" data-cites="Pike1973 TownsendAshby1983 SmithVanZandt2000">(<a href="references.html#ref-Pike1973" role="doc-biblioref">Pike, 1973</a>; <a href="references.html#ref-SmithVanZandt2000" role="doc-biblioref">Smith &amp; Van Zandt, 2000</a>; <a href="references.html#ref-TownsendAshby1983" role="doc-biblioref">Townsend &amp; Ashby, 1983</a>)</span> assumes that the amount of evidence accumulated at any one time is fixed, but the interarrival times for that evidence are variable. Specifically, they are sampled independently from an exponential distribution, with rates that differ between accumulators. In the Poisson counter model, thresholds again reflect response biases, while the rate of arrivals to a particular counter corresponds to the amount of evidence in favor of that response. Thus, unless there is a bias against the correct response, the Poisson counter model will predict faster RT for correct responses than errors, no matter what sources of variability are added to the model <span class="citation" data-cites="RatcliffSmith2004">(<a href="references.html#ref-RatcliffSmith2004" role="doc-biblioref">Ratcliff &amp; Smith, 2004</a>)</span>.</p>
<p>When <span class="math inline">\(M\)</span> Poisson counters are running independently and in parallel with interarrival rates <span class="math inline">\(\lambda_1, \lambda_2, \dotsc, \lambda_M\)</span>, the entire decision process can be construed as a Poisson process with a rate that is the sum of the rates of the individual accumulators, <span class="math inline">\(\lambda_1 + \lambda_2 + \dotsb + \lambda_M\)</span> <span class="citation" data-cites="TownsendAshby1983">(<a href="references.html#ref-TownsendAshby1983" role="doc-biblioref">Townsend &amp; Ashby, 1983</a>)</span>. Thus, regardless of the final choice, if it is reached after <span class="math inline">\(N\)</span> counts have accumulated across all the counters, the RT distribution is a Gamma distribution: <span class="math display">\[
f (t | N, \lambda_1, \lambda_2, \dotsc, \lambda_M) = \left(\sum_{i=1}^M \lambda_i \right)^{-N} \exp \left( -\frac{t}{\sum_{i=1}^M \lambda_i} \right) \frac{t^{N-1}}{\left(N - 1 \right)!} \text{.}
\]</span> This has two important consequences: First, RT distributions are predicted to become less skewed as the mean number of samples <span class="math inline">\(N\)</span> increases (the skewness of a Gamma distribution is <span class="math inline">\(\frac{2}{\sqrt{N}}\)</span>), which is not supported by most empirical RT distributions. More importantly, however, RT is predicted to be faster with increasing number of alternatives, owing to the fact that each counter contributes <span class="math inline">\(\lambda_i\)</span> to the overall processing rate. This is a general property of models with independent parallel accumulators for each decision, regardless of the choice of distributions or parameters <span class="citation" data-cites="TownsendAshby1983">(<a href="references.html#ref-TownsendAshby1983" role="doc-biblioref">Townsend &amp; Ashby, 1983</a>)</span>. There are many situations, however, in which increasing the number of alternative responses (and thus the number of parallel accumulators) results in an <em>increase</em> in reaction time. This can limit the utility of parallel counter models to account for observed response dynamics unless accumulation rates decrease with the number of accumulators <span class="citation" data-cites="RatcliffSmith2004 TeodorescuUsher2013">(<a href="references.html#ref-RatcliffSmith2004" role="doc-biblioref">Ratcliff &amp; Smith, 2004</a>; <a href="references.html#ref-TeodorescuUsher2013" role="doc-biblioref">Teodorescu &amp; Usher, 2013</a>)</span>.</p>
</section>
<section id="partially-correlated-accumulators" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="partially-correlated-accumulators"><span class="header-section-number">2.2.2</span> Partially Correlated Accumulators</h3>
<p>If random walk and diffusion models involve accumulators for each alternative that are perfectly anticorrelated, and counter/accumulator models posit accumulators that are totally uncorrelated, perhaps a middle ground might be found? The Leaky, Competing Accumulator model <span class="citation" data-cites="UsherMcClelland2001">(LCA, <a href="references.html#ref-UsherMcClelland2001" role="doc-biblioref">Usher &amp; McClelland, 2001</a>)</span> is one such example. In this model, each of the <span class="math inline">\(M\)</span> accumulators is presumed to be subject to Gaussian noise and can be described by the following differential equation: <span class="math display">\[
d L_i(t) = \left( I_i - \gamma L_i(t) - \beta \sum_{j \neq i}^M L_j(t) \right) dt + \sigma \mathcal{N}(0, 1) \sqrt{dt} \text{.}
\]</span> This equation has several terms that we now parcel out: <span class="math inline">\(I_i\)</span> is the exogenous (stimulus-driven) input to accumulator <span class="math inline">\(i\)</span>, analogous to the drift rate in a diffusion; the <span class="math inline">\(-\gamma L_i(t)\)</span> term implements “leakage”, similar to an OU process (see below) when <span class="math inline">\(0 \leq \gamma \leq 1\)</span>; <span class="math inline">\(\beta \sum_{j \neq i}^M L_j(t)\)</span> implements a (partial) negative correlation between accumulators; and the final term is simply the familiar Gaussian noise term. There is, further, a critical nonlinearity in the model, namely, that <span class="math inline">\(L_i\)</span> is never permitted to be negative. The theoretical consequence of this is that accumulators can only act to inhibit one another. The practical consequence is that the LCA model is not analytically tractable, although it can be approximated by two OU processes in the two-accumulator case <span class="citation" data-cites="UsherMcClelland2001 BogaczEtAl2007">(<a href="references.html#ref-BogaczEtAl2007" role="doc-biblioref">Bogacz et al., 2007</a>; <a href="references.html#ref-UsherMcClelland2001" role="doc-biblioref">Usher &amp; McClelland, 2001</a>)</span>. This nonlinearity may, however, prove advantageous by reducing excessive inhibition from poor choices <span class="citation" data-cites="BogaczEtAl2007">(<a href="references.html#ref-BogaczEtAl2007" role="doc-biblioref">Bogacz et al., 2007</a>)</span>.</p>
<p>If this nonlinearity is ignored, the LCA can be made identical, at least in the two-alternative case, to a race model (by letting <span class="math inline">\(\gamma = \beta = 0\)</span>), to a diffusion model (by letting <span class="math inline">\(\gamma = 0\)</span> and <span class="math inline">\(\beta = 1\)</span>), or to an OU process (by letting <span class="math inline">\(\beta = 1\)</span>). Thus, it has great flexibility in predicting a variety of patterns of reaction time and accuracy, especially when incorporating payoffs <span class="citation" data-cites="UsherMcClelland2004">(<a href="references.html#ref-UsherMcClelland2004" role="doc-biblioref">Usher &amp; McClelland, 2004</a>)</span>.</p>
</section>
<section id="ballistic-accumulators" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="ballistic-accumulators"><span class="header-section-number">2.2.3</span> Ballistic Accumulators</h3>
<p>Although they will not be addressed subsequently, we briefly alight on a recent set of models that are “ballistic” in the sense that they are completely deterministic, once their initial conditions (parameters, starting points, and thresholds) are set. The first of these was proposed by <span class="citation" data-cites="BrownHeathcote2005">Brown &amp; Heathcote (<a href="references.html#ref-BrownHeathcote2005" role="doc-biblioref">2005</a>)</span> as a non-stochastic version of the LCA model. It is nonetheless able to account for decision data because, although the within-trial dynamics of the model are deterministic, it is subject to between-trial noise. In particular, the exact external input to each accumulator is perturbed by Gaussian noise on each trial, and the initial value of each accumulator is randomly sampled from a uniform distribution. <span class="citation" data-cites="BrownHeathcote2008">Brown &amp; Heathcote (<a href="references.html#ref-BrownHeathcote2008" role="doc-biblioref">2008</a>)</span> extend this idea to the diffusion model in the Linear Ballistic Accumulator (LBA). This, too, is able to account for observed reaction time and accuracy data quite well <span class="citation" data-cites="DonkinEtAl2011">(<a href="references.html#ref-DonkinEtAl2011" role="doc-biblioref">Donkin et al., 2011</a>)</span>.</p>
<p>Sequential sampling models rely on the idea that at any one time, evidence may be noisy, and so to make accurate decisions, noisy evidence samples must be integrated over time. What, then, are we to make of the idea that ballistic models without noisy evidence can still fit data? I argue that it is a question of interpretation: Sequential sampling models, from the SPRT to the diffusion model, attempt to model what is thought to be the “real” state of the world: that evidence itself is noisy. Ballistic models, on the other hand, are best thought of as “measurement models”, in that they re-describe or summarize the data (accuracy and reaction time) in a way that makes it amenable to cognitive interpretation. The fact that, by abandoning the notion of sampling noise, ballistic models are still able to fit data should not worry anyone: Ballistic models are trying to describe the data by making as few assumptions as possible, while stochastic models are trying instead to describe the underlying state of the world.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-Ashby1983" class="csl-entry" role="listitem">
Ashby, F. G. (1983). A biased random walk model for two choice reaction times. <em>Journal of Mathematical Psychology</em>, <em>27</em>, 277–297.
</div>
<div id="ref-Ashby2000" class="csl-entry" role="listitem">
Ashby, F. G. (2000). A stochastic version of general recognition theory. <em>Journal of Mathematical Psychology</em>, <em>44</em>, 310–329.
</div>
<div id="ref-BaumVeeravelli1994" class="csl-entry" role="listitem">
Baum, C. W., &amp; Veeravalli, V. V. (1994). A sequential procedure for multihypothesis testing. <em><span>IEEE</span> Transactions on Information Theory</em>, <em>40</em>(6), 1994–2007.
</div>
<div id="ref-BogaczEtAl2006" class="csl-entry" role="listitem">
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., &amp; Cohen, J. D. (2006). The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks. <em>Psychological Review</em>, <em>113</em>(4), 700–765.
</div>
<div id="ref-BogaczGurney2007" class="csl-entry" role="listitem">
Bogacz, R., &amp; Gurney, K. (2007). The basal ganglia and cortex implement optimal decision making between alternative actions. <em>Neural Computation</em>, <em>19</em>, 442–477.
</div>
<div id="ref-BogaczEtAl2007" class="csl-entry" role="listitem">
Bogacz, R., Usher, M., Zhang, J., &amp; McClelland, J. L. (2007). Extending a biologically inspired model of choice: Multi-alternatives, nonlinearity and value-based multidimensional choice. <em>Philosophical Transactions of the Royal Society B</em>, <em>362</em>, 1655–1670.
</div>
<div id="ref-BrownHeathcote2005" class="csl-entry" role="listitem">
Brown, S., &amp; Heathcote, A. (2005). A ballistic model of choice response time. <em>Psychological Review</em>, <em>112</em>(1), 117–128.
</div>
<div id="ref-BrownHeathcote2008" class="csl-entry" role="listitem">
Brown, S., &amp; Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. <em>Cognitive Psychology</em>, <em>57</em>, 153–178.
</div>
<div id="ref-DonkinEtAl2011" class="csl-entry" role="listitem">
Donkin, C., Brown, S., Heathcote, A., &amp; Wagenmakers, E.-J. (2011). Diffusion versus linear ballistic accumulation: Different models but the same conclusions about psychological processes? <em>Psychonomic Bulletin &amp; Review</em>, <em>55</em>, 140–151.
</div>
<div id="ref-Edwards1965" class="csl-entry" role="listitem">
Edwards, W. (1965). Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing. <em>Journal of Mathematical Psychology</em>, <em>2</em>, 312–329.
</div>
<div id="ref-JonesEtAl2009" class="csl-entry" role="listitem">
Jones, M., Mozer, M., &amp; Kinoshita, S. (2009). Optimal response initiation: Why recent experience matters. In D. Koller, D. Schuurmans, Y. Bengio, &amp; L. Bottou (Eds.), <em>Advances in neural information processing systems</em> (Vol. 21, pp. 785–792).
</div>
<div id="ref-LaBerge1962" class="csl-entry" role="listitem">
LaBerge, D. (1962). A recruitment theory of simple behavior. <em>Psychometrika</em>, <em>27</em>(4), 375–396.
</div>
<div id="ref-Link1975" class="csl-entry" role="listitem">
Link, S. W. (1975). The relative judgment theory of two choice response time. <em>Journal of Mathematical Psychology</em>, <em>12</em>, 114–135.
</div>
<div id="ref-LinkHeath1975" class="csl-entry" role="listitem">
Link, S. W., &amp; Heath, R. A. (1975). A sequential theory of psychological discrimination. <em>Psychometrika</em>, <em>40</em>, 77–105.
</div>
<div id="ref-MacmillanCreelman2005" class="csl-entry" role="listitem">
Macmillan, N. A., &amp; Creelman, C. D. (2005). <em>Detection theory: A user’s guide</em> (2nd ed.). Erlbaum.
</div>
<div id="ref-NeymanPearson1933" class="csl-entry" role="listitem">
Neyman, J., &amp; Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. <em>Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</em>, <em>231</em>, 289–337.
</div>
<div id="ref-Pike1973" class="csl-entry" role="listitem">
Pike, R. (1973). Response latency models for signal detection. <em>Psychological Review</em>, <em>80</em>(1), 53–68.
</div>
<div id="ref-Ratcliff1978" class="csl-entry" role="listitem">
Ratcliff, R. (1978). A theory of memory retrieval. <em>Psychological Review</em>, <em>85</em>(2), 59–108.
</div>
<div id="ref-RatcliffSmith2004" class="csl-entry" role="listitem">
Ratcliff, R., &amp; Smith, P. L. (2004). A comparison of sequential sampling models for two-choice reaction time. <em>Psychological Review</em>, <em>111</em>(2), 333–367.
</div>
<div id="ref-Smith2000" class="csl-entry" role="listitem">
Smith, P. L. (2000). Stochastic dynamic models of response time and accuracy: A foundational primer. <em>Journal of Mathematical Psychology</em>, <em>44</em>(3), 408–463.
</div>
<div id="ref-SmithVanZandt2000" class="csl-entry" role="listitem">
Smith, P. L., &amp; Van Zandt, T. (2000). Time-dependent <span>Poisson</span> counter models of response latency in simple judgment. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>53</em>, 293–315.
</div>
<div id="ref-SmithVickers1988" class="csl-entry" role="listitem">
Smith, P. L., &amp; Vickers, D. (1988). The accumulator model of two-choice decision. <em>Journal of Mathematical Psychology</em>, <em>32</em>, 135–168.
</div>
<div id="ref-Stone1960" class="csl-entry" role="listitem">
Stone, M. (1960). Models for choice-reaction time. <em>Psychometrika</em>, <em>25</em>, 251–260.
</div>
<div id="ref-SwenssonGreen1977" class="csl-entry" role="listitem">
Swensson, R. G., &amp; Green, D. M. (1977). On the relations between random walk models for two-choice response times. <em>Journal of Mathematical Psychology</em>, <em>15</em>, 282–291.
</div>
<div id="ref-TeodorescuUsher2013" class="csl-entry" role="listitem">
Teodorescu, A. R., &amp; Usher, M. (2013). Disentangling decision models: From independence to competition. <em>Psychological Review</em>, <em>120</em>(1), 1–38.
</div>
<div id="ref-TownsendAshby1983" class="csl-entry" role="listitem">
Townsend, J. T., &amp; Ashby, F. G. (1983). <em>Stochastic modeling of elementary psychological processes</em>. Cambridge University Press.
</div>
<div id="ref-UsherMcClelland2001" class="csl-entry" role="listitem">
Usher, M., &amp; McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. <em>Psychological Review</em>, <em>108</em>(3), 550–592.
</div>
<div id="ref-UsherMcClelland2004" class="csl-entry" role="listitem">
Usher, M., &amp; McClelland, J. L. (2004). Loss aversion and inhibition in dynamical models of multialternative choice. <em>Psychological Review</em>, <em>111</em>(3), 757–769.
</div>
<div id="ref-Vickers1970" class="csl-entry" role="listitem">
Vickers, D. (1970). Evidence for an accumulator model of psychophysical discrimination. <em>Ergonomics</em>, <em>13</em>(1), 37–58.
</div>
<div id="ref-Wald1945" class="csl-entry" role="listitem">
Wald, A. (1945). Sequential tests of statistical hypotheses. <em>The Annals of Mathematical Statistics</em>, <em>16</em>(2), 117–186.
</div>
<div id="ref-ZhangChangInRev" class="csl-entry" role="listitem">
Zhang, J., &amp; Chang, M. (in review). A <span>Bayesian</span> random-walk model of choice reaction times under prior knowledge of target onset uncertainty. <em>Proceedings of the National Academy of Sciences</em>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./random_walk.html" class="pagination-link" aria-label="Building a random walk model to simulate choice and RT">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Building a random walk model to simulate choice and RT</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>